{"role": "system", "content": "You are an intelligent agent with expertise in **retrieving useful context from both the DuckDB database and the Milvus vectorstore through SQL execution and similarity search** and **answering user questions**. You will be given a natural language question concerning PDF files, along with the schema of both the database and the vectorstore. Your ultimate goal is to answer the input question with pre-defined answer format. The DuckDB database contains all parsed content of raw PDF files, while the Milvus vectorstore encodes specific column cells from the database as vectors. You can predict executable actions, interact with the hybrid environment (including database and vectorstore) across multiple turns, and retrieve necessary context until you are confident in resolving the question.\n\n--------\n\n## Task Description\nEach task consists of the following parts:\n\n[Question]: User question regarding the PDF, e.g., Is there any ...?\n[Answer Format]: it describes the format of the final answer, e.g., the answer is \"Yes\" or \"No\" without punctuation.\n[Anchor PDF]: Optional, a python str or list, the PDF(s) you must use to answer the question.\n[Reference PDF]: Optional, a python str or list, the PDF(s) you may use to answer the question.\n[Conference]: Optional, a python str or list, the conference(s) and year(s) of the relevant papers for retrieval.\n[Database Schema]: A detailed serialized schema of the DuckDB database for reference when generating SQL queries. It includes 1) tables, 2) columns and their data types, 3) descriptions for these schema items, and 4) primary key and foreign key constraints.\n[Vectorstore Schema]: A detailed serialized schema of the Milvus vectorstore for reference when generating executable retrieval actions with specific parameters. It includes 1) collections, 2) fields, 3) encodable (table, column) pairs in the relational database where the vectorized content originates, and 4) grammar for valid filter rules.\n\n\n--------\n\n## Action and Observation Space\nAll allowable action types include ['RetrieveFromDatabase', 'ClassicRetrieve', 'GenerateAnswer']. Here is the detailed specification in MARKDOWN format:\n\n### Action Type\nRetrieveFromDatabase\n\n### Description\nGenerate an SQL query to retrieve the desired information from the DuckDB database. Please refer to the concrete database schema to produce a valid and executable SQL.\n\n### Observation\nThe observation space is the execution result of the SQL query. You do not need to worry about the actual execution, we will perform it for you. If the SQL failed to execute, we will return the error message. Extremely long SQL output will be truncated.\n\n### Syntax and Parameters (MARKDOWN Format)\nRetrieveFromDatabase(sql: str)\n- sql: str, required. The concrete DuckDB SQL query to execute and retrieve results.\n\n### Use Cases\n\n#### Case 1\nGet the abstract of the paper with paper_id '12345678' from the metadata table in the DuckDB database.\n\n[Action]: RetrieveFromDatabase(sql=\"SELECT abstract FROM metadata WHERE paper_id = '12345678';\")\n\n\n#### Case 2\nFind which page in the paper with paper_id '12345678' contains Figure 3.\n\n[Action]: RetrieveFromDatabase(sql=\"SELECT pages.page_number FROM images JOIN pages JOIN metadata ON images.ref_page_id = pages.page_id AND pages.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '12345678' AND images.image_caption LIKE '%Figure 3%';\")\n\n\n----\n\n### Action Type\nClassicRetrieve\n\n### Description\nGiven a query text, retrieve relevant context from the Milvus vectorstore.\n\n### Observation\nThe observation space is the retrieved top-ranked entries from the Milvus vectorstore based on queries.\n\n### Syntax and Parameters (MARKDOWN Format)\nClassicRetrieve(query: str, limit: int = 5)\n- query: str, required. The query text will be encoded and used to search for relevant context. You can rephrase the original user question to obtain a more clear and structured query requirement.\n- limit: int, optional, default to 5. The number of top-ranked context to retrieve. Please set it to a positive integer to limit the number of returned results. Extremely large limit values may be truncated.\n\n### Use Cases\n\n#### Case 1\nRetrieve top 5 pieces about a certain topic.\n\n[Action]: ClassicRetrieve(query='Is there any work about the topic structured RAG?')\n\n\n#### Case 2\nRetrieve detailed information about the learning rate for training the ResNet model. The top 4 most relevant entries will be returned based on the query.\n\n[Action]: ClassicRetrieve(query=\"What's the learning rate for training the ResNet model?\", limit=4)\n\n\n----\n\n### Action Type\nGenerateAnswer\n\n### Description\nWhen you take this action, the retrieved results suffice to answer the user question. PLEASE STRICTLY ADHERE TO THE ANSWER FORMAT FOR THE CURRENT QUESTION.\n\n### Observation\nThere is no observation for this terminal action, since it indicates the completion of the task and end of the interaction.\n\n### Syntax and Parameters (MARKDOWN Format)\nGenerateAnswer(answer: Any)\n- answer: Any, required. The final answer to the user question. Please adhere to the answer format for the current question.\n\n### Use Cases\n\n#### Case 1\nThe answer to the user question is 42.\n\n[Action]: GenerateAnswer(answer=42)\n\n\n#### Case 2\nThe answer to the user question is a list of strings: ['Results', 'Discussion'].\n\n[Action]: GenerateAnswer(answer=['Results', 'Discussion'])\n\n\n\n--------\n\n## Interaction Framework\n\nThe main interaction procedure proceeds like this:\n\n----\n\n[Thought]: ... reasoning process, why to take this action ...\n[Action]: ... which action to take, please strictly conform to the action specification ...\n[Observation]: ... execution results or error message after taking the action ...\n\n... # more interleaved triplets of ([Thought], [Action], [Observation])\n\n[Thought]: ... reasoning process to produce the final answer ...\n[Action]: ... the terminate action `GenerateAnswer`, there is no further observation ...\n\n----\n\nIn general, the main interaction loop consists of an interleaved of triplets ([Thought], [Action], [Observation]), except the last `GenerateAnswer` action which does not have \"[Observation]:\". You need to predict the \"[Thought]: ...\" followed by the \"[Action]: ...\" for each turn, and we will execute your action in the environment and provide the \"[Observation]: ...\" for the previous action.\n\n--------\n\n## Suggestions or Hints for Agent Interaction\n\n1. Explore multiple retrieval strategies. For example:\n- Experiment with different (table, column) pairs to extract diverse types of information.\n- Query various embedding models (collections) to find the most relevant context.\n\n2. Combine both structured and unstructured data. Concretely:\n- Use SQL queries to retrieve precise facts and structured data. Pay special attention to morphological variations in cell values.\n- Perform similarity searches in the vectorstore to capture semantic relationships and hidden insights.\n\n3. Iterate and refine:\n- If SQL execution result is not satisfactory, try alternative SQL queries to explore the database content carefully.\n- If the vector-based neural retrieval is insufficient, try alternative approaches or parameter settings.\n- Use your findings to validate or enrich the final response.\n\n4. Ensure confidence. That is, only make a final decision when you are confident that the retrieved information fully addresses the userâ€™s query.\n\n\nRemember that, for each question, you only have 20 interaction turns at most. Now, let's start!\n"}
{"role": "user", "content": "[Question]: In the paper \"Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning\", which method performs the best on ID states with full-chain setting? In the paper that proposed that method, where does the -inf in Fig. 3 come from?\n[Answer Format]: Your answer should be a Python list of 2 strings, the first is the abbreviation of the method, the second is the reason why -inf appears in Fig. 3.\n[Anchor PDF]: '1e3d6210-2df4-5eba-92d6-beab951bf795'\n[Database Schema]: The database schema for /home/htc981/workspace/project/HNS-RAG/data/database/ai_research/ai_research.sql is as follows:\n/* database ai_research: This database contains information about AI research papers. Each PDF file is represented or parsed via different views, e.g., pages, sections, figures, tables, and references. We also extract the concrete content inside each concrete element via OCR.\n*/\n/* table metadata: This table stores metadata about each paper, including the number of pages, paper path and paper id.\n*/\nCREATE TABLE IF NOT EXISTS metadata (\n\tpaper_id UUID, -- A unique identifier for this paper.\n\ttitle VARCHAR, -- The title of this paper.\n\tabstract VARCHAR, -- The abstract of this paper.\n\tnum_pages INTEGER, -- The number of pages in this paper.\n\tconference_full VARCHAR, -- The full name of the conference where this paper was published. `uncategorized` if the paper has not been published yet.\n\tconference_abbreviation VARCHAR, -- The abbreviation of the conference where this paper was published. `uncategorized` if the paper has not been published yet.\n\tpub_year INTEGER, -- The year when this paper was published.\n\tvolume VARCHAR, -- The volume of the conference where this paper was published. e.g. findings.\n\tdownload_url VARCHAR, -- The url from which the paper can be downloaded.\n\tbibtex VARCHAR, -- The bibtex of this paper.\n\tauthors VARCHAR[], -- The full names of authors of this paper.\n\tpdf_path VARCHAR, -- The path to the PDF file of this paper.\n\ttldr VARCHAR, -- A brief summary of the paper's main idea or findings generated by LLM based on title and abstract.\n\ttags VARCHAR[], -- Keywords representing the paper's topics, methods, or applications generated by LLM based on title and abstract.,\n\tPRIMARY KEY (paper_id)\n);\n/* table pages: This table stores information of the pages in the papers, including their content, size and their order within the paper. The pagesare extracted using PyMuPDF.\n*/\nCREATE TABLE IF NOT EXISTS pages (\n\tpage_id UUID, -- A unique identifier for each page.\n\tpage_number INTEGER, -- The page number in the current paper, starting from 1.\n\tpage_width INTEGER, -- The pixel width of the current page.\n\tpage_height INTEGER, -- The pixel height of the current page.\n\tpage_content VARCHAR, -- The content of the page.\n\tpage_summary VARCHAR, -- A brief summary of the page content, generated by LLM, focusing on key information and describing the page content.\n\tref_paper_id UUID, -- A foreign key linking to the `paper_id` in the `metadata` table.,\n\tPRIMARY KEY (page_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id)\n);\n/* table images: This table stores the information about images in each paper. The images are extracted using MinerU.\n*/\nCREATE TABLE IF NOT EXISTS images (\n\timage_id UUID, -- The unique identifier of the image.\n\timage_caption VARCHAR, -- The caption of this image, \"\" if it doesn't have one.\n\timage_summary VARCHAR, -- A brief summary of the image, generated by LLM, focusing on key information and describing the image.\n\tbounding_box INTEGER[4], -- The bounding box of the figure in the format [x0, y0, w, h], where (x0, y0) represents the coordinates of the top-left corner and (w, h) represents the width and height which are used to determine the shape of the rectangle.\n\tordinal INTEGER, -- Each figure is labeled with one distinct integer number in the current page, which starts from 0.\n\tref_paper_id UUID, -- A foreign key linking to the `paper_id` in the `metadata` table.\n\tref_page_id UUID, -- A foreign key linking to the `page_id` in the `pages` table.,\n\tPRIMARY KEY (image_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id),\n\tFOREIGN KEY (ref_page_id) REFERENCES pages(page_id)\n);\n/* table chunks: This table contains the information of each chunk of text (chunk size = 512 tokens with no overlapping) in each page of the paper. A chunk is a sub-text that is extracted from the main text using langchain, such as a sentence or a paragraph.\n*/\nCREATE TABLE IF NOT EXISTS chunks (\n\tchunk_id UUID, -- A unique identifier for each chunk of text.\n\ttext_content VARCHAR, -- The text content of the current chunk.\n\tordinal INTEGER, -- Each chunk is labeled with one distinct integer number in the current page, which starts from 0.\n\tref_paper_id UUID, -- A foreign key linking to the `paper_id` in the `metadata` table.\n\tref_page_id UUID, -- A foreign key linking to the `page_id` in the `pages` table.,\n\tPRIMARY KEY (chunk_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id),\n\tFOREIGN KEY (ref_page_id) REFERENCES pages(page_id)\n);\n/* table tables: This table stores information about tables extracted from pages using MinerU, including content (in html format), bounding box and summary of each table generated by LLM.\n*/\nCREATE TABLE IF NOT EXISTS tables (\n\ttable_id UUID, -- A unique identifier for each table.\n\ttable_caption VARCHAR, -- Caption of the table, showing key information of the table.\n\ttable_content VARCHAR, -- The content of the table in html format.\n\ttable_summary VARCHAR, -- A brief summary of the table content generated by LLM, focusing on key information and describing the table content.\n\tbounding_box INTEGER[4], -- The bounding box of the table in the format [x0, y0, w, h], where (x0, y0) represents the coordinates of the top-left corner and (w, h) represents the width and height.\n\tordinal INTEGER, -- Each table is labeled with one distinct integer number in the current page, which starts from 0.\n\tref_paper_id UUID, -- A foreign key linking to the `paper_id` in the `metadata` table.\n\tref_page_id UUID, -- A foreign key linking to the `page_id` in the `pages` table where this table is located.,\n\tPRIMARY KEY (table_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id),\n\tFOREIGN KEY (ref_page_id) REFERENCES pages(page_id)\n);\n/* table sections: This table contains the text content of each section in the paper, e.g. `Introduction`, `Experiment`, `Conclusion`, `Reference`. The sections are extracted using PyMuPDF or MinerU.\n*/\nCREATE TABLE IF NOT EXISTS sections (\n\tsection_id UUID, -- A unique identifier for each section of text.\n\tsection_title VARCHAR, -- The title of the current section.\n\tsection_content VARCHAR, -- The text content of the current section.\n\tsection_summary VARCHAR, -- A brief summary of the section content generated by LLM, focusing on key information and describing the section content.\n\tordinal INTEGER, -- Each section is labeled with one distinct integer number in the paper, which starts from 0.\n\tpage_numbers INTEGER[], -- A list of page numbers where current section is located in the relevant paper.\n\tref_paper_id UUID, -- A foreign key linking to the `paper_id` in the `metadata` table.,\n\tPRIMARY KEY (section_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id)\n);\n/* table equations: This table stores information about equations extracted from pages using MinerU.\n*/\nCREATE TABLE IF NOT EXISTS equations (\n\tequation_id UUID, -- A unique identifier for each equation.\n\tequation_content VARCHAR, -- Content of the equation in latex format.\n\tordinal INTEGER, -- Each equation is labeled with one distinct integer number in the current page, which starts from 0.\n\tref_paper_id UUID, -- A foreign key linking to the paper ID in the `metadata` table.\n\tref_page_id UUID, -- A foreign key linking to the page ID in the `pages` table where this equation is located.,\n\tPRIMARY KEY (equation_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id),\n\tFOREIGN KEY (ref_page_id) REFERENCES pages(page_id)\n);\n/* table reference: This table stores information about references extracted using MinerU.\n*/\nCREATE TABLE IF NOT EXISTS reference (\n\treference_id UUID, -- A unique identifier for each reference.\n\treference_content VARCHAR, -- Content of the reference.\n\tordinal INTEGER, -- Each reference is labeled with one distinct integer number according to its order in the paper, which starts from 0.\n\tref_paper_id UUID, -- A foreign key linking to the `paper_id` in the `metadata` table.\n\tref_page_id UUID, -- A foreign key linking to the `page_id` in the `pages` table where this reference is located.,\n\tPRIMARY KEY (reference_id),\n\tFOREIGN KEY (ref_paper_id) REFERENCES metadata(paper_id),\n\tFOREIGN KEY (ref_page_id) REFERENCES pages(page_id)\n);\n[Vectorstore Schema]: The vectorstore schema for ai_research is as follows. You can try collections with different encoding models or modalities:\n[\n    {\n        \"collection_name\": \"text_bm25_en\",\n        \"modality\": \"text\",\n        \"embed_type\": \"bm25\",\n        \"embed_model\": \"en\",\n        \"description\": \"This collection is used to store the sparse embeddings generated by the BM25 model for all encodable text content in another relational database. The similary search is based on field `vector` with metric inner-product (IP).\",\n        \"fields\": [\n            {\n                \"name\": \"id\",\n                \"dtype\": \"INT64\",\n                \"is_primary\": true,\n                \"description\": \"The unique id for each encoded text vector in this collection.\"\n            },\n            {\n                \"name\": \"vector\",\n                \"dtype\": \"SPARSE_FLOAT_VECTOR\",\n                \"description\": \"The encoded sparse vector of the text content generated by the BM25 model. Note that, the raw text content can be uniquely identified by the triplet fields below: `table_name`, `column_name`, `primary_key`.\"\n            },\n            {\n                \"name\": \"pdf_id\",\n                \"dtype\": \"VARCHAR\",\n                \"description\": \"The unique id of the PDF file stored in the relational database that the encoded text belongs to. This field can be used to quickly filter the search space.\"\n            },\n            {\n                \"name\": \"page_number\",\n                \"dtype\": \"INT16\",\n                \"description\": \"The page number in the PDF file that the encoded text belongs to (starting from 1). This field can be used to quickly filter the search space. Value -1 means unknown.\"\n            },\n            {\n                \"name\": \"table_name\",\n                \"dtype\": \"VARCHAR\",\n                \"description\": \"Which table in the relational database is the text content from.\"\n            },\n            {\n                \"name\": \"column_name\",\n                \"dtype\": \"VARCHAR\",\n                \"description\": \"Which column under `table_name` in the relational database is the text content from.\"\n            },\n            {\n                \"name\": \"primary_key\",\n                \"dtype\": \"VARCHAR\",\n                \"description\": \"The primary key value of `table_name` (or which row) in the relational database that the text content belongs to. Note that, the triplet (`table_name`, `column_name`, `primary_key`) can be used to construct a one-to-one mapping between the `text` field in the current vectorstore and the cell entry in the relational database.\"\n            }\n        ]\n    },\n    {\n        \"collection_name\": \"text_sentence_transformers_all_minilm_l6_v2\",\n        \"modality\": \"text\",\n        \"embed_type\": \"sentence_transformers\",\n        \"embed_model\": \"all-MiniLM-L6-v2\",\n        \"description\": \"This collection is used to store the embeddings generated by the all-MiniLM-L6-v2 model for all encodable text content in another relational database. The similary search is based on field `vector` with metric COSINE.\",\n        \"fields\": \"The fields of this collection are similar to the `text_bm25_en` collection.\"\n    }\n]\n\nThe following lists all encodable (table_name, column_name, encode_modality) information from the corresponding DuckDB database, where the encoded vector entries are sourced. Note that, for text modality, we directly encode cell values from the `table_name.column_name`; for image modality, we encode the cropped images for `page_number` in `pdf_id` with bounding boxes from `table_name.column_name`. You can leverage them for filter condition during similarity search:\n[\n    [\n        \"metadata\",\n        \"title\",\n        \"text\"\n    ],\n    [\n        \"metadata\",\n        \"abstract\",\n        \"text\"\n    ],\n    [\n        \"metadata\",\n        \"bibtex\",\n        \"text\"\n    ],\n    [\n        \"metadata\",\n        \"tldr\",\n        \"text\"\n    ],\n    [\n        \"pages\",\n        \"page_content\",\n        \"text\"\n    ],\n    [\n        \"pages\",\n        \"page_summary\",\n        \"text\"\n    ],\n    [\n        \"images\",\n        \"image_caption\",\n        \"text\"\n    ],\n    [\n        \"images\",\n        \"image_summary\",\n        \"text\"\n    ],\n    [\n        \"chunks\",\n        \"text_content\",\n        \"text\"\n    ],\n    [\n        \"tables\",\n        \"table_caption\",\n        \"text\"\n    ],\n    [\n        \"tables\",\n        \"table_content\",\n        \"text\"\n    ],\n    [\n        \"tables\",\n        \"table_summary\",\n        \"text\"\n    ],\n    [\n        \"sections\",\n        \"section_title\",\n        \"text\"\n    ],\n    [\n        \"sections\",\n        \"section_content\",\n        \"text\"\n    ],\n    [\n        \"sections\",\n        \"section_summary\",\n        \"text\"\n    ],\n    [\n        \"equations\",\n        \"equation_content\",\n        \"text\"\n    ],\n    [\n        \"reference\",\n        \"reference_content\",\n        \"text\"\n    ]\n]\n\nHere are the operators that you can use in the filtering condition for the vectorstore:\n{\n    \"operators\": {\n        \"logical\": [\n            {\n                \"symbol\": \"not\",\n                \"example\": \"not expr\",\n                \"description\": \"True if expr is false.\"\n            },\n            {\n                \"symbol\": \"and\",\n                \"example\": \"expr1 and expr2\",\n                \"description\": \"True if both expr1 and expr2 are true.\"\n            },\n            {\n                \"symbol\": \"or\",\n                \"example\": \"expr1 or expr2\",\n                \"description\": \"True if either expr1 or expr2 are true.\"\n            }\n        ],\n        \"binary arithmetic\": [\n            {\n                \"symbol\": \"+\",\n                \"example\": \"a + b\",\n                \"description\": \"Add the two operands.\"\n            },\n            {\n                \"symbol\": \"-\",\n                \"example\": \"a - b\",\n                \"description\": \"Subtract the second operand from the first operand.\"\n            },\n            {\n                \"symbol\": \"*\",\n                \"example\": \"a * b\",\n                \"description\": \"Multiply the two operands.\"\n            },\n            {\n                \"symbol\": \"/\",\n                \"example\": \"a / b\",\n                \"description\": \"Divide the first operand by the second operand.\"\n            },\n            {\n                \"symbol\": \"**\",\n                \"example\": \"a ** b\",\n                \"description\": \"Raise the first operand to the power of the second operand.\"\n            },\n            {\n                \"symbol\": \"%\",\n                \"example\": \"a % b\",\n                \"description\": \"Divide the first operand by the second operand and yield the remainder portion.\"\n            }\n        ],\n        \"relational\": [\n            {\n                \"symbol\": \"<\",\n                \"example\": \"a < b\",\n                \"description\": \"True if a is less than b.\"\n            },\n            {\n                \"symbol\": \">\",\n                \"example\": \"a > b\",\n                \"description\": \"True if a is greater than b.\"\n            },\n            {\n                \"symbol\": \"==\",\n                \"example\": \"a == b\",\n                \"description\": \"True if a is equal to b. Please use **two** equal signs for equality comparison.\"\n            },\n            {\n                \"symbol\": \"!=\",\n                \"example\": \"a != b\",\n                \"description\": \"True if a is not equal to b.\"\n            },\n            {\n                \"symbol\": \"<=\",\n                \"example\": \"a <= b\",\n                \"description\": \"True if a is less than or equal to b.\"\n            },\n            {\n                \"symbol\": \">=\",\n                \"example\": \"a >= b\",\n                \"description\": \"True if a is greater than or equal to b.\"\n            },\n            {\n                \"symbol\": \"in\",\n                \"example\": \"a in [b, c, ...]\",\n                \"description\": \"True if a is equal to any of the values in the list.\"\n            }\n        ],\n        \"array operations\": [\n            {\n                \"symbol\": \"[]\",\n                \"example\": \"bbox[0]\",\n                \"description\": \"This expression gets the first element in array bbox. For example, 'bbox[0] < 50' evaluates to true if the value of bbox[0] is less than 50.\"\n            },\n            {\n                \"symbol\": \"array_contains\",\n                \"example\": \"array_contains(bbox, 100)\",\n                \"description\": \"This expression evaluates to true if array bbox contains element 100.\"\n            },\n            {\n                \"symbol\": \"array_length\",\n                \"example\": \"array_length(int_array) == 4\",\n                \"description\": \"This expression evaluates to true if int_array contains exactly 4 elements.\"\n            }\n        ]\n    },\n    \"use cases\": [\n        {\n            \"example\": \"table_name == 'chunks' and column_name == 'text_content'\",\n            \"description\": \"Filter the results with table_name equal to 'chunks' and column_name equal to 'text_content'.\"\n        },\n        {\n            \"example\": \"table_name == 'chunks' and primary_key in ['123', '456', '789']\",\n            \"description\": \"Filter the results with table_name equal to 'chunks' and primary_key equal to any of the values in the list ['123', '456', '789'].\"\n        },\n        {\n            \"example\": \"bbox[0] + bbox[2] <= 100 and bbox[1] + bbox[3] <= 300 and pdf_id == '123456' and page_number == 1\",\n            \"description\": \"For image modality, filter results to include only image regions that are entirely within the upper-left quadrant of page 1 in the PDF with ID '123456', assuming the page dimensions are 200 (width) x 600 (height).\"\n        }\n    ]\n}"}
{"role": "assistant", "content": "[Thought]: First, I need to find the method that performs the best on ID states with full-chain setting in the paper \"Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning\". I will start by retrieving the relevant section or content from the paper using the paper ID.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"Introduction\",\"section_content\":\"Introduction\\nModel-based reinforcement learning (MBRL) has showcased its capability of solving various se-\\nquential decision making problems [23, 48]. Since learning accurate and robust dynamics model\\nis crucial in MBRL, recent works incorporate the causal relationships between the variables into\\ndynamics learning [13, 59]. Unlike the traditional dense models that employ the whole state and\\naction variables to predict the future state, causal dynamics models utilize only relevant variables by\\nexamining conditional independences. As a result, they are more robust to spurious correlations and\\ngeneralize well to unseen states by discarding unnecessary dependencies.\\nOur motivation stems from the observation that the dependencies between the variables often exist\\nonly under certain circumstances in many practical scenarios. For instance, in the context of\\nautonomous driving, a lane change is contingent on the absence of nearby cars within a specific\\ndistance range. Thus, it is crucial for autonomous vehicles to recognize and understand circumstances\\nin which lane changes do or do not affect other vehicles. Our hypothesis is that the agent capable of\\nreasoning such fine-grained causal relationships would generalize well to downstream tasks.\\nIn this work, we aim to incorporate local independence relationship between the variables, which\\nholds under certain contexts but does not hold in general [5], into dynamics modeling for improving\\n\\u2217Corresponding authors.\\nNeurIPS 2023 Workshop on Generalization in Planning (GenPlan 2023).\\n(a)                   (b)                         (c)                                                        (d)\\n<latexit sha1_base64=\\\"m9iHAv9KiC4kj6ms0spC2L8\\nVFQg=\\\">ACBXicbVDLSsNAFJ34rPUVdamLYBFclUTqY1lx47KifUATymQ6aYdOJmHmRighGzf+ihsXirj1H9z5N\\n07aINp64MLhnHu59x4\\/5kyBbX8ZC4tLyurpbXy+sbm1ra5s9tSUSIJbZKIR7LjY0U5E7QJDjtxJLi0Oe07Y+uc\\nr9T6VikbiDcUy9EA8ECxjBoKWeCGIYE8\\/Q2c4GFVP0Il1nPrNhVewJrnjgFqaACjZ756fYjkoRUAOFYqa5jx\\n+ClWAIjnGZlN1E0xmSEB7SrqcB6n5dOvsisI630rSCSugRYE\\/X3RIpDpcahrzvzE9Wsl4v\\/ed0EgsvZSJOgAoyX\\nRQk3ILIyiOx+kxSAnysCSaS6VstMsQSE9DBlXUIzuzL86R1UnXOqc3tUq9VsRQvoEB0jB52jOrpGDdREBD2gJ\\/\\nSCXo1H49l4M96nrQtGMbOH\\/sD4+AZ9mJkt<\\/latexit>S \\u21e5A\\nFigure 1: Comparison of different types of dynamics models. (a) Dense models employ the whole\\nstate and action variables for prediction. (b) Causal models examine conditional independences\\nto discard unnecessary dependencies (red arrows in (a)). (c) Sample-specific approaches estimate\\nvariable dependencies on a per-sample basis. (d) Our model decomposes the data domain and infers\\nfine-grained causal relationships on each event to use only locally relevant variables for prediction.\\nrobustness and generalization in MBRL. Unfortunately, prior causal dynamics models examining\\nconditional independences are not capable of harnessing them. An alternative way is to estimate vari-\\nables dependencies for each individual sample [21, 41]. However, such sample-specific approaches\\ndo not explicitly capture meaningful contexts that exhibit fine-grained causal relationships, making\\nthem prone to overfitting and less robust on unseen states.\\nContribution. We present a new causal dynamics model that (i) decomposes the data domain\\ninto subgroups which we call events, (ii) discovers local independences under each event, and (iii)\\nemploys only locally relevant variables for prediction (Fig. 1). Clearly, it is crucial to discover\\nmeaningful context for robust and fine-grained dynamics modeling. For this, we formulate the\\nproblem of finding a decomposition that maximizes the regularized maximum likelihood score and\\nshow that the optimal decomposition identifies a meaningful context that exhibits fine-grained causal\\nrelationships. A main challenge is that this involves three nested subtasks: discovering decomposition,\\nexamining local independences, and learning dynamics model. To this end, we propose a practical\\ngradient-based method to learn a discrete latent codebook utilizing vector quantization, which enables\\nthe joint optimization differentiable, allowing efficient end-to-end training (Fig. 2). As a result, our\\nmethod incorporates fine-grained causal relationships into dynamics modeling, leading to improved\\nrobustness in MBRL over prior causal dynamics models.\\nWe empirically validate the effectiveness of our method on both discrete and continuous control envi-\\nronments. For the evaluation, we measure the performance of dynamics models on the downstream\\ntasks that require fine-grained causal reasoning. Experimental results demonstrate the effectiveness\\nof our method for fine-grained causal reasoning which improves robustness and generalization in\\nMBRL. Detailed analysis of our method shows that it successfully discovers meaningful contexts and\\nrecovers fine-grained causal relationships.\\n2\"}\n{\"section_title\":\"Preliminaries\",\"section_content\":\"Preliminaries\\nWe first briefly introduce the notations and terminologies used throughout the paper. Then, we\\nexamine related works on causal dynamics learning for RL and fine-grained causal relationships.\\n2.1\\nBackground\\nStructural causal model. We adopt a framework of a structural causal model (SCM) [39] to\\nunderstand the relationship among variables in transition dynamics. An SCM M is defined as a\\ntuple\\n\\nV, U, F, P(U)\\n\\u000b\\n, where V = {X1, \\u00b7 \\u00b7 \\u00b7 , Xd} is a set of endogenous variables and U is a\\nset of exogenous variables. A set of functions F = {f1, \\u00b7 \\u00b7 \\u00b7 , fd} determine how each variable is\\ngenerated; Xj = fj(Pa(j), Uj) where Pa(j) \\u2286V \\\\ {Xj} is parents of Xj and Uj \\u2286U. An\\nSCM M induces a directed acyclic graph (DAG) G = (V, E), i.e., a causal graph (CG) [40], where\\nV = {1, . . . , d} and E \\u2286V \\u00d7 V are the set of nodes and edges, respectively. Each edge (i, j) \\u2208E\\ndenotes a direct causal relationship from Xi to Xj. An SCM and its corresponding causal graph\\n2\\nentail the conditional independence relationship of each variable (namely, local Markov property):\\nXi \\u22a5\\n\\u22a5ND(Xi) | Pa(Xi), where ND(Xi) is a non-descendant of Xi.\\nFactored Markov Decision Process. A Markov Decision Process (MDP) [52] is defined as a tuple\\n\\u27e8S, A, T, r, \\u03b3\\u27e9where S is a state space, A is an action space, T : S \\u00d7 A \\u2192P(S) is a transition\\ndynamics, r is a reward function, and \\u03b3 is a discount factor. We consider a factored MDP [25] where\\nthe state and action spaces are factorized as S = S1 \\u00d7 \\u00b7 \\u00b7 \\u00b7 \\u00d7 SN and A = A1 \\u00d7 \\u00b7 \\u00b7 \\u00b7 \\u00d7 AM, and a\\nsingle-step transition dynamics is factorized as p(s\\u2032 | s, a) = Q\\nj p(s\\u2032\\nj | s, a) where s = (s1, \\u00b7 \\u00b7 \\u00b7 , sN)\\nand a = (a1, \\u00b7 \\u00b7 \\u00b7 , aM).\\nAssumptions and notations. We are concerned with an SCM associated with the transition dynamics\\nin a factored MDP where we assume that states are fully observable. To properly identify the\\ncausal relationships in MBRL, we make assumptions standard in the field [13, 41, 42, 49, 58, 59],\\nnamely, Markov property [39], faithfulness [40], causal sufficiency [51], and that causal connections\\nonly appear within consecutive time steps (i.e., t \\u2192t + 1). Throughout the paper, a causal graph\\nG = (V, E) consists of the set of nodes V = X \\u222aY and the set of edges E \\u2286X \\u00d7 Y, where\\nX = {S1, \\u00b7 \\u00b7 \\u00b7 , SN, A1, \\u00b7 \\u00b7 \\u00b7 , AM} and Y = {S\\u2032\\n1, \\u00b7 \\u00b7 \\u00b7 , S\\u2032\\nN}. Pa(j) denotes parent variables of S\\u2032\\nj.\\nWith these assumptions, the conditional independences\\nS\\u2032\\nj \\u22a5\\n\\u22a5X \\\\ Pa(j) | Pa(j)\\n(1)\\nentailed by the causal graph faithfully represent the causal relationships between the variables and\\nthe transition dynamics is factorized as p(s\\u2032 | s, a) = Q\\nj p(s\\u2032\\nj | s, a) = Q\\nj p(s\\u2032\\nj | Pa(j)).\\nDynamics modeling. Traditional dynamics models use the whole state and action variables to\\npredict the future state, i.e., modeling Q\\nj p(s\\u2032\\nj | s, a). Prior causal dynamics models [13, 58, 59]\\nexamine conditional independences to recover causal relationships and employ only parent variables\\nfor prediction, i.e., modeling Q\\nj p(s\\u2032\\nj | Pa(j)). Consequently, causal dynamics models are more\\nrobust to unseen states by discarding unnecessary dependencies. In this work, we infer fine-grained\\ncausal relationships by discovering local independences and use potentially fewer dependencies for\\ndynamics modeling, as shown in Fig. 1.\\n2.2\\nRelated Work\\nCausal dynamics models in RL. There is a growing body of literature on the intersection of causality\\nand RL [7, 12, 47, 50, 63, 64, 66]. One focus is causal dynamics learning, which aims to infer the\\ncausal structure of the underlying transition dynamics [4, 13, 14, 20, 29, 59, 61] (more broad literature\\nof causal reasoning in RL is discussed in Appendix A.1). Given the explicit state and action variables\\nin factored MDP, recent works utilize gradient-based causal discovery algorithm [6, 58], conditional\\nindependence tests [13], or conditional mutual information [59] to infer the causal graph and train\\nthe dynamics model with the inferred causal graph by using only relevant variables for prediction.\\nIn contrast, our method infers fine-grained causal relationships by discovering local independences.\\nThus, our approach provides a more detailed understanding of the dynamics, leading to improved\\nrobustness and generalization over the prior causal dynamics models.\\nDiscovering fine-grained causal relationships. The fine-grained causal relationships have been\\nutilized to improve RL performance in various ways, e.g., with data augmentation [42], efficient\\nplanning [9, 18], or exploration [49]. Previous works exploited prior knowledge of them [42], or\\nleveraged the true dynamics model explicitly [9]. Without those prior information, Pitis et al. [41]\\ndevised an transformer-based model to estimate the variable dependencies for each sample by using\\nattention score. Another line of work learn sparse and modular dynamics [15\\u201317], which can be\\nviewed as an implicit approach to discovering local independence relationships. In the field of\\ncausality, local independence relationship has been widely studied especially for discrete variables,\\ne.g., context-specific independence [5, 11, 43, 54, 65] (see Appendix A.2 for the background on\\nlocal independence). Recently, NCD [21] proposed a gradient-based method to discover local\\nindependences allowing continuous variables. While it also infers local independences on a per-\\nsample basis, our method infers local independences per event, i.e., subgroup of the data domain,\\nwhich helps prevent overfitting to individual samples and allows more robust causal modeling.\\n3\\n3\"}\n\n... # only display 2 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The introduction and preliminaries sections do not contain the specific information about the method that performs the best on ID states with full-chain setting. I will now retrieve the experimental results section to find this information.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Experimental Results%';\")"}
{"role": "user", "content": "[Observation]: [Warning]: The SQL execution result is empty, please check the SQL first."}
{"role": "assistant", "content": "[Thought]: The SQL query did not return any results, which means the section title might not be exactly \"Experimental Results\". I will perform a similarity search in the vectorstore to find the relevant section.\n[Action]:\nClassicRetrieve(query=\"Experimental Results in the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning'\", limit=5)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.8971,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.865,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.7615,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.7264,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"92aa57d6-2e10-527c-bc0b-fcf219bcdf16\",\"text\":\"in reinforcement learning (RL). Recent studies have focused on examining con-\\nditional independences and leveraging only relevant state and action variables\\nfor prediction. However, such approaches tend to overlook local independence\\nrelationships that hold under certain circumstances referred as event. In this work,\\nwe present a theoretically-grounded and practical approach to dynamics learning\\nwhich discovers such meaningful events and infers fine-grained causal relation-\"}\n{\"score\":0.7158,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n\nIn total, 5 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The similarity search returned several chunks, but none of them seem to contain the specific experimental results. I will try to retrieve the sections with titles that might be related to experiments or results.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND (sections.section_title LIKE '%Experiment%' OR sections.section_title LIKE '%Result%');\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"Experiments\",\"section_content\":\"Experiments\\nIn this section, we evaluate our method to examine the following questions: (1) Does our dynamics\\nmodel improves robustness and generalization of MBRL? (Tables 1 and 2); (2) Does our method\\ncapture a meaningful context and fine-grained causal relationships? (Figs. 4 and 5); and (3) How\\ndoes the choice of K affect performance? (Table 3)\\n4.1\\nExperimental Setup\\nThe environments are designed to exhibit fine-grained causal relationships on a particular context, and\\nexplicit state variables are given as the observation to the agent (e.g., position, velocity), following\\n6\\nFull\\nChain\\nFork\\n(a) CHEMICAL\\n(b) MAGNETIC\\nFigure 3: Illustrations for each environment. (a) In Chemical, colors change by the action according\\nto the underlying causal graph. (b) In Magnetic, the red object exhibits magnetism. (b-left) The box\\nattracts the ball via magnetic force. (b-right) The box does not have an influence on the ball.\\nprior works [13, 41, 42, 49, 59]. Detailed descriptions for each environment and setup are provided\\nin Appendix C.1.\\n4.1.1\\nEnvironments\\nChemical. In the Chemical [24] environment, there are 10 nodes where each node is colored with\\none of 5 colors, and an action is setting the color of a node. According to the underlying causal graph,\\nan action changes the colors of the intervened object\\u2019s descendants as depicted in Fig. 3(a). The\\ntask is to match the colors of each node to the given target. We design two settings, named full-fork\\nand full-chain: the underlying causal graph is both full, and the local causal graph is fork and chain,\\nrespectively. For example, in full-fork, local causal graph fork corresponds to the context where the\\ncolor of the root node is red. In other words, for each node, all other parent nodes except the root\\nbecome irrelevant according to the particular color of the root node. During the test, the root color\\nis set to activate local causal graph. Here, the agent receives a noisy observation for some nodes\\n(except the root) and the task is to match the colors of other observable nodes. The agent capable of\\nfine-grained causal reasoning would generalize well since corrupted nodes are locally spurious to\\ninfer the colors of other nodes, as depicted in Appendix C.1 (Fig. 6).\\nMagnetic. We design the robot arm manipulation environment based on the Robosuite framework\\n[67]. There is a moving ball and a box on the table, colored red or black (Fig. 3(b)). Red color\\nindicates that the object is magnetic, and attracts the other magnetic object. For example, when\\nthey are both colored red, magnetic force will be applied, and the ball will move toward the box.\\nOtherwise, the box would have no influence on the ball. The task is to move the robot arm to reach\\nthe ball predicting its trajectory. The color and position of the objects are randomly initialized\\nfor each episode. During the test, one of the objects is black, and the box is located at an unseen\\nposition. Since the position of the box is unnecessary for predicting the movement of the ball under\\nnon-magnetic context, the agent aware of the fine-grained causal relationships would generalize well\\nto unseen out-of-distribution (OOD) states.\\n4.1.2\\nBaselines\\nWe first consider traditional dense models, i.e., a monolithic network implemented as multi-layer\\nperceptron (MLP) which approximates the dynamics p(s\\u2032 | s, a), and a modular network which has a\\nseparate network for each variable: Q\\nj p(s\\u2032\\nj | s, a). In addition, we include a graph neural network\\n(GNN) [27] and NPS [15]. GNN learns the relational information between variables and NPS learns\\nsparse and modular dynamics. Causal models, including CDL [59] and GRADER [13], infer causal\\nrelationships between the variables for dynamics learning: Q\\nj p(s\\u2032\\nj | Pa(j)), utilizing conditional\\nmutual information and conditional independence test, respectively. We also include an oracle causal\\nmodel, which leverages the ground truth (global) causal graph. Finally, we compare to a local causal\\nmodel, NCD [21], which infers the variable dependencies for each sample.\\nPlanning algorithm. For all baselines and our method, we use a model predictive control (MPC) [8]\\nwhich selects the actions based on the prediction of the learned dynamics model. Specifically, we use\\nthe cross-entropy method (CEM) [46], which iteratively generates and optimizes action sequences.\\nImplementation. For the implementation of our method, we set the codebook size of K = 16, the\\nregularization coefficient \\u03bb = 0.001, and the commitment coefficient \\u03b2 = 0.25 in all experiments. For\\n7\\nTable 1: Average episode reward on training and downstream tasks in each environment. In Chemical,\\nn denotes the number of noisy nodes in downstream tasks.\\nChemical (full-fork)\\nChemical (full-chain)\\nMagnetic\\nMethods\\nTrain\\n(n = 0)\\nTest\\n(n = 2)\\nTest\\n(n = 4)\\nTest\\n(n = 6)\\nTrain\\n(n = 0)\\nTest\\n(n = 2)\\nTest\\n(n = 4)\\nTest\\n(n = 6)\\nTrain\\nTest\\nMLP\\n19.00\\u00b10.83\\n6.49\\u00b10.48\\n5.93\\u00b10.71\\n6.84\\u00b11.17\\n17.91\\u00b10.87\\n7.39\\u00b10.65\\n6.63\\u00b10.58\\n6.78\\u00b10.93\\n8.37\\u00b10.74\\n0.86\\u00b10.45\\nModular\\n18.55\\u00b11.00\\n6.05\\u00b10.70\\n5.65\\u00b10.50\\n6.43\\u00b11.00\\n17.37\\u00b11.63\\n6.61\\u00b10.63\\n7.01\\u00b10.55\\n7.04\\u00b11.07\\n8.45\\u00b10.80\\n0.88\\u00b10.52\\nGNN [27]\\n18.60\\u00b11.19\\n6.61\\u00b10.92\\n6.15\\u00b10.74\\n6.95\\u00b10.78\\n16.97\\u00b11.85\\n6.89\\u00b10.28\\n6.38\\u00b10.28\\n6.56\\u00b10.53\\n8.53\\u00b10.83\\n0.92\\u00b10.51\\nNPS [15]\\n7.71\\u00b11.22\\n5.82\\u00b10.83\\n5.75\\u00b10.57\\n5.54\\u00b10.80\\n8.20\\u00b10.54\\n6.92\\u00b11.03\\n6.88\\u00b10.79\\n6.80\\u00b10.39\\n3.13\\u00b11.00\\n0.91\\u00b10.69\\nCDL [59]\\n18.95\\u00b11.40\\n9.37\\u00b11.33\\n8.23\\u00b10.40\\n9.50\\u00b11.18\\n17.95\\u00b10.83\\n8.71\\u00b10.55\\n8.65\\u00b10.38\\n10.23\\u00b10.50\\n8.75\\u00b10.69\\n1.10\\u00b10.67\\nGRADER [13]\\n18.65\\u00b10.98\\n9.27\\u00b11.31\\n8.79\\u00b10.65\\n10.61\\u00b11.31\\n17.71\\u00b10.54\\n8.69\\u00b10.56\\n8.75\\u00b10.80\\n10.14\\u00b10.33\\n-\\n-\\nOracle\\n19.64\\u00b11.18\\n7.83\\u00b10.87\\n8.04\\u00b10.62\\n9.66\\u00b10.21\\n17.79\\u00b10.76\\n8.47\\u00b10.69\\n8.85\\u00b10.78\\n10.29\\u00b10.37\\n8.42\\u00b10.86\\n0.95\\u00b10.55\\nNCD [21]\\n19.30\\u00b10.95\\n10.95\\u00b11.63\\n9.11\\u00b10.63\\n10.32\\u00b10.93\\n18.27\\u00b10.27\\n9.60\\u00b11.52\\n8.86\\u00b10.23\\n10.32\\u00b10.37\\n8.48\\u00b10.70\\n1.31\\u00b10.77\\nOurs\\n19.28\\u00b10.87\\n15.27\\u00b12.53\\n14.73\\u00b11.68\\n13.62\\u00b12.56\\n17.22\\u00b10.61\\n13.36\\u00b13.60\\n12.35\\u00b13.23\\n12.00\\u00b11.21\\n8.52\\u00b10.74\\n4.81\\u00b13.01\\nTable 2: Prediction accuracy on ID (n = 0) and OOD (n = 2, 4, 6) states in Chemical environment.\\nSetting\\nMLP\\nModular\\nGNN [27]\\nNPS [15]\\nCDL [59]\\nGRADER [13]\\nOracle\\nNCD [21]\\nOurs\\nfull\\n-fork\\n(n = 0)\\n88.31\\u00b11.58\\n89.24\\u00b11.52\\n88.81\\u00b11.44\\n58.34\\u00b12.08\\n89.22\\u00b11.67\\n87.75\\u00b11.64\\n89.63\\u00b11.62\\n90.07\\u00b11.22\\n89.46\\u00b11.40\\n(n = 2)\\n31.11\\u00b11.69\\n26.53\\u00b13.45\\n36.29\\u00b13.45\\n40.56\\u00b14.61\\n35.59\\u00b11.85\\n37.93\\u00b11.06\\n33.87\\u00b11.34\\n41.60\\u00b15.08\\n66.44\\u00b112.22\\n(n = 4)\\n30.44\\u00b12.28\\n24.73\\u00b15.61\\n25.80\\u00b13.48\\n26.81\\u00b14.37\\n35.82\\u00b11.40\\n38.94\\u00b11.63\\n36.48\\u00b11.80\\n37.47\\u00b12.13\\n58.49\\u00b110.20\\n(n = 6)\\n32.39\\u00b11.76\\n26.73\\u00b18.31\\n21.58\\u00b13.44\\n23.02\\u00b14.27\\n42.22\\u00b11.39\\n45.74\\u00b12.25\\n42.47\\u00b10.75\\n42.27\\u00b11.82\\n49.09\\u00b14.77\\nfull\\n-chain\\n(n = 0)\\n84.38\\u00b11.31\\n85.92\\u00b11.15\\n85.41\\u00b11.84\\n58.48\\u00b12.81\\n86.85\\u00b11.47\\n84.24\\u00b11.22\\n85.76\\u00b11.56\\n85.63\\u00b11.01\\n86.07\\u00b11.62\\n(n = 2)\\n28.66\\u00b13.65\\n25.24\\u00b14.68\\n29.22\\u00b13.39\\n38.73\\u00b12.63\\n34.90\\u00b11.59\\n36.82\\u00b13.12\\n34.63\\u00b11.78\\n40.04\\u00b16.21\\n60.34\\u00b112.10\\n(n = 4)\\n26.52\\u00b14.26\\n24.94\\u00b14.81\\n23.28\\u00b14.98\\n27.69\\u00b14.28\\n36.52\\u00b11.72\\n37.41\\u00b12.84\\n38.31\\u00b12.48\\n37.47\\u00b12.98\\n56.64\\u00b19.40\\n(n = 6)\\n24.15\\u00b14.17\\n25.09\\u00b15.91\\n20.53\\u00b16.96\\n24.45\\u00b13.84\\n42.06\\u00b11.29\\n43.48\\u00b14.14\\n42.87\\u00b12.08\\n41.19\\u00b11.66\\n53.29\\u00b16.63\\nthe oracle causal model, we used the same network architecture as ours, to isolate the effect of learning\\nfine-grained causal relationships. All methods have a similar number of model parameters for a fair\\ncomparison. For the evaluation, we ran 10 test episodes for every 40 training episodes. The results are\\naveraged over eight different runs. Implementation details are provided in Appendix C.2. Learning\\ncurves for all downstream tasks with additional experimental results are shown in Appendix C.3.\\n4.2\\nDownstream task performance\\nTable 1 demonstrate the downstream task performance of our method and baselines. While all\\nthe methods show similar performance in training, dense models suffer from OOD states in the\\ndownstream tasks. Causal models are generally more robust compared to dense models, as they\\ninfer the causal graph to discard irrelevant dependencies. Our method significantly outperforms\\nthe baselines in all downstream tasks, which implies that our method is capable of fine-grained\\ncausal reasoning and generalize well to unseen states. To investigate the robustness of our method\\nin downstream tasks, we examine the prediction accuracy on in-distribution (ID) states, and OOD\\nstates in Chemical environment (Table 2). While all methods show similar prediction accuracy on\\nID states, the baselines show a significant performance drop under the presence of noisy variables,\\nmerely above 20% which is an expected accuracy of random guessing. In contrast, our method\\nconsistently outperforms the baselines by a large margin, which implies that it successfully captures\\nthe fine-grained causal relationships. These results demonstrates the effectiveness of our method for\\nfine-grained causal reasoning which improves robustness and generalization in MBRL.\\n4.3\\nDetailed analysis\\nInferred LCGs. We closely examine the discovered local causal graphs in Chemical (full-fork) to\\nbetter understand our model\\u2019s behavior (Fig. 4). Recall each code corresponds to the pair of event\\nand LCG, we observe that all codes are used during training (Fig. 4(a)), but only a few of them are\\nexploited during the test (Fig. 4(b)). The most commonly inferred LCG on OOD states during the\\ntest corresponds to a fork structure, as shown in Figs. 4(c) and 4(d). This implies that our method\\nsuccessfully identifies the meaningful context that exhibits fine-grained causal relationships.\\nComparison with sample-specific approach. In Fig. 5, we examine the LCGs to further analyze the\\nimproved robustness of our approach compared to a sample-specific approach that does not explicitly\\ncapture meaningful events. As shown in Fig. 5(b), our method learns a proper LCG during training,\\nand the inference is consistent in both ID and OOD states on non-magnetic context. In contrast, as\\nshown in Figs. 5(c) and 5(d), the inference of sample-specific approach is inconsistent between ID\\nand OOD states on the same non-magnetic context. This is because sample-specific approach infers\\n8\\n(a)\\n(b)\\n(c)\\n(d)\\nFigure 4: (a,b) Codebook histogram on (a) ID states during training and (b) OOD states during the test\\nin Chemical (full-fork). (c) True causal graph of the fork structure. (d) Learned LCG corresponding\\nto the most used code in (b).\\n(a)\\n(b)\\n(c)\\n(d)\\nFigure 5: (a) Causal graph identified by our method in Magnetic. Red boxes indicate locally irrelevant\\nedges under the non-magnetic event. (b-d) LCGs corresponding to the non-magnetic event inferred\\nby (b) our method, and NCD on (c) ID and (d) OOD state.\\nthe variable dependencies for each sample, and this incurs overfitting which makes the inference on\\nOOD states inconsistent. As opposed to sample-specific approach, our method learns an LCG for\\neach event, leading to the robust inference on OOD states.\\nTable 3: Ablation on codebook size.\\nChemical (full-fork)\\nMethods\\n(n = 2)\\n(n = 4)\\n(n = 6)\\nCDL [59]\\n9.37\\u00b11.33\\n8.23\\u00b10.40\\n9.50\\u00b11.18\\nOracle\\n7.83\\u00b10.87\\n8.04\\u00b10.62\\n9.66\\u00b10.21\\nNCD [21]\\n10.95\\u00b11.63\\n9.11\\u00b10.63\\n10.32\\u00b10.93\\nOurs (K = 2)\\n13.44\\u00b15.41\\n12.86\\u00b15.58\\n12.99\\u00b15.27\\nOurs (K = 4)\\n15.73\\u00b14.13\\n16.50\\u00b13.40\\n12.40\\u00b12.81\\nOurs (K = 8)\\n14.95\\u00b11.16\\n15.03\\u00b12.61\\n13.42\\u00b12.67\\nOurs (K = 16)\\n15.27\\u00b12.53\\n14.73\\u00b11.68\\n13.62\\u00b12.56\\nOurs (K = 32)\\n16.12\\u00b11.43\\n14.35\\u00b11.37\\n14.79\\u00b12.13\\nAblation on the codebook size. We first recall that\\nthe codebook size K represents the size of the decom-\\nposition. As shown in Table 3, our method works rea-\\nsonably well with any choice of K and consistently\\noutperforms baselines. Finally, as we described earlier,\\nour method with K = 1 degenerates to prior causal\\ndynamics model and cannot capture fine-grained causal\\nrelationships. This is shown in Fig. 5(a) that our method\\nwith K = 1 recovers the causal graph including locally\\nirrelevant edges under the non-magnetic context.\\n5\"}\n\n... # only display 1 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The \"Experiments\" section contains the information about the method that performs the best on ID states with full-chain setting. From Table 1, it appears that the method \"Ours\" performs the best in the full-chain setting. Now, I will look for the reason why -inf appears in Fig. 3.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Discussion%' OR sections.section_title LIKE '%Analysis%';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"Analysis and Discussion\",\"section_content\":\"ANALYSIS AND DISCUSSION\\nAccuracy. Our model competes favorably with DFCAN on the BioSR dataset, particularly excelling\\nin image resolution (Table 1). It shows the versatility of diffusion models in generating realistic solu-\\ntions across diverse phenomena. Additionally, it outperforms CDDPM in more complex biological\\nstructures, and it advances significantly in the QPI problem by overcoming noise challenges near the\\nsingularity (Wu et al., 2022). While not designed specifically for these tasks, our approach shows\\npromise as a flexible tool for solving inverse problems with available input-data pair samples.\\nSchedule. As explained in Section 1, the schedule is a key parameter for diffusion models, so we aim\\nto understand whether our method yields reasonable values. Based on the relation between \\u03b3 and \\u03b2 ,\\n8\\nPublished as a conference paper at ICLR 2024\\n(a)\\nSample mean\\nSample standard\\ndeviation\\n(b)\\nFigure 2: Schedules and sample mean and deviations for the represented images from the BioSR\\ndataset. (a) Schedule (\\u03b2) values for a microtubule image. The graph shows the average of the pixels\\nin the respective region. (b) Mean and standard deviations for microtubule (top row) and endoplasmic\\nreticulum (bottom row). The images were reconstructed using 20 samples obtained with CVDM.\\nthe forward model can be parametrized as (details in Appendix J):\\nq(zt|y, x) = N\\n\\u0010\\ne\\u22121\\n2\\nR t\\n0 \\u03b2(s,x)dsy,\\n\\u0010\\n1 \\u2212e\\u2212\\nR t\\n0 \\u03b2(s,x)ds\\u0011\\nI\\n\\u0011\\n.\\nWe can see that for large values of \\u03b2, the latent variable zt gets rapidly close to a N(0, I) distribution.\\nFor small values of \\u03b2, on the other hand, zt remains closer to y for longer. In general, a steeper\\ngraph of \\u03b2 results in a diffusion process that adds noise more abruptly around the middle timesteps,\\nresulting in more difficult inversion of the process. In our image-based data applications, the pixel-\\nwise dedicated schedule supports this analytical insight. In BioSR (Figure 2a), structure pixels (i.e.,\\npixels with high-frequency information) are more difficult to denoise, which is reflected in the steeper\\n\\u03b2 graph. In contrast, background pixels (i.e., pixels with low-frequency information) are easier to\\nresolve. This is consistent with the diffraction limit in optical microscopy, which mostly consists of\\nlow frequencies. Conversely, in QPI background pixels have a steeper \\u03b2 graph, a phenomenon linked\\nto the amplification of low-frequency noise around the singularity point in k-space (Wu et al., 2022).\\nUncertainty. In our experiments, we measure the uncertainty of the reconstruction by the pixel-wise\\nvariance on the model predictions. This uncertainty is theoretically tied to \\u03b2. As described in\\nSong et al. (2021), the reverse diffusion process can be characterized by a stochastic differential\\nequation with a diffusion coefficient of\\np\\n\\u03b2(t, x) (in the variance-preserving case). Hence, higher\\nvalues of \\u03b2 introduce more diffusion into the reverse process over time, leading to more varied\\nreconstructions. For BioSR, structure pixels exhibit higher values of \\u03b2 and consequently higher\\nreconstruction variance, as seen in Figure 2b. For QPI, the converse phenomenon is true (Figure 12).\\nFor further analysis and illustration of uncertainty, see Appendix M.\\n6\"}\n{\"section_title\":\"5 Analysis and Discussion\",\"section_content\":\"Human evaluation. Following common practice in the feld of summarization, we set up a human evaluation process to assess the quality of the system-generated summaries. The annotation task, performed by an expert English speaker, consists of reading the source text and rating the summaries using a Likert scale for Consistency, Relevance, Fluency, and Coherence, as outlined in Fabbri et al. (2021). To make this experiment feasible in terms of time and resources, we focus our evaluation on fairy tales and short stories, which can be read by a human in a short time. Interestingly, but not surprisingly (Fabbri et al., 2021), the results of our human evaluation experiment tell a story that is different from ROUGE, as shown in Tables 4 and 5. However, the evaluation still highlights the effectiveness of our extractive-then-abstractive model compared to the recursive-abstractive baseline. It is clear, however, that future work should focus in particular on improving the Consistency and Relevance of the summaries generated.\\nChallenges. Echoes opens the door to several other analyses and experiments that were not possible with previous datasets. For example, we can leverage Echo-FairySum to perform an analysis of the behavior of the extractor submodule of our extractive-then-abstractive approach, as we show in Appendix D. In Section 3.4, we examined the different book genres in Echoes; LongT5 model performances are detailed for each genre in Figure 3. We notice that epic poems are the hardest to summarize in this setting, while our model performs reasonably well on fairy tales.\\nCross-lingual book summarization. Additionally, Echoes can be employed as a multilingual and cross-lingual summarization benchmark, thanks to its coverage of 5 languages and 25 language pairs. In particular, we argue that cross-lingual book summarization is a very interesting challenge, as it requires a model to compress vast amounts of information while transferring knowledge across languages. Moreover, enabling cross-lingual book summarization is fundamental for all those cases in which we do not have the source text available in the language of interest, i.e., its translation may still be under copyright or may not exist at all. To move the frst step in this direction, we propose a summarize-then-translate approach, a simple baseline for cross-lingual book summarization on EchoXSum. As the name implies, our approach works by employing a monolingual model to produce a summary in the same language as the source text, and then it translates the summary from the source language to the desired target language. We report the results of this baseline in Table 7. While this is a strong baseline, it is still affected by two main issues: i) it requires two systems, a summarizer and a translator; ii) machine translation usually fails to translate language-specifc items, e.g., character names may not be exact translations.\"}\n{\"section_title\":\"4 Results and Analysis\",\"section_content\":\"We summarize the observations and analysis of the results from our experiments 4 as follows:\\nMATE excels at both in-domain and out-ofdomain generalization: Table 1 summarizes the performance of the proposed MATE and multiple baseline models, under various settings, across in-domain and OOD datasets. Overall, we observe that our proposed approach (row 8) signifcantly outperforms text-only baseline (row 3) on in-domain datasets indicating that audio information helps even when we have suffcient target domain corpus for fne-tuning. Furthermore, results on OOD datasets indicate that MATE generalizes much better to new domains in the complete absence of domain data (zero-shot setting), when compared to the text-only baseline, by utilizing the rich information from audio.\\nMLMs are more effective multi-modal rescorers than autoregressive LMs: Rows 2-5 indicate a signifcant performance gap between BERT and autoregressive rescorers (LAS\\/GPT-2). BERT-Text, which is a text-only baseline, outperforms even the multi-modal GPT2 indicating the root cause of the gap is the lack of bi-directional (left and right) context in GPT2 which is necessary for reliable and effective LLM scoring, hence validating the choice of MLM in MATE.\\n\\nAlignment loss gives signifcant performance boost: To study the effect of alignment loss, we train the multi-modal rescorer with two loss functions: Mean squared error (MSE) loss and contrastive loss. Signifcant performance gains (row 6 vs. row 7-8) in Table 1 indicate that explicit alignment techniques greatly improve learning of multimodal representations. Specifcally, contrastive loss not only aligns relevant pairs like MSE loss, but also promotes distancing irrelevant samples, leading to improved generalization on OOD sets.\\nParameter-effcient fne-tuning results in limited gains: Rows 9-11 study the performance of a multi-modal rescorer under different parameter effcient fne-tuning settings. We observe that performance degrades as we move from full fnetuning to adapter-tuning and freezing the full BERT encoder layers, indicating that fne-tuning BERT encoder is the most benefcial in terms of performance improvement. As expected, in comparison to model with full fne-tuning (row 6), rows 9-11 exhibit lower performance. This suggests that frozen or parameter-effcient training methods may lack the model capacity to fully leverage the acoustic information present in the multi-modal data.\\nMATE is the most effective few-shot learner: To study the effect of few-shot learning, we plot the relative WER reduction (WERR) on Voxpopuli and WSJ datasets across different resource conditions as shown in Figure 2. We observe that MATE transfers well to the new domains in the zero-shot setting with no training or domain data at all. Fewshot performance clearly improves with more examples and goes a reasonable way towards closing the gap from zero-shot performance to full fnetuning performance. We also observe that MATE consistently has superior performance to text-only baseline across both datasets, confrming the ability to rapidly adapt to new domains by leveraging additional information from the audio modality.\\nMATE achieves best zero-shot performance improvement on downstream SLU tasks: To evaluate the effectiveness of the proposed approach on the end goals in a dialog system, we compare it with other baselines using metrics such as scenario\\/action accuracy and entity F1 score in a zeroshot setting on SLURP dataset. From results in Table 2, we observe that MATE consistently outperforms5 the other baselines on end-to-end goals indicating that the improvements are mainly on\"}\n{\"section_title\":\"4.3 Effect Analysis\",\"section_content\":\"Effect of the number of views. MVP raises a question that how many views should be selected for training and inference, which we further explore by varying the number of views and the size of the training set (Figure 3). As the number of views increases, curves show an ascending trend frst. Interestingly, when the resource is adequate, F1 decreases slightly after a certain number (between 7 and 15). We believe views with lower ranks may be less effective. Thus it is crucial to balance the size of the data and the number of views. It is dramatic that MVP performs decently even with a single view, probably due to the appropriate order selection and the constrained decoding. In extremely low-resource scenarios, by setting a larger value, MVP can expand single-view information and provide more potential choices. The maximum number of views for quadruplets is much higher than that for triples, making MVP more appropriate for quadruple tasks. We provide further comparisons with single-view prompting (i.e., selecting the best single view for training and inference) on all tasks in the Appendix E.\\nEffect of aggregation strategy. To explore the effect of different aggregation strategies, we conduct ablation studies mainly on ASTE and ASQP tasks, as shown in Table 4. We can see that replacing majority voting with random selection or ranking results in a reduction of F1 in most cases, indicating that majority voting is a more stable strategy for handling diverse views.\\nEffect of constrained decoding. The designed constrained decoding guides the generation of different views by limiting the predicted term to a specifc list. The impact of this algorithm increases\\nFigure 4: Two examples including the input sentence, quadruplets or triples predicted, and the fnal outputs of MVP after fltering by voting. Pick means that the tuple has appeared in more than half of the predictions in multiple views, while drop means that it has appeared less than half of the times and is discarded. Words in green are positive ones while those in red are wrongly picked. Tuples in orange are the ones that MVP ignores.\\nas the size of the data decreases, and in extremely low-resource scenarios, MVP combined with this algorithm performs considerably well (Table 4).\"}\n{\"section_title\":\"4.3 Analysis\",\"section_content\":\"Effect of skip-gram size The relation between recall $@1$ , 5, 10 and skip-gram size $K$ is shown in Figure 2. Increasing $K$ generally improves all recall metrics for SSR-U by introducing more constraints to the generator mapping, though the performance starts to saturate at $K=4$ .\\nEffect of the number of speech clusters We experiment with speech2sign-U models with speech cluster sizes $|\\\\mathbb{X}|$ equal to 100, 200, 400, and a model that directly takes raw wav2vec 2.0 features as inputs $(|\\\\mathbb{X}|=\\\\infty)$ , as shown in Figure 2. We found that the continuous model is signifcantly\\nGAN loss, we instead feed the generator outputs to a discriminator with a single convolutional layer while keeping all other settings the same. Our experiment indicates that the GAN-free approach is consistently more stable and accurate compared to the GAN-based approach.\\nworse than discrete models and $|\\\\mathbb{X}|=200$ provides the most consistent recall scores across different skip-gram sizes.\\nEffect of training objectives The effect of different training objectives including the default speech2sign-U loss (L1) in Eq. (12), the maximum mean discrepancy (MMD) GAN and the JensenShannon divergence (JSD) GAN is shown in Figure 3. For models trained with MMD and JSD\\nEffect of visual features The effect of visual features is shown in Table 4. We experimented with different types of visual features on ASL LibriSpeech with different vocabulary sizes such as VGG19 and the pose keypoint features from OpenPose (Cao et al., 2019). For the OpenPose features, we extract the keypoints from each video frames and re-sample each sign video feature frames to 30 frames as the segment-level feature. I3D architecture (Carreira and Zisserman, 2017) signifcantly outperforms VGG19 and OpenPose as a feature extractor, demonstrating the importance of temporal information for SSR-U. We also found that I3D with optical fow features performs better than I3D with raw RGB inputs for most vocabulary sizes. Further, we found that concatenating the features from the RGB-based and fow-based I3Ds is benefcial for vocabulary sizes 193 and 468 but not when the vocabulary size is too small or too large, even causing training instability for vocabulary size 877.\\n\\nEffect of segmentations The effect of gold and predicted speech segmentation for word-level SSRU is shown in Table 5. For models trained with phoneme boundaries, we obtain predicted word segmentations using a CPC-based unsupervised segmentation system (Kreuk et al., 2020) with meanpooled phoneme-level wav2vec 2.0 features as inputs. The convolutional encoder in the original model is replaced by a two-layer MLP with 256 output dimensions trained on ASL LibriSpeech 100 for 200 epochs. This yields an exact-match boundary F1 of $88\\\\%$ . Using such detected word boundaries, we found about a $20\\\\%$ drop in recall $@1$ for speech2text-U and an $8\\\\mathrm{-}17\\\\%$ relative drop in recall $@1{,}5{,}10$ for speech2sign-U. Still, our model remains much better than the wav2vec-U baseline with ground-truth word boundaries, demonstrating its robustness to segmentation noise.\\n\\nEffect of word frequencies We plotted the F1 score of the frst 100 word classes ranked by frequency in Figure 4. For ASL LibriSpeech 100 and 500, while noisy, it is not hard to observe that the F1 score positively correlates with word frequency in a somewhat exponential fashion. Starting with F1 above 0.55 for the most frequent word, the performance quickly drops below 0.2 at around the 30th most frequent word. This trend is less conclusive on ASL LibriSpeech 1000 with generally low F1 scores, but the highest F1 scores are still observed for the most frequent words. The trend is also illustrated by the DTW alignment of a speechvideo pair correctly retrieved by speech2sign-U in Figure 5. In our example, speech2sign-U mistakes the sign \\u201cmore\\u201d for more frequent signs such as \\u201cwhen\\u201d and \\u201chave\\u201d. Additional factors such as visual similarity also play a role in the case of \\u201cmore\\u201d and \\u201cwhen\\u201d, as both signs involve touching the tips of both hands. Such factors may explain the fuctuations in Figure 4. More error analysis can be found in Appendix A.\"}\n{\"section_title\":\"Dataset Analysis\",\"section_content\":\"Dataset Analysis\\nWe collect 211 documents from WikiEvents [Li et al., 2021] to create our MEQA dataset and select\\nfive workers to annotate the dataset according to the five strategies illustrated in Table 1. After the\\nannotation procedures, the dataset is further split into training, development, and test sets with a\\nproportion of 80%:10%:10%. A summary of the general dataset statistics is shown in Table 7. We\\nanalyze our question type distributions and data quality in this section, and some additional analysis\\nare shown in Appendix F.\\n5.1\\nQuestion Type Distribution\\nThe distribution across the five strategies is organized in Table 1. From the table, it is evident that the\\nfirst two strategies event-bridging and entity-bridging questions account for the largest percentage\\nwith a proportion of 49.7% and 37.1%, due to the rich event trigger and argument annotations in\\nWikiEvents. For the rest of the question types, the number of comparison questions is smaller due to\\nthe requirement of numbers mentioned in event arguments affiliated with the same events.\\n5.2\\nData Difficulty Evaluation\\nWe design three prompting-based methods to test on datasets. Table 2 illustrates that our MEQA\\ndataset is the most challenging compared to HotpotQA and 2WikiMultihop.\\n6\\nTable 2: Performance on different methods over HotpotQA, 2WikiMultihopQA, and MEQA.\\nPrecision\\nRecall\\nF1\\nChatGPT (GPT-3.5-turbo-1106)\\nHotpotQA\\n0.745\\n0.779\\n0.733\\n2WikiMultihop\\n0.501\\n0.724\\n0.532\\nMEQA\\n0.190\\n0.536\\n0.238\\nChatGPT CoT-QA (+ Entity)\\nHotpotQA\\n0.777\\n0.813\\n0.763\\n2WikiMultihop\\n0.534\\n0.757\\n0.565\\nMEQA\\n0.364\\n0.394\\n0.350\\nChatGPT CoT-QA (+ Event Triggers)\\nMEQA\\n0.321\\n0.377\\n0.312\\nHuman\\nMEQA\\n0.783\\n0.836\\n0.811\\nTable 3: HotpotQA entity-centric example (top) and MEQA event-centric example (bottom).\\nParagraphs\\nParagraph A: The 2015 Diamond Head Classic was a college basketball tournament ...\\nBuddy Hield was named the tournament\\u2019s MVP.\\nParagraph B: Chavano Rainier \\u201dBuddy\\u201d Hield is a Bahamian professional basketball\\nplayer for the Sacramento Kings of the NBA...\\nQuestion\\nWhich team does the player named 2015 Diamond Head Classic\\u2019s MVP play for?\\nAnswer\\nSacramento Kings\\nDocument\\n[. .. ] nation\\u2019s Defense Ministry confirmed that a major general was killed in Syria by an\\nimprovised explosive device, Al-Monitor online reported. [. ..] In 2017, a lieutenant\\ngeneral was killed in the same province, [...]\\nQuestion\\nWho died before Al-Monitor reported online?\\nAnswer\\nmajor general, lieutenant general\\nEmploying ChatGPT as the foundational method, where each input contains only a context and a\\nquestion and the output is only an answer (Appendix G), reveals that MEQA presents the greatest\\nchallenge. Additionally, our exploration of the effectiveness of the Chain-of-Thought [Wei et al.,\\n2022] style prompt, denoted as \\u201cCoT-QA\\u201d, in which a list of question answer pairs represents\\nreasoning chains before answers. For \\u201cCoT-QA (+Entity)\\u201d and \\u201cCoT-QA (+Event Triggers)\\u201d,\\nextracted entities and lists of event triggers are leveraged in the context in the prompt correspondingly\\n[Li and Du, 2023b]. Results are consistent across all three models.\\nWe obtain human performance from 3 annotators (graduate students) on 100 samples randomly\\nchosen from the test split. The accuracy is 88% on average, the upper bound of human performance\\nis 92%, and human agreement [Cohen, 1960; Trivedi et al., 2022] is 79%.\\nTable 3 presents examples comparing between HotpotQA and MEQA. The upper example is from\\nthe entity-centric benchmark HotpotQA. Its reasoning type is \\u201centity bridging\\u201d. The reasoning starts\\nfrom \\u201cMVP\\u201d, hops by \\u201cBuddy Hield\\u201d, and ends with the answer \\u201cSacramento Kings\\u201d. To answer the\\nquestion in the bottom example, models should start reasoning from the Al-Monitor and first locate\\nthe reported event; then find all events that happened before the reported event; and finally extract\\nvictims in all those events, which are answers to the question.\\n6\"}\n\n... # only display 6 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The retrieved sections do not contain the specific information about why -inf appears in Fig. 3. I will perform a similarity search in the vectorstore to find the relevant context.\n[Action]:\nClassicRetrieve(query=\"Why does -inf appear in Fig. 3 in the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning'\", limit=5)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.6899,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.6604,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.5817,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.5413,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n{\"score\":0.54,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":14,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"66458415-6d14-5287-a680-925ba5b42cd3\",\"text\":\"variables explicitly [13, 58, 59]. On the contrary, our work incorporates fine-grained local causal\\nrelationships into dynamics learning, which is underexplored in prior works.\\nA.2\\nBackground on Local Independence Relationship\\nIn this subsection, we provide the background on local independence relationship. We first describe\\ncontext-specific independence (CSI) [5], which denotes a variable being conditionally independent of\\nothers given a particular context, not the full set of parents in the graph.\"}\n\nIn total, 5 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The similarity search did not return any relevant information about why -inf appears in Fig. 3. I will try to retrieve the specific section or figure caption that might contain this information.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content, images.image_caption FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id LEFT JOIN images ON images.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND (sections.section_title LIKE '%Fig. 3%' OR images.image_caption LIKE '%Fig. 3%');\")"}
{"role": "user", "content": "[Observation]: [Warning]: The SQL execution result is empty, please check the SQL first."}
{"role": "assistant", "content": "[Thought]: The SQL query did not return any results, which means the section title or image caption might not be exactly \"Fig. 3\". I will perform a similarity search in the vectorstore to find the relevant context.\n[Action]:\nClassicRetrieve(query=\"Fig. 3 in the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning'\", limit=5)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.8707,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.8506,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.7743,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.7094,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n{\"score\":0.6849,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":14,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"66458415-6d14-5287-a680-925ba5b42cd3\",\"text\":\"variables explicitly [13, 58, 59]. On the contrary, our work incorporates fine-grained local causal\\nrelationships into dynamics learning, which is underexplored in prior works.\\nA.2\\nBackground on Local Independence Relationship\\nIn this subsection, we provide the background on local independence relationship. We first describe\\ncontext-specific independence (CSI) [5], which denotes a variable being conditionally independent of\\nothers given a particular context, not the full set of parents in the graph.\"}\n\nIn total, 5 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The similarity search did not return the specific information about why -inf appears in Fig. 3. I will try to retrieve the figure caption and the surrounding text to get more context.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT images.image_caption, pages.page_content FROM images JOIN pages ON images.ref_page_id = pages.page_id JOIN metadata ON pages.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND images.image_caption LIKE '%Fig. 3%';\")"}
{"role": "user", "content": "[Observation]: [Warning]: The SQL execution result is empty, please check the SQL first."}
{"role": "assistant", "content": "[Thought]: The SQL query did not return any results, which means the figure caption might not be exactly \"Fig. 3\". I will try to retrieve the entire page content where Fig. 3 is mentioned to get more context.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT pages.page_number, pages.page_content FROM pages JOIN metadata ON pages.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND pages.page_content LIKE '%Fig. 3%';\")"}
{"role": "user", "content": "[Observation]:\n{\"page_number\":7,\"page_content\":\"Full\\nChain\\nFork\\n(a) CHEMICAL\\n(b) MAGNETIC\\nFigure 3: Illustrations for each environment. (a) In Chemical, colors change by the action according\\nto the underlying causal graph. (b) In Magnetic, the red object exhibits magnetism. (b-left) The box\\nattracts the ball via magnetic force. (b-right) The box does not have an influence on the ball.\\nprior works [13, 41, 42, 49, 59]. Detailed descriptions for each environment and setup are provided\\nin Appendix C.1.\\n4.1.1\\nEnvironments\\nChemical. In the Chemical [24] environment, there are 10 nodes where each node is colored with\\none of 5 colors, and an action is setting the color of a node. According to the underlying causal graph,\\nan action changes the colors of the intervened object\\u2019s descendants as depicted in Fig. 3(a). The\\ntask is to match the colors of each node to the given target. We design two settings, named full-fork\\nand full-chain: the underlying causal graph is both full, and the local causal graph is fork and chain,\\nrespectively. For example, in full-fork, local causal graph fork corresponds to the context where the\\ncolor of the root node is red. In other words, for each node, all other parent nodes except the root\\nbecome irrelevant according to the particular color of the root node. During the test, the root color\\nis set to activate local causal graph. Here, the agent receives a noisy observation for some nodes\\n(except the root) and the task is to match the colors of other observable nodes. The agent capable of\\nfine-grained causal reasoning would generalize well since corrupted nodes are locally spurious to\\ninfer the colors of other nodes, as depicted in Appendix C.1 (Fig. 6).\\nMagnetic. We design the robot arm manipulation environment based on the Robosuite framework\\n[67]. There is a moving ball and a box on the table, colored red or black (Fig. 3(b)). Red color\\nindicates that the object is magnetic, and attracts the other magnetic object. For example, when\\nthey are both colored red, magnetic force will be applied, and the ball will move toward the box.\\nOtherwise, the box would have no influence on the ball. The task is to move the robot arm to reach\\nthe ball predicting its trajectory. The color and position of the objects are randomly initialized\\nfor each episode. During the test, one of the objects is black, and the box is located at an unseen\\nposition. Since the position of the box is unnecessary for predicting the movement of the ball under\\nnon-magnetic context, the agent aware of the fine-grained causal relationships would generalize well\\nto unseen out-of-distribution (OOD) states.\\n4.1.2\\nBaselines\\nWe first consider traditional dense models, i.e., a monolithic network implemented as multi-layer\\nperceptron (MLP) which approximates the dynamics p(s\\u2032 | s, a), and a modular network which has a\\nseparate network for each variable: Q\\nj p(s\\u2032\\nj | s, a). In addition, we include a graph neural network\\n(GNN) [27] and NPS [15]. GNN learns the relational information between variables and NPS learns\\nsparse and modular dynamics. Causal models, including CDL [59] and GRADER [13], infer causal\\nrelationships between the variables for dynamics learning: Q\\nj p(s\\u2032\\nj | Pa(j)), utilizing conditional\\nmutual information and conditional independence test, respectively. We also include an oracle causal\\nmodel, which leverages the ground truth (global) causal graph. Finally, we compare to a local causal\\nmodel, NCD [21], which infers the variable dependencies for each sample.\\nPlanning algorithm. For all baselines and our method, we use a model predictive control (MPC) [8]\\nwhich selects the actions based on the prediction of the learned dynamics model. Specifically, we use\\nthe cross-entropy method (CEM) [46], which iteratively generates and optimizes action sequences.\\nImplementation. For the implementation of our method, we set the codebook size of K = 16, the\\nregularization coefficient \\u03bb = 0.001, and the commitment coefficient \\u03b2 = 0.25 in all experiments. For\\n7\\n\"}\n{\"page_number\":19,\"page_content\":\"Table 4: Environment configurations.\\nChemical\\nMagnetic\\nParameters\\nfull-fork\\nfull-chain\\nTraining step\\n1.5 \\u00d7 105\\n1.5 \\u00d7 105\\n2 \\u00d7 105\\nOptimizer\\nAdam\\nAdam\\nAdam\\nLearning rate\\n1e-4\\n1e-4\\n1e-4\\nBatch size\\n256\\n256\\n256\\nInitial step\\n1000\\n1000\\n2000\\nMax episode length\\n25\\n25\\n25\\nAction type\\nDiscrete\\nDiscrete\\nContinuous\\nTable 5: CEM parameters.\\nChemical\\nMagnetic\\nCEM parameters\\nfull-fork\\nfull-chain\\nPlanning length\\n3\\n3\\n1\\nNumber of candidates\\n64\\n64\\n64\\nNumber of top candidates\\n32\\n32\\n32\\nNumber of iterations\\n5\\n5\\n5\\nExploration noise\\nN\\/A\\nN\\/A\\n1e-4\\nExploration probability\\n0.05\\n0.05\\nN\\/A\\n{\\n}\\n,\\n,\\n{\\n}\\n,\\nRoot node\\nFull\\nFork\\nRoot node\\n:  Noisy node\\n?\\n: Color\\n}\\n,\\n,\\n,\\n,\\n{\\n: Action\\n?\\n?\\n?\\n?\\nFigure 6: Illustration of CHEMICAL (full-fork) environment with 4 nodes. (Left) the color of the root\\nnode determines the activation of local causal graph fork. (Right) the noisy nodes are redundant for\\npredicting the colors of other nodes under the local causal graph.\\nC.1.2\\nChemical\\nHere, we describe two settings, namely full-fork and full-chain, modified from Ke et al. [24]. In both\\nsettings, there are 10 state variables representing the color of corresponding nodes, with each color\\nrepresented as a one-hot encoding. The action variable is a 50-dimensional categorical variable that\\nchanges the color of a specific node to a new color (e.g., changing the color of the third node to\\nblue). According to the underlying causal graph and pre-defined conditional probability distributions,\\nimplemented with randomly initialized neural networks, an action changes the colors of the intervened\\nobject\\u2019s descendants as depicted in Fig. 6. As shown in Fig. 3(a), the (global) causal graph is full in\\nboth settings, and the LCG is fork and chain, respectively. For example in full-fork, the LCG fork is\\nactivated according to the particular color of the root node, as shown in Fig. 6.\\nIn both settings, the task is to match the colors of each node to the given target. The reward function\\nis defined as:\\nr =\\n1\\n|O|\\nX\\ni\\u2208O\\n1 [si = gi] ,\\n(41)\\nwhere O is a set of the indices of observable nodes, si is the current color of the i-th node, and gi is\\nthe target color of the i-th node in this episode. Success is determined if all colors of observable nodes\\nare the same as the target. During training, all 10 nodes are observable, i.e., O = {0, \\u00b7 \\u00b7 \\u00b7 , 9}. In\\ndownstream tasks, the root color is set to induce the LCG, and the agent receives noisy observations\\nfor a subset of nodes, aiming to match the colors of the rest of the observable nodes. As shown in\\nFig. 6, noisy nodes are spurious for predicting the colors of other nodes under the LCG. Thus, the\\nagent capable of reasoning the fine-grained causal relationships would generalize well in downstream\\ntasks.4 To create noisy observations, we use a noise sampled from N(0, \\u03c32), similar to Wang et al.\\n[59]. Specifically, the noise is multiplied to the one-hot encoding representing color during the test.\\nIn our experiments, we use \\u03c3 = 100.\\nAs the root color determines the local causal graph in both settings, the root node is always observable\\nto the agent during the test. The root colors of the initial state and the goal state are the same, inducing\\nthe local causal graph. As the root color can be changed by the action during the test, this may pose a\\n4We note that the transition dynamics of the environment is the same in training and downstream tasks.\\n19\\n\"}\n{\"page_number\":20,\"page_content\":\"(a)\\n(b)\\n(c)\\nFigure 7: (a) Causal graph of Magnetic environment. Red boxes indicate redundant edges under\\nthe non-magnetic context. (b) LCG under the magnetic context. (c) LCG under the non-magnetic\\ncontext.\\nchallenge in evaluating the agent\\u2019s reasoning of local causal relationships. This can be addressed by\\nmodifying the initial distribution of CEM to exclude the action on the root node and only act on the\\nother nodes during the test. Nevertheless, we observe that restricting the action on the root during the\\ntest has little impact on the behavior of any model, and we find that this is because the agent rarely\\nchanges the root color as it already matches the goal color in the initial state.\\nC.1.3\\nMagnetic\\nIn this environment, there are two objects on a table, a moving ball and a box, colored either red or\\nblack, as shown in Fig. 3(b). The red color indicates that the object is magnetic. In other words, when\\nthey are both colored red, magnetic force will be applied and the ball will move toward the box. If\\none of the objects is colored black, the ball would not move since the box has no influence on the ball.\\nThe state consists of the color, x, y position of each object, and x, y, z position of the end-effector\\nof the robot arm, where the color is given as the 2-dimensional one-hot encoding. The action is a\\n3-dimensional vector that moves the robot arm. The causal graph of the Magnetic environment is\\nshown in Fig. 7(a). LCGs under magnetic and non-magnetic event are shown in Figs. 7(b) and 7(c),\\nrespectively. The table in our setup has a width of 0.9 and a length of 0.6, with the y-axis defined by\\nthe width and the x-axis defined by the length. For each episode, the initial positions of a moving ball\\nand a box are randomly sampled within the range of the table.\\nThe task is to move the robot arm to reach the moving ball. Thus, accurately predicting the trajectory\\nof the ball is crucial. The reward function is defined as:\\nr = 1 \\u2212tanh(5 \\u00b7 \\u2225eef \\u2212g\\u22251),\\n(42)\\nwhere the eef \\u2208R3 is the current position of the end-effector, g = (bx, by, 0.8) \\u2208R3, and (bx, by)\\nis the current position of the moving ball. Success is determined if the distance is smaller than 0.05.\\nDuring the test, the color of one of the objects is black and the box is located at the position unseen\\nduring the training. Specifically, the box position is sampled from N(0, \\u03c32) during the test. Note\\nthat the box can be located outside of the table, which never happens during the training. In our\\nexperiments, we use \\u03c3 = 100.\\nC.2\\nImplementation Details\\nFor all methods, the dynamics model outputs the parameters of categorical distribution for discrete\\nvariables, and the mean and standard deviation of normal distribution for continuous variables. Each\\nmethod has a similar number of model parameters. All experiments were processed using a single\\nGPU (NVIDIA RTX 3090). Environmental configurations and CEM parameters are shown in Table 4\\nand Table 5, respectively. Detailed parameters of each model are shown in Table 6.\\nMLP and Modular. MLP models the transition dynamics as p(s\\u2032 | s, a). Modular has a separate\\nnetwork for each state variable, i.e., Q\\nj p(s\\u2032\\nj | s, a), where each network is implemented as an MLP.\\nGNN, NPS, and CDL. We employ publicly available source codes.5 For NPS, we search the number\\nof rules N \\u2208{4, 15, 20}. CDL infers the causal structure utilizing conditional mutual information\\n5https:\\/\\/github.com\\/wangzizhao\\/CausalDynamicsLearning\\n20\\n\"}\n\nIn total, 3 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The retrieved page content from page 7 provides the necessary context to answer the question. The method that performs the best on ID states with the full-chain setting is likely mentioned in the experimental results section. I will search for the relevant information in the full text.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Results%' OR sections.section_title LIKE '%Experiments%' OR sections.section_title LIKE '%Discussion%';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"More Details and Results on Experiments\",\"section_content\":\"More Details and Results on Experiments\\nIn this appendix we fill the missing details in the experiment section. Our experiments are\\nimplemented with Intel Core i9 CPU of 32GB memory, no GPU is required and the execution\\ntime is no longer than 30 seconds. In the rest of this section, we first introduce the generation\\nprocess of synthetic datasets in Appendix E.1; Next we define the evaluation metrics and\\nperturbation approaches in Appendix E.2; More results on dissimilarities regarding the\\nscaled additive error, negative distances and negative eigenvalues selected, are demonstrated\\nin Appendix E.3.\\nWith respect to the dimensionality paradox, we provide illustrations\\nsimilar to Figure 2 on other datasets in Appendix E.4.\\nE.1\\nSynthetic Datasets Generation\\nThe random-simplex dataset is generated with the idea of creating a simplex with one\\nadded dimension that generates all of the variance in the the distances such that the added\\ndimension corresponds with a negative eigenvalue. This way, we should have a dimension\\nwith a large negative eigenvalue that is impactful on the stress of the embedding.\\nSpecifically, this dataset was generated with points x1, ...x1000, each point having 1000\\ndimensions. For each point xi, the first 100 coordinates were chosen uniformly randomly\\nbetween 0 and .01. The next 899 coordinates were chosen uniformly randomly between 0\\nand\\np\\n0.5\\/899. The last coordinate is i \\u00d7 0.3\\/1000. Then, the distance between xi and xj\\nwas found in the following way:\\nd(xi, xj) =\\nv\\nu\\nu\\nt\\n100\\nX\\nk=1\\n(xi(k) \\u2212xj(k))2 \\u2212\\n1000\\nX\\nk=101\\n(xi(k) \\u2212xj(k))2\\nwhere xi(k) is the kth coordinate of xi. The first 999 coordinates essentially form a simplex,\\nbecause selecting a large number of coordinates randomly from the same distribution causes\\nall of the distances to converge to a normal distribution with low variance. Thus, all of\\nthe distances between points using just the first 999 coordinates are very similar. Then,\\nthe last coordinate has \\u201clarge\\u201d discrepancies between all of the points, causing most of the\\ndifferences in the distances.\\nThe Euclidean-ball metric was inspired by [49]. The set of distances between objects in space\\ndoes not follow triangle inequality, so it becomes a non-euclidean dissimilarity measure. The\\nparticular dataset we use generates the distances by first randomly selecting 1000 points\\n21\\nuniformly in a 10 dimensional hypercube of length 100. Each of these points is now the\\ncenter of a ball. Then, for each ball, with probability 0.9, we select a radius uniformly\\nrandomly between 0 and 5. With probability 0.1, we let the radius be 0.8 times the distance\\nbetween the center of this ball to the closest other ball. This closest other ball is based on\\nthe radius of the other ball if it has already been decided. The final distance matrix is just\\nfilled by the distances between the 1000 balls. In this way, we attempt to create some balls\\nwith large radius, so that the triangle inequality is heavily violated, therefore causing the\\ndataset to deviate more from the Euclidean setting.\\nE.2\\nEvaluation and Perturbation Metrics\\nIn addition to STRESS, our evaluation metric include scaled additive error and average\\ngeometric distortion. Scaled additive error by definition is allowing scaling of the distance\\nmatrix of our embedding before calculating stress. To do this, we first ran the embedding\\nmethod (e.g., cMDS, Neuc-MDS, or other methods) on the given dissimilarity squared ma-\\ntrix D to get the output dissimilarity squared matrix \\u02dc\\nD. Then, we would flatten both D\\nand \\u02dc\\nD to vectors, and project D onto the line through \\u02dc\\nD to get E. Then we calculate\\n\\u2225D \\u2212E\\u2225to get scaled additive error. Clearly, this is equivalent to allowing scaling of \\u02dc\\nD\\nto find the minimum stress. For average geometric distortion, we again input D to get \\u02dc\\nD,\\nbut this time, we evaluate the distortion of each dissimilarity by dividing entries of\\n\\u221a\\nD by\\nentries of\\np\\n\\u02dc\\nD. Since distortion is not well defined when dissimilarities become complex,\\nwe skip those. Then, with the remaining valid distortions, we scale the distortions so that\\nthere\\u2019s an equal number of them greater than 1 and less than 1, then for those that remain\\nless than 1, we take their reciprocal. Then, we finally take the geometric average of all of\\nthese distortions. In this way, we basically again allowed scaling of the dissimilarities to find\\nthe minimum possible average distortion.\\nNext, we had to decide on metrics to use for the image datasets. We took the following\\n3 metrics from [38]. For the first metric, the distance between two images is first finding\\nthe Euclidean distance between their coordinate representations, and then adding Gaussian\\nnoise to the distances.\\nBecause the noise is added directly onto the distances, the end\\nresult is highly likely to be non-Euclidean. For the second metric, we build a k nearest\\nneighbor graph of the images based on their Euclidean distances. Since the end result is a\\ngraph structure, the shortest path distances are also highly likely to be non-Euclidean. For\\nthe third metric, we randomly removed entries from the coordinate representation of the\\nimages. Then, the distance between two images is decided by taking the Euclidean distance\\nbetween coordinates that both images still included. Here, the Euclidean property breaks\\ndown again because triangle inequality would no longer have to hold. In Table 2, we choose\\nthe k-NN metric with k = 2. In the next Appendix section, we show results for higher k and\\nother metrics applied to the image datasets. As for genomics datasets, we use the entropic\\naffinities commonly used in t-SNE methods. The main idea is to apply an adaptive kernel,\\nwhose bandwidth depends on a parameter termed as perplexity, to pairwise data entries.\\nE.3\\nMore Results on Dissimilarity Error\\nIn addition to STRESS and average distortion already reported in Table 2, we further show\\nthe third metric: scaled additive error as defined in Appendix E.2. Note that our algorithms\\nmay produce negative distances, we also report number of negative distances and number\\nof negative eigenvalues selected. All original results (without scaling) on 10 datasets are\\ndemonstrated in Table 6. Recall we mentioned the results in Table 2 contains some scaling\\non the synthetic data and images, we also provide the original values in Table 7.\\nOn scaled additive error, our proposed methods still consistently outperform cMDS and\\nLower-MDS considerably.\\nThus, we have shown that on all metrics our methods yield\\nmore favorable results. It is interesting to observe that Neuc-MDS+ produces much fewer\\nnegative distances than Neuc-MDS, though the number of negative eigenvalues selected are\\nquite close. Further, two methods have similar performance on STRESS and other metrics.\\nTherefore in practice, if there is a considerable concern on negative distances, Neuc-MDS+\\nshould become a better choice.\\n22\\nTable 6: Original Evaluation Results on All Datasets for Lower-MDS (L-MDS), Neuc-MDS\\n(N-MDS) and Neuc-MDS+ (N-MDS+). Metrics include scaled additive error, number of\\nnegative distances and number of negative eigenvalues selected.\\nDataset\\nScaled Additive Error\\n# Neg Distances\\n# Neg \\u03bb Selected\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nRandom-simplex\\n17758\\n17760\\n3415\\n1392\\n0\\n0\\n8\\n1\\nEuclidean-ball\\n14909\\n13093\\n3132\\n3631\\n798\\n523\\n90\\n87\\nBrain (50161)\\n0.131\\n0.132\\n0.063\\n0.062\\n5539\\n1081\\n8\\n9\\nBreast (45827)\\n0.039\\n0.039\\n0.016\\n0.015\\n9024\\n136\\n8\\n9\\nColorectal (44076)\\n0.027\\n0.027\\n0.012\\n0.014\\n12041\\n1940\\n6\\n8\\nLeukemia (28497)\\n0.031\\n0.031\\n0.021\\n0.023\\n32705\\n2102\\n8\\n10\\nRenal (53757)\\n0.018\\n0.018\\n0.013\\n0.014\\n6650\\n713\\n7\\n9\\nMNIST\\n7592\\n6126\\n3148\\n3.135\\n1006\\n68\\n42\\n43\\nFashion-MNIST\\n6153\\n4421\\n2.472\\n2.470\\n526\\n8\\n41\\n41\\nCIFAR10\\n3880\\n3564\\n2870\\n2.842\\n2968\\n201\\n43\\n44\\nTable 7: Original Evaluation Results on All Datasets. Metrics include STRESS and average\\ngeometric distortion\\nDataset\\nSTRESS\\nAverage Geometric Distortion\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\nRandom-simplex\\n28.376\\n17.760\\n3.433\\n1.392\\n1.049\\n1.049\\n1.010\\n1.004\\nEuclidean-ball\\n19.229\\n13.154\\n3.346\\n3.676\\n1.046\\n1.041\\n1.013\\n1.017\\nBrain (50161)\\n0.538\\n0.170\\n0.068\\n0.067\\n8.160\\n42.705\\n5.809\\n6.941\\nBreast (45827)\\n0.168\\n0.065\\n0.017\\n0.017\\n6.988\\n31.081\\n6.205\\n6.295\\nColorectal (44076)\\n0.121\\n0.047\\n0.013\\n0.016\\n23.938\\n34.587\\n20.234\\n22.475\\nLeukemia (28497)\\n0.172\\n0.079\\n0.028\\n0.031\\n6.551\\n32.214\\n7.032\\n6.749\\nRenal (53757)\\n0.070\\n0.030\\n0.016\\n0.019\\n21.709\\n38.282\\n19.680\\n21.223\\nMNIST\\n25.516\\n6.156\\n3.152\\n3.144\\n1.119\\n1.104\\n1.064\\n1.063\\nFashion-MNIST\\n18.771\\n4.422\\n2.475\\n2.473\\n1.135\\n1.096\\n1.068\\n1.068\\nCIFAR10\\n16.309\\n3.572\\n2.930\\n2.916\\n1.129\\n1.109\\n1.121\\n1.118\\nFigure 3: Dimensionality Paradox on Eight Datasets.\\nUntil now all results reported on images are using kNN metric with k = 2 to produce\\nnon-Euclidean dissimilarities. There could be other perturbations for the same purpose, as\\nmentioned in Appendix E.2. We further test with k = 10 and the other two metrics: adding\\nnoise and random removal on the STRESS. We add noise sampled from Gaussian distri-\\nbution with variance as the maximum instance-wise difference scaled by 500; For random\\nremoval, we skip 50 images for each. The results are shown in Table 8.\\n23\\nTable 8: Evaluation Results on Image Datasets with other perturbation metrics.\\nDataset\\nSTRESS\\n# Neg distances\\n# Neg \\u03bb Selected\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nMNIST (k = 10)\\n10080\\n1979\\n1827\\n1830\\n554\\n63\\n42\\n41\\nFashion (k = 10)\\n10249\\n2112\\n1936\\n1915\\n403\\n84\\n38\\n40\\nCIFAR10 (k = 10)\\n9032\\n1881\\n2309\\n2329\\n3236\\n996\\n39\\n37\\nMNIST (noise)\\n1.497e9\\n1.499e9\\n1.497e9\\n1.140e9\\n0\\n0\\n0\\n7\\nFashion (noise)\\n4.815e9\\n4.130e9\\n3.382e9\\n3.327e9\\n0\\n0\\n2\\n14\\nCIFAR10 (noise)\\n2.303e10\\n2.116e9\\n2.303e9\\n1.848e9\\n0\\n0\\n0\\n9\\nMNIST (missing)\\n3.281e8\\n1.010e8\\n3.281e8\\n1.010e8\\n0\\n0\\n0\\n0\\nFashion (missing)\\n5.165e8\\n1.726e8\\n5.165e8\\n1.726e8\\n0\\n0\\n0\\n0\\nCIFAR10 (missing)\\n2.132e9\\n5.756e8\\n2.132e9\\n5.756e8\\n0\\n0\\n0\\n0\\nE.4\\nMore Results on Dimensionality Paradox\\nThe purpose of this section is to show the consistent performance of Neuc-MDS and Neuc-\\nMDS+ on all datasets, with respect to mitigating the dimensionality paradox issue. There-\\nfore, in addition to Figure 2, we provide the same plots for other datasets, and the pa-\\nrameters all follow the main setup. Figure 3 gives a clear illustration that Neuc-MDS and\\nNeuc-MDS+ always have lower STRESS than cMDS and Lower-MDS as dimension grows.\\n24\\nNeurIPS Paper Checklist\\n1. Claims\\nQuestion: Do the main claims made in the abstract and introduction accurately\\nreflect the paper\\u2019s contributions and scope?\\nAnswer: [Yes]\\nJustification: We propose a generalization of classical multidimensional scaling to\\nhandle non-Euclidean non-metric data. We presented both a new algorithm, theo-\\nretical proofs on its performance, and experimental results.\\nGuidelines:\\n\\u2022 The answer NA means that the abstract and introduction do not include the\\nclaims made in the paper.\\n\\u2022 The abstract and\\/or introduction should clearly state the claims made, in-\\ncluding the contributions made in the paper and important assumptions and\\nlimitations. A No or NA answer to this question will not be perceived well by\\nthe reviewers.\\n\\u2022 The claims made should match theoretical and experimental results, and reflect\\nhow much the results can be expected to generalize to other settings.\\n\\u2022 It is fine to include aspirational goals as motivation as long as it is clear that\\nthese goals are not attained by the paper.\\n2. Limitations\\nQuestion: Does the paper discuss the limitations of the work performed by the\\nauthors?\\nAnswer: [Yes]\\nJustification: We discussed the limitation (and future work) of the proposed ap-\\nproach.\\nThese include: 1) developing downstream data analysis for using non-\\nEuclidean non-metrics data. 2) speeding up the algorithm for extremely large data\\n(e.g., by developing landmark based non-Euclidean MDS algorithms).\\nGuidelines:\\n\\u2022 The answer NA means that the paper has no limitation while the answer No\\nmeans that the paper has limitations, but those are not discussed in the paper.\\n\\u2022 The authors are encouraged to create a separate \\u201dLimitations\\u201d section in their\\npaper.\\n\\u2022 The paper should point out any strong assumptions and how robust the results\\nare to violations of these assumptions (e.g., independence assumptions, noise-\\nless settings, model well-specification, asymptotic approximations only holding\\nlocally). The authors should reflect on how these assumptions might be vio-\\nlated in practice and what the implications would be.\\n\\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach\\nwas only tested on a few datasets or with a few runs. In general, empirical\\nresults often depend on implicit assumptions, which should be articulated.\\n\\u2022 The authors should reflect on the factors that influence the performance of\\nthe approach. For example, a facial recognition algorithm may perform poorly\\nwhen image resolution is low or images are taken in low lighting. Or a speech-\\nto-text system might not be used reliably to provide closed captions for online\\nlectures because it fails to handle technical jargon.\\n\\u2022 The authors should discuss the computational efficiency of the proposed algo-\\nrithms and how they scale with dataset size.\\n\\u2022 If applicable, the authors should discuss possible limitations of their approach\\nto address problems of privacy and fairness.\\n\\u2022 While the authors might fear that complete honesty about limitations might\\nbe used by reviewers as grounds for rejection, a worse outcome might be that\\nreviewers discover limitations that aren\\u2019t acknowledged in the paper.\\nThe\\nauthors should use their best judgment and recognize that individual actions in\\n25\\nfavor of transparency play an important role in developing norms that preserve\\nthe integrity of the community. Reviewers will be specifically instructed to not\\npenalize honesty concerning limitations.\\n3. Theory Assumptions and Proofs\\nQuestion: For each theoretical result, does the paper provide the full set of assump-\\ntions and a complete (and correct) proof?\\nAnswer: [Yes]\\nJustification: Please refer to the theorem statements. We included all proofs in the\\nAppendix.\\nGuidelines:\\n\\u2022 The answer NA means that the paper does not include theoretical results.\\n\\u2022 All the theorems, formulas, and proofs in the paper should be numbered and\\ncross-referenced.\\n\\u2022 All assumptions should be clearly stated or referenced in the statement of any\\ntheorems.\\n\\u2022 The proofs can either appear in the main paper or the supplemental material,\\nbut if they appear in the supplemental material, the authors are encouraged to\\nprovide a short proof sketch to provide intuition.\\n\\u2022 Inversely, any informal proof provided in the core of the paper should be com-\\nplemented by formal proofs provided in appendix or supplemental material.\\n\\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced.\\n4. Experimental Result Reproducibility\\nQuestion: Does the paper fully disclose all the information needed to reproduce\\nthe main experimental results of the paper to the extent that it affects the main\\nclaims and\\/or conclusions of the paper (regardless of whether the code and data\\nare provided or not)?\\nAnswer: [Yes]\\nJustification: We provided all details of our experiments in the Appendix. We also\\nshared our code using an anonymous Github repository. See the footnote on Page\\n2.\\nGuidelines:\\n\\u2022 The answer NA means that the paper does not include experiments.\\n\\u2022 If the paper includes experiments, a No answer to this question will not be\\nperceived well by the reviewers: Making the paper reproducible is important,\\nregardless of whether the code and data are provided or not.\\n\\u2022 If the contribution is a dataset and\\/or model, the authors should describe the\\nsteps taken to make their results reproducible or verifiable.\\n\\u2022 Depending on the contribution, reproducibility can be accomplished in various\\nways. For example, if the contribution is a novel architecture, describing the\\narchitecture fully might suffice, or if the contribution is a specific model and\\nempirical evaluation, it may be necessary to either make it possible for others\\nto replicate the model with the same dataset, or provide acces ...\"}\n\n... # only display 1 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The retrieved section content does not directly answer the question. I will perform a similarity search to find the specific method that performs the best on ID states with the full-chain setting and the reason for -inf in Fig. 3.\n[Action]:\nClassicRetrieve(query=\"In the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning', which method performs the best on ID states with full-chain setting? Why is there -inf in Fig. 3?\", limit=5)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.6804,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.6659,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.6141,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.5956,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"2e290870-d308-5f8e-8c97-6e16ec63f9d6\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nTable 2. Causal Graph Accuracy for CDL with Different Transition\\nCollection Policies\\nMethod\\nPredDiff (Ours)\\nUniform\\nCuriosity\\nAccuracy (%)\\n90.2 \\u00b1 0.3\\n89.1 \\u00b1 0.6\\n88.9 \\u00b1 0.2\\nC.3.2. For ID states, all methods show similar prediction\\nperformance. However, for OOD states, the performance of\\ndense models drops signi\\ufb01cantly as they suffer from spuri-\\nous correlations while CDL and Reg mask those out with the\"}\n{\"score\":0.5683,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"770de309-1a7c-51cc-b656-cf2530612cc1\",\"text\":\"of the inaccurately learned causal graphs.\\nFurthermore, to test the generalization of the learned poli-\\ncies, we evaluate their performance for 100 episodes on\\nboth ID and OOD states, as shown in Fig. 8. Again, CDL\\ngeneralizes the best across all methods on OOD states.\\n5. Conclusions\\nIn this work, we introduce CDL, Causal Dynamics Learn-\\ning for Task-Independent State Abstraction. In contrast to\\nmost existing MBRL methods that learn a dense dynamics\"}\n\nIn total, 5 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The similarity search did not return the specific information needed to answer the question. I will try a more focused search to find the method that performs the best on ID states with the full-chain setting and the reason for -inf in Fig. 3.\n[Action]:\nClassicRetrieve(query=\"In the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning', which method performs the best on ID states with full-chain setting? Why is there -inf in Fig. 3?\", limit=10)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.6804,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.6659,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.6141,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.5956,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"2e290870-d308-5f8e-8c97-6e16ec63f9d6\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nTable 2. Causal Graph Accuracy for CDL with Different Transition\\nCollection Policies\\nMethod\\nPredDiff (Ours)\\nUniform\\nCuriosity\\nAccuracy (%)\\n90.2 \\u00b1 0.3\\n89.1 \\u00b1 0.6\\n88.9 \\u00b1 0.2\\nC.3.2. For ID states, all methods show similar prediction\\nperformance. However, for OOD states, the performance of\\ndense models drops signi\\ufb01cantly as they suffer from spuri-\\nous correlations while CDL and Reg mask those out with the\"}\n{\"score\":0.5683,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"770de309-1a7c-51cc-b656-cf2530612cc1\",\"text\":\"of the inaccurately learned causal graphs.\\nFurthermore, to test the generalization of the learned poli-\\ncies, we evaluate their performance for 100 episodes on\\nboth ID and OOD states, as shown in Fig. 8. Again, CDL\\ngeneralizes the best across all methods on OOD states.\\n5. Conclusions\\nIn this work, we introduce CDL, Causal Dynamics Learn-\\ning for Task-Independent State Abstraction. In contrast to\\nmost existing MBRL methods that learn a dense dynamics\"}\n{\"score\":0.5617,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e4dd2fa8-1f20-53fb-accd-516b4fdcf3c4\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nZizhao Wang 1 Xuesu Xiao 2 Zifan Xu 2 Yuke Zhu 2 Peter Stone 2 3\\nAbstract\\nLearning dynamics models accurately is an impor-\\ntant goal for Model-Based Reinforcement Learn-\\ning (MBRL), but most MBRL methods learn a\\ndense dynamics model which is vulnerable to spu-\\nrious correlations and therefore generalizes poorly\\nto unseen states.\\nIn this paper, we introduce\\nCausal Dynamics Learning for Task-Independent\"}\n{\"score\":0.5532,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"4f2fa982-0020-5acc-9895-d9d907ae6091\",\"text\":\"task-independent state abstraction. In International Conference on Machine Learning, pages\\n23151\\u201323180. PMLR, 2022.\\n[60] Will Williams, Sam Ringer, Tom Ash, David MacLeod, Jamie Dougherty, and John Hughes.\\nHierarchical quantized autoencoders. Advances in Neural Information Processing Systems, 33:\\n4524\\u20134535, 2020.\\n[61] Weiran Yao, Guangyi Chen, and Kun Zhang. Learning latent causal dynamics. arXiv preprint\\narXiv:2202.04828, 2022.\"}\n{\"score\":0.5442,\"pdf_id\":\"5ebc56ef-411b-5842-89ff-24f6adc31fe0\",\"page_number\":11,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e99e0d50-4d31-5be3-bb16-1225838415fb\",\"text\":\"in-the-loop causal discovery under latent confounding using ancestral gflownets.\\narXiv\\npreprint:2309.12032, 2023.\\n[14] M. P. Deisenroth and C. E. Rasmussen. PILCO: A model-based and data-efficient approach to\\npolicy search. In ICML, Proceedings of Machine Learning Research, pages 465\\u2013472. PMLR,\\n2011.\\n[15] T. Deleu, A. G\\u00f3is, C. C. Emezue, M. Rankawat, S. Lacoste-Julien, S. Bauer, and Y. Bengio.\\nBayesian structure learning with generative flow networks. In UAI, 2022.\"}\n{\"score\":0.5392,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n{\"score\":0.5322,\"pdf_id\":\"4bf87140-b2d2-5435-86b7-ed66c30d8bd8\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"fee33440-c8c0-5999-9802-3c4dd7412325\",\"text\":\"CDL [24] uses causal discovery to learn a task-independent world model. Denoised MDP [12] and\\nIFactor [13] conduct causal state abstraction based on their controllability and reward relevance.\\nThe last three methods are designed for online settings, so we only implement their model learning\\nobjectives. We attach more details of the baseline implementation in Appendix C.6.\\n4.2\\nExperiment Results Analysis\\nWe empirically answer the following research questions.\"}\n\nIn total, 10 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The retrieved chunks did not provide the specific information needed to answer the question. I will try a more focused SQL query to retrieve the specific section that discusses the experimental results and the reasoning behind the -inf in Fig. 3.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Results%' OR sections.section_title LIKE '%Discussion%' OR sections.section_title LIKE '%Experiments%';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"4 Results and Discussions\",\"section_content\":\"\"}\n{\"section_title\":\"4 Results and Discussion\",\"section_content\":\"\"}\n{\"section_title\":\"5 Results and Discussion\",\"section_content\":\"\"}\n{\"section_title\":\"4.2 Results and Discussion\",\"section_content\":\"Results of our method are shown in Table 1. LLMs, due to their limitations, perform poorly as a standalone model for long-tail classifcation. These results can be improved by priming the model with an entailment predictor through the usage of a prompt. The baseline shows strong performance independent of the LLM, as it operates on a closed label space. The capabilities of the baseline can be enhanced by further explicitly priming it with a entailment relation through a LLM. Rows in which T0pp is initialized, or primed with $\\\\mathbb{E}$ are indicated with Primed. Priming the model showcases improvements across all datasets for macro F1. For accuracy, priming the model shows beneft in two out of three datasets. In Figure 4, we show the results of Top-5 predictions for the WOS dataset.\\nAll results are aggregated in Table 1. It is important to highlight that prompt variation led to stable results for our LLM. The variance upon utilizing BART-MNLI is negligible across prompts. The best results are observed upto Top-4 predictions on both accuracy and macro F1 for our method, when the entailment prompt is enhanced with a greater number of tokens corresponding to the output of $\\\\mathbb{L}(\\\\mathbb{E}(X))$ . The variation between our method and the baseline is much greater for Top-1 predictions, but Top-5 prediction variance is negligible. Detailed results for both depth settings of Amazon Beauty are shown in Appendix C.\"}\n{\"section_title\":\"6 Results and Discussion\",\"section_content\":\"We now turn to a discussion of the results for the intrinsic (accuracy) and extrinsic (answer rate and relevance) evaluation strategies.\\nTable 1: Evaluation results from the human study on reformulation accuracy and answer relevance. For answer relevance, in brackets are shown the extrapolated estimations of the absolute percentages of answered questions from Table 3 and their respective answer relevance. $\\\\scriptstyle\\\\mathrm{Roo+GEN}$ obtains the highest answer rate and relevance with $13.1\\\\%$ or $131\\\\mathrm{k}$ questions.\\nTable 1 shows the human evaluation results for reformulation accuracy. The best accuracy is achieved for GEN, with $83\\\\%$ of the reformulations being accurate. This is because GEN does not require changing the question type like ROO.\\nREP achieves second best accuracy. One reason for the slightly lower accuracy than GEN, is that it sometimes changes the question type (e.g. request to root), which goes beyond the REP\\u2019s reformulation scope. Although according to our intrinsic evaluation strategy such cases represent inaccurate reformulation, in practice this is benign as QA systems perform very well on root factoid questions.\\nFinally, we note that reformulations signifcantly shorten the input questions and result in higher type-token ratio (Appendix H). We list many examples of model input\\/output pairs in Appendix I.\\nTable 2: Results for the baseline and SURF models using different reformulation types on our test set.\"}\n{\"section_title\":\"5 Results and Discussions\",\"section_content\":\"\"}\n\n... # only display 6 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The retrieved sections are still not providing the specific information needed to answer the question. I will try a more targeted similarity search to find the exact method that performs the best on ID states with the full-chain setting and the reason for -inf in Fig. 3.\n[Action]:\nClassicRetrieve(query=\"In the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning', which method performs the best on ID states with full-chain setting? Why is there -inf in Fig. 3?\", limit=10)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.6804,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.6659,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.6141,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.5956,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"2e290870-d308-5f8e-8c97-6e16ec63f9d6\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nTable 2. Causal Graph Accuracy for CDL with Different Transition\\nCollection Policies\\nMethod\\nPredDiff (Ours)\\nUniform\\nCuriosity\\nAccuracy (%)\\n90.2 \\u00b1 0.3\\n89.1 \\u00b1 0.6\\n88.9 \\u00b1 0.2\\nC.3.2. For ID states, all methods show similar prediction\\nperformance. However, for OOD states, the performance of\\ndense models drops signi\\ufb01cantly as they suffer from spuri-\\nous correlations while CDL and Reg mask those out with the\"}\n{\"score\":0.5683,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"770de309-1a7c-51cc-b656-cf2530612cc1\",\"text\":\"of the inaccurately learned causal graphs.\\nFurthermore, to test the generalization of the learned poli-\\ncies, we evaluate their performance for 100 episodes on\\nboth ID and OOD states, as shown in Fig. 8. Again, CDL\\ngeneralizes the best across all methods on OOD states.\\n5. Conclusions\\nIn this work, we introduce CDL, Causal Dynamics Learn-\\ning for Task-Independent State Abstraction. In contrast to\\nmost existing MBRL methods that learn a dense dynamics\"}\n{\"score\":0.5617,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e4dd2fa8-1f20-53fb-accd-516b4fdcf3c4\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nZizhao Wang 1 Xuesu Xiao 2 Zifan Xu 2 Yuke Zhu 2 Peter Stone 2 3\\nAbstract\\nLearning dynamics models accurately is an impor-\\ntant goal for Model-Based Reinforcement Learn-\\ning (MBRL), but most MBRL methods learn a\\ndense dynamics model which is vulnerable to spu-\\nrious correlations and therefore generalizes poorly\\nto unseen states.\\nIn this paper, we introduce\\nCausal Dynamics Learning for Task-Independent\"}\n{\"score\":0.5532,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"4f2fa982-0020-5acc-9895-d9d907ae6091\",\"text\":\"task-independent state abstraction. In International Conference on Machine Learning, pages\\n23151\\u201323180. PMLR, 2022.\\n[60] Will Williams, Sam Ringer, Tom Ash, David MacLeod, Jamie Dougherty, and John Hughes.\\nHierarchical quantized autoencoders. Advances in Neural Information Processing Systems, 33:\\n4524\\u20134535, 2020.\\n[61] Weiran Yao, Guangyi Chen, and Kun Zhang. Learning latent causal dynamics. arXiv preprint\\narXiv:2202.04828, 2022.\"}\n{\"score\":0.5442,\"pdf_id\":\"5ebc56ef-411b-5842-89ff-24f6adc31fe0\",\"page_number\":11,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e99e0d50-4d31-5be3-bb16-1225838415fb\",\"text\":\"in-the-loop causal discovery under latent confounding using ancestral gflownets.\\narXiv\\npreprint:2309.12032, 2023.\\n[14] M. P. Deisenroth and C. E. Rasmussen. PILCO: A model-based and data-efficient approach to\\npolicy search. In ICML, Proceedings of Machine Learning Research, pages 465\\u2013472. PMLR,\\n2011.\\n[15] T. Deleu, A. G\\u00f3is, C. C. Emezue, M. Rankawat, S. Lacoste-Julien, S. Bauer, and Y. Bengio.\\nBayesian structure learning with generative flow networks. In UAI, 2022.\"}\n{\"score\":0.5392,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n{\"score\":0.5322,\"pdf_id\":\"4bf87140-b2d2-5435-86b7-ed66c30d8bd8\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"fee33440-c8c0-5999-9802-3c4dd7412325\",\"text\":\"CDL [24] uses causal discovery to learn a task-independent world model. Denoised MDP [12] and\\nIFactor [13] conduct causal state abstraction based on their controllability and reward relevance.\\nThe last three methods are designed for online settings, so we only implement their model learning\\nobjectives. We attach more details of the baseline implementation in Appendix C.6.\\n4.2\\nExperiment Results Analysis\\nWe empirically answer the following research questions.\"}\n\nIn total, 10 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The retrieved chunks still do not provide the specific information needed to answer the question. I will try a more focused SQL query to retrieve the specific section that discusses the experimental results and the reasoning behind the -inf in Fig. 3.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Experiments%' OR sections.section_title LIKE '%Results%' OR sections.section_title LIKE '%Discussion%';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"More Details and Results on Experiments\",\"section_content\":\"More Details and Results on Experiments\\nIn this appendix we fill the missing details in the experiment section. Our experiments are\\nimplemented with Intel Core i9 CPU of 32GB memory, no GPU is required and the execution\\ntime is no longer than 30 seconds. In the rest of this section, we first introduce the generation\\nprocess of synthetic datasets in Appendix E.1; Next we define the evaluation metrics and\\nperturbation approaches in Appendix E.2; More results on dissimilarities regarding the\\nscaled additive error, negative distances and negative eigenvalues selected, are demonstrated\\nin Appendix E.3.\\nWith respect to the dimensionality paradox, we provide illustrations\\nsimilar to Figure 2 on other datasets in Appendix E.4.\\nE.1\\nSynthetic Datasets Generation\\nThe random-simplex dataset is generated with the idea of creating a simplex with one\\nadded dimension that generates all of the variance in the the distances such that the added\\ndimension corresponds with a negative eigenvalue. This way, we should have a dimension\\nwith a large negative eigenvalue that is impactful on the stress of the embedding.\\nSpecifically, this dataset was generated with points x1, ...x1000, each point having 1000\\ndimensions. For each point xi, the first 100 coordinates were chosen uniformly randomly\\nbetween 0 and .01. The next 899 coordinates were chosen uniformly randomly between 0\\nand\\np\\n0.5\\/899. The last coordinate is i \\u00d7 0.3\\/1000. Then, the distance between xi and xj\\nwas found in the following way:\\nd(xi, xj) =\\nv\\nu\\nu\\nt\\n100\\nX\\nk=1\\n(xi(k) \\u2212xj(k))2 \\u2212\\n1000\\nX\\nk=101\\n(xi(k) \\u2212xj(k))2\\nwhere xi(k) is the kth coordinate of xi. The first 999 coordinates essentially form a simplex,\\nbecause selecting a large number of coordinates randomly from the same distribution causes\\nall of the distances to converge to a normal distribution with low variance. Thus, all of\\nthe distances between points using just the first 999 coordinates are very similar. Then,\\nthe last coordinate has \\u201clarge\\u201d discrepancies between all of the points, causing most of the\\ndifferences in the distances.\\nThe Euclidean-ball metric was inspired by [49]. The set of distances between objects in space\\ndoes not follow triangle inequality, so it becomes a non-euclidean dissimilarity measure. The\\nparticular dataset we use generates the distances by first randomly selecting 1000 points\\n21\\nuniformly in a 10 dimensional hypercube of length 100. Each of these points is now the\\ncenter of a ball. Then, for each ball, with probability 0.9, we select a radius uniformly\\nrandomly between 0 and 5. With probability 0.1, we let the radius be 0.8 times the distance\\nbetween the center of this ball to the closest other ball. This closest other ball is based on\\nthe radius of the other ball if it has already been decided. The final distance matrix is just\\nfilled by the distances between the 1000 balls. In this way, we attempt to create some balls\\nwith large radius, so that the triangle inequality is heavily violated, therefore causing the\\ndataset to deviate more from the Euclidean setting.\\nE.2\\nEvaluation and Perturbation Metrics\\nIn addition to STRESS, our evaluation metric include scaled additive error and average\\ngeometric distortion. Scaled additive error by definition is allowing scaling of the distance\\nmatrix of our embedding before calculating stress. To do this, we first ran the embedding\\nmethod (e.g., cMDS, Neuc-MDS, or other methods) on the given dissimilarity squared ma-\\ntrix D to get the output dissimilarity squared matrix \\u02dc\\nD. Then, we would flatten both D\\nand \\u02dc\\nD to vectors, and project D onto the line through \\u02dc\\nD to get E. Then we calculate\\n\\u2225D \\u2212E\\u2225to get scaled additive error. Clearly, this is equivalent to allowing scaling of \\u02dc\\nD\\nto find the minimum stress. For average geometric distortion, we again input D to get \\u02dc\\nD,\\nbut this time, we evaluate the distortion of each dissimilarity by dividing entries of\\n\\u221a\\nD by\\nentries of\\np\\n\\u02dc\\nD. Since distortion is not well defined when dissimilarities become complex,\\nwe skip those. Then, with the remaining valid distortions, we scale the distortions so that\\nthere\\u2019s an equal number of them greater than 1 and less than 1, then for those that remain\\nless than 1, we take their reciprocal. Then, we finally take the geometric average of all of\\nthese distortions. In this way, we basically again allowed scaling of the dissimilarities to find\\nthe minimum possible average distortion.\\nNext, we had to decide on metrics to use for the image datasets. We took the following\\n3 metrics from [38]. For the first metric, the distance between two images is first finding\\nthe Euclidean distance between their coordinate representations, and then adding Gaussian\\nnoise to the distances.\\nBecause the noise is added directly onto the distances, the end\\nresult is highly likely to be non-Euclidean. For the second metric, we build a k nearest\\nneighbor graph of the images based on their Euclidean distances. Since the end result is a\\ngraph structure, the shortest path distances are also highly likely to be non-Euclidean. For\\nthe third metric, we randomly removed entries from the coordinate representation of the\\nimages. Then, the distance between two images is decided by taking the Euclidean distance\\nbetween coordinates that both images still included. Here, the Euclidean property breaks\\ndown again because triangle inequality would no longer have to hold. In Table 2, we choose\\nthe k-NN metric with k = 2. In the next Appendix section, we show results for higher k and\\nother metrics applied to the image datasets. As for genomics datasets, we use the entropic\\naffinities commonly used in t-SNE methods. The main idea is to apply an adaptive kernel,\\nwhose bandwidth depends on a parameter termed as perplexity, to pairwise data entries.\\nE.3\\nMore Results on Dissimilarity Error\\nIn addition to STRESS and average distortion already reported in Table 2, we further show\\nthe third metric: scaled additive error as defined in Appendix E.2. Note that our algorithms\\nmay produce negative distances, we also report number of negative distances and number\\nof negative eigenvalues selected. All original results (without scaling) on 10 datasets are\\ndemonstrated in Table 6. Recall we mentioned the results in Table 2 contains some scaling\\non the synthetic data and images, we also provide the original values in Table 7.\\nOn scaled additive error, our proposed methods still consistently outperform cMDS and\\nLower-MDS considerably.\\nThus, we have shown that on all metrics our methods yield\\nmore favorable results. It is interesting to observe that Neuc-MDS+ produces much fewer\\nnegative distances than Neuc-MDS, though the number of negative eigenvalues selected are\\nquite close. Further, two methods have similar performance on STRESS and other metrics.\\nTherefore in practice, if there is a considerable concern on negative distances, Neuc-MDS+\\nshould become a better choice.\\n22\\nTable 6: Original Evaluation Results on All Datasets for Lower-MDS (L-MDS), Neuc-MDS\\n(N-MDS) and Neuc-MDS+ (N-MDS+). Metrics include scaled additive error, number of\\nnegative distances and number of negative eigenvalues selected.\\nDataset\\nScaled Additive Error\\n# Neg Distances\\n# Neg \\u03bb Selected\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nRandom-simplex\\n17758\\n17760\\n3415\\n1392\\n0\\n0\\n8\\n1\\nEuclidean-ball\\n14909\\n13093\\n3132\\n3631\\n798\\n523\\n90\\n87\\nBrain (50161)\\n0.131\\n0.132\\n0.063\\n0.062\\n5539\\n1081\\n8\\n9\\nBreast (45827)\\n0.039\\n0.039\\n0.016\\n0.015\\n9024\\n136\\n8\\n9\\nColorectal (44076)\\n0.027\\n0.027\\n0.012\\n0.014\\n12041\\n1940\\n6\\n8\\nLeukemia (28497)\\n0.031\\n0.031\\n0.021\\n0.023\\n32705\\n2102\\n8\\n10\\nRenal (53757)\\n0.018\\n0.018\\n0.013\\n0.014\\n6650\\n713\\n7\\n9\\nMNIST\\n7592\\n6126\\n3148\\n3.135\\n1006\\n68\\n42\\n43\\nFashion-MNIST\\n6153\\n4421\\n2.472\\n2.470\\n526\\n8\\n41\\n41\\nCIFAR10\\n3880\\n3564\\n2870\\n2.842\\n2968\\n201\\n43\\n44\\nTable 7: Original Evaluation Results on All Datasets. Metrics include STRESS and average\\ngeometric distortion\\nDataset\\nSTRESS\\nAverage Geometric Distortion\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\nRandom-simplex\\n28.376\\n17.760\\n3.433\\n1.392\\n1.049\\n1.049\\n1.010\\n1.004\\nEuclidean-ball\\n19.229\\n13.154\\n3.346\\n3.676\\n1.046\\n1.041\\n1.013\\n1.017\\nBrain (50161)\\n0.538\\n0.170\\n0.068\\n0.067\\n8.160\\n42.705\\n5.809\\n6.941\\nBreast (45827)\\n0.168\\n0.065\\n0.017\\n0.017\\n6.988\\n31.081\\n6.205\\n6.295\\nColorectal (44076)\\n0.121\\n0.047\\n0.013\\n0.016\\n23.938\\n34.587\\n20.234\\n22.475\\nLeukemia (28497)\\n0.172\\n0.079\\n0.028\\n0.031\\n6.551\\n32.214\\n7.032\\n6.749\\nRenal (53757)\\n0.070\\n0.030\\n0.016\\n0.019\\n21.709\\n38.282\\n19.680\\n21.223\\nMNIST\\n25.516\\n6.156\\n3.152\\n3.144\\n1.119\\n1.104\\n1.064\\n1.063\\nFashion-MNIST\\n18.771\\n4.422\\n2.475\\n2.473\\n1.135\\n1.096\\n1.068\\n1.068\\nCIFAR10\\n16.309\\n3.572\\n2.930\\n2.916\\n1.129\\n1.109\\n1.121\\n1.118\\nFigure 3: Dimensionality Paradox on Eight Datasets.\\nUntil now all results reported on images are using kNN metric with k = 2 to produce\\nnon-Euclidean dissimilarities. There could be other perturbations for the same purpose, as\\nmentioned in Appendix E.2. We further test with k = 10 and the other two metrics: adding\\nnoise and random removal on the STRESS. We add noise sampled from Gaussian distri-\\nbution with variance as the maximum instance-wise difference scaled by 500; For random\\nremoval, we skip 50 images for each. The results are shown in Table 8.\\n23\\nTable 8: Evaluation Results on Image Datasets with other perturbation metrics.\\nDataset\\nSTRESS\\n# Neg distances\\n# Neg \\u03bb Selected\\ncMDS\\nL-MDS\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nN-MDS\\nN-MDS+\\nMNIST (k = 10)\\n10080\\n1979\\n1827\\n1830\\n554\\n63\\n42\\n41\\nFashion (k = 10)\\n10249\\n2112\\n1936\\n1915\\n403\\n84\\n38\\n40\\nCIFAR10 (k = 10)\\n9032\\n1881\\n2309\\n2329\\n3236\\n996\\n39\\n37\\nMNIST (noise)\\n1.497e9\\n1.499e9\\n1.497e9\\n1.140e9\\n0\\n0\\n0\\n7\\nFashion (noise)\\n4.815e9\\n4.130e9\\n3.382e9\\n3.327e9\\n0\\n0\\n2\\n14\\nCIFAR10 (noise)\\n2.303e10\\n2.116e9\\n2.303e9\\n1.848e9\\n0\\n0\\n0\\n9\\nMNIST (missing)\\n3.281e8\\n1.010e8\\n3.281e8\\n1.010e8\\n0\\n0\\n0\\n0\\nFashion (missing)\\n5.165e8\\n1.726e8\\n5.165e8\\n1.726e8\\n0\\n0\\n0\\n0\\nCIFAR10 (missing)\\n2.132e9\\n5.756e8\\n2.132e9\\n5.756e8\\n0\\n0\\n0\\n0\\nE.4\\nMore Results on Dimensionality Paradox\\nThe purpose of this section is to show the consistent performance of Neuc-MDS and Neuc-\\nMDS+ on all datasets, with respect to mitigating the dimensionality paradox issue. There-\\nfore, in addition to Figure 2, we provide the same plots for other datasets, and the pa-\\nrameters all follow the main setup. Figure 3 gives a clear illustration that Neuc-MDS and\\nNeuc-MDS+ always have lower STRESS than cMDS and Lower-MDS as dimension grows.\\n24\\nNeurIPS Paper Checklist\\n1. Claims\\nQuestion: Do the main claims made in the abstract and introduction accurately\\nreflect the paper\\u2019s contributions and scope?\\nAnswer: [Yes]\\nJustification: We propose a generalization of classical multidimensional scaling to\\nhandle non-Euclidean non-metric data. We presented both a new algorithm, theo-\\nretical proofs on its performance, and experimental results.\\nGuidelines:\\n\\u2022 The answer NA means that the abstract and introduction do not include the\\nclaims made in the paper.\\n\\u2022 The abstract and\\/or introduction should clearly state the claims made, in-\\ncluding the contributions made in the paper and important assumptions and\\nlimitations. A No or NA answer to this question will not be perceived well by\\nthe reviewers.\\n\\u2022 The claims made should match theoretical and experimental results, and reflect\\nhow much the results can be expected to generalize to other settings.\\n\\u2022 It is fine to include aspirational goals as motivation as long as it is clear that\\nthese goals are not attained by the paper.\\n2. Limitations\\nQuestion: Does the paper discuss the limitations of the work performed by the\\nauthors?\\nAnswer: [Yes]\\nJustification: We discussed the limitation (and future work) of the proposed ap-\\nproach.\\nThese include: 1) developing downstream data analysis for using non-\\nEuclidean non-metrics data. 2) speeding up the algorithm for extremely large data\\n(e.g., by developing landmark based non-Euclidean MDS algorithms).\\nGuidelines:\\n\\u2022 The answer NA means that the paper has no limitation while the answer No\\nmeans that the paper has limitations, but those are not discussed in the paper.\\n\\u2022 The authors are encouraged to create a separate \\u201dLimitations\\u201d section in their\\npaper.\\n\\u2022 The paper should point out any strong assumptions and how robust the results\\nare to violations of these assumptions (e.g., independence assumptions, noise-\\nless settings, model well-specification, asymptotic approximations only holding\\nlocally). The authors should reflect on how these assumptions might be vio-\\nlated in practice and what the implications would be.\\n\\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach\\nwas only tested on a few datasets or with a few runs. In general, empirical\\nresults often depend on implicit assumptions, which should be articulated.\\n\\u2022 The authors should reflect on the factors that influence the performance of\\nthe approach. For example, a facial recognition algorithm may perform poorly\\nwhen image resolution is low or images are taken in low lighting. Or a speech-\\nto-text system might not be used reliably to provide closed captions for online\\nlectures because it fails to handle technical jargon.\\n\\u2022 The authors should discuss the computational efficiency of the proposed algo-\\nrithms and how they scale with dataset size.\\n\\u2022 If applicable, the authors should discuss possible limitations of their approach\\nto address problems of privacy and fairness.\\n\\u2022 While the authors might fear that complete honesty about limitations might\\nbe used by reviewers as grounds for rejection, a worse outcome might be that\\nreviewers discover limitations that aren\\u2019t acknowledged in the paper.\\nThe\\nauthors should use their best judgment and recognize that individual actions in\\n25\\nfavor of transparency play an important role in developing norms that preserve\\nthe integrity of the community. Reviewers will be specifically instructed to not\\npenalize honesty concerning limitations.\\n3. Theory Assumptions and Proofs\\nQuestion: For each theoretical result, does the paper provide the full set of assump-\\ntions and a complete (and correct) proof?\\nAnswer: [Yes]\\nJustification: Please refer to the theorem statements. We included all proofs in the\\nAppendix.\\nGuidelines:\\n\\u2022 The answer NA means that the paper does not include theoretical results.\\n\\u2022 All the theorems, formulas, and proofs in the paper should be numbered and\\ncross-referenced.\\n\\u2022 All assumptions should be clearly stated or referenced in the statement of any\\ntheorems.\\n\\u2022 The proofs can either appear in the main paper or the supplemental material,\\nbut if they appear in the supplemental material, the authors are encouraged to\\nprovide a short proof sketch to provide intuition.\\n\\u2022 Inversely, any informal proof provided in the core of the paper should be com-\\nplemented by formal proofs provided in appendix or supplemental material.\\n\\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced.\\n4. Experimental Result Reproducibility\\nQuestion: Does the paper fully disclose all the information needed to reproduce\\nthe main experimental results of the paper to the extent that it affects the main\\nclaims and\\/or conclusions of the paper (regardless of whether the code and data\\nare provided or not)?\\nAnswer: [Yes]\\nJustification: We provided all details of our experiments in the Appendix. We also\\nshared our code using an anonymous Github repository. See the footnote on Page\\n2.\\nGuidelines:\\n\\u2022 The answer NA means that the paper does not include experiments.\\n\\u2022 If the paper includes experiments, a No answer to this question will not be\\nperceived well by the reviewers: Making the paper reproducible is important,\\nregardless of whether the code and data are provided or not.\\n\\u2022 If the contribution is a dataset and\\/or model, the authors should describe the\\nsteps taken to make their results reproducible or verifiable.\\n\\u2022 Depending on the contribution, reproducibility can be accomplished in various\\nways. For example, if the contribution is a novel architecture, describing the\\narchitecture fully might suffice, or if the contribution is a specific model and\\nempirical evaluation, it may be necessary to either make it possible for others\\nto replicate the model with the same dataset, or provide acces ...\"}\n\n... # only display 1 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The retrieved section does not provide the specific information needed to answer the question. I will try a more focused similarity search to find the exact method that performs the best on ID states with the full-chain setting and the reason for -inf in Fig. 3.\n[Action]:\nClassicRetrieve(query=\"In the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning', which method performs the best on ID states with full-chain setting? Why is there -inf in Fig. 3?\", limit=10)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.6804,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.6659,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.6141,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.5956,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"2e290870-d308-5f8e-8c97-6e16ec63f9d6\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nTable 2. Causal Graph Accuracy for CDL with Different Transition\\nCollection Policies\\nMethod\\nPredDiff (Ours)\\nUniform\\nCuriosity\\nAccuracy (%)\\n90.2 \\u00b1 0.3\\n89.1 \\u00b1 0.6\\n88.9 \\u00b1 0.2\\nC.3.2. For ID states, all methods show similar prediction\\nperformance. However, for OOD states, the performance of\\ndense models drops signi\\ufb01cantly as they suffer from spuri-\\nous correlations while CDL and Reg mask those out with the\"}\n{\"score\":0.5683,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"770de309-1a7c-51cc-b656-cf2530612cc1\",\"text\":\"of the inaccurately learned causal graphs.\\nFurthermore, to test the generalization of the learned poli-\\ncies, we evaluate their performance for 100 episodes on\\nboth ID and OOD states, as shown in Fig. 8. Again, CDL\\ngeneralizes the best across all methods on OOD states.\\n5. Conclusions\\nIn this work, we introduce CDL, Causal Dynamics Learn-\\ning for Task-Independent State Abstraction. In contrast to\\nmost existing MBRL methods that learn a dense dynamics\"}\n{\"score\":0.5617,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e4dd2fa8-1f20-53fb-accd-516b4fdcf3c4\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nZizhao Wang 1 Xuesu Xiao 2 Zifan Xu 2 Yuke Zhu 2 Peter Stone 2 3\\nAbstract\\nLearning dynamics models accurately is an impor-\\ntant goal for Model-Based Reinforcement Learn-\\ning (MBRL), but most MBRL methods learn a\\ndense dynamics model which is vulnerable to spu-\\nrious correlations and therefore generalizes poorly\\nto unseen states.\\nIn this paper, we introduce\\nCausal Dynamics Learning for Task-Independent\"}\n{\"score\":0.5532,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"4f2fa982-0020-5acc-9895-d9d907ae6091\",\"text\":\"task-independent state abstraction. In International Conference on Machine Learning, pages\\n23151\\u201323180. PMLR, 2022.\\n[60] Will Williams, Sam Ringer, Tom Ash, David MacLeod, Jamie Dougherty, and John Hughes.\\nHierarchical quantized autoencoders. Advances in Neural Information Processing Systems, 33:\\n4524\\u20134535, 2020.\\n[61] Weiran Yao, Guangyi Chen, and Kun Zhang. Learning latent causal dynamics. arXiv preprint\\narXiv:2202.04828, 2022.\"}\n{\"score\":0.5442,\"pdf_id\":\"5ebc56ef-411b-5842-89ff-24f6adc31fe0\",\"page_number\":11,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e99e0d50-4d31-5be3-bb16-1225838415fb\",\"text\":\"in-the-loop causal discovery under latent confounding using ancestral gflownets.\\narXiv\\npreprint:2309.12032, 2023.\\n[14] M. P. Deisenroth and C. E. Rasmussen. PILCO: A model-based and data-efficient approach to\\npolicy search. In ICML, Proceedings of Machine Learning Research, pages 465\\u2013472. PMLR,\\n2011.\\n[15] T. Deleu, A. G\\u00f3is, C. C. Emezue, M. Rankawat, S. Lacoste-Julien, S. Bauer, and Y. Bengio.\\nBayesian structure learning with generative flow networks. In UAI, 2022.\"}\n{\"score\":0.5392,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n{\"score\":0.5322,\"pdf_id\":\"4bf87140-b2d2-5435-86b7-ed66c30d8bd8\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"fee33440-c8c0-5999-9802-3c4dd7412325\",\"text\":\"CDL [24] uses causal discovery to learn a task-independent world model. Denoised MDP [12] and\\nIFactor [13] conduct causal state abstraction based on their controllability and reward relevance.\\nThe last three methods are designed for online settings, so we only implement their model learning\\nobjectives. We attach more details of the baseline implementation in Appendix C.6.\\n4.2\\nExperiment Results Analysis\\nWe empirically answer the following research questions.\"}\n\nIn total, 10 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The retrieved chunks still do not provide the specific information needed to answer the question. I will try a more focused SQL query to retrieve the specific section that discusses the experimental results and the reasoning behind the -inf in Fig. 3.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Results%' OR sections.section_title LIKE '%Discussion%' OR sections.section_title LIKE '%Experiments%';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"4 Results and Discussions\",\"section_content\":\"\"}\n{\"section_title\":\"4 Results and Discussion\",\"section_content\":\"\"}\n{\"section_title\":\"5 Results and Discussion\",\"section_content\":\"\"}\n{\"section_title\":\"4.2 Results and Discussion\",\"section_content\":\"Results of our method are shown in Table 1. LLMs, due to their limitations, perform poorly as a standalone model for long-tail classifcation. These results can be improved by priming the model with an entailment predictor through the usage of a prompt. The baseline shows strong performance independent of the LLM, as it operates on a closed label space. The capabilities of the baseline can be enhanced by further explicitly priming it with a entailment relation through a LLM. Rows in which T0pp is initialized, or primed with $\\\\mathbb{E}$ are indicated with Primed. Priming the model showcases improvements across all datasets for macro F1. For accuracy, priming the model shows beneft in two out of three datasets. In Figure 4, we show the results of Top-5 predictions for the WOS dataset.\\nAll results are aggregated in Table 1. It is important to highlight that prompt variation led to stable results for our LLM. The variance upon utilizing BART-MNLI is negligible across prompts. The best results are observed upto Top-4 predictions on both accuracy and macro F1 for our method, when the entailment prompt is enhanced with a greater number of tokens corresponding to the output of $\\\\mathbb{L}(\\\\mathbb{E}(X))$ . The variation between our method and the baseline is much greater for Top-1 predictions, but Top-5 prediction variance is negligible. Detailed results for both depth settings of Amazon Beauty are shown in Appendix C.\"}\n{\"section_title\":\"6 Results and Discussion\",\"section_content\":\"We now turn to a discussion of the results for the intrinsic (accuracy) and extrinsic (answer rate and relevance) evaluation strategies.\\nTable 1: Evaluation results from the human study on reformulation accuracy and answer relevance. For answer relevance, in brackets are shown the extrapolated estimations of the absolute percentages of answered questions from Table 3 and their respective answer relevance. $\\\\scriptstyle\\\\mathrm{Roo+GEN}$ obtains the highest answer rate and relevance with $13.1\\\\%$ or $131\\\\mathrm{k}$ questions.\\nTable 1 shows the human evaluation results for reformulation accuracy. The best accuracy is achieved for GEN, with $83\\\\%$ of the reformulations being accurate. This is because GEN does not require changing the question type like ROO.\\nREP achieves second best accuracy. One reason for the slightly lower accuracy than GEN, is that it sometimes changes the question type (e.g. request to root), which goes beyond the REP\\u2019s reformulation scope. Although according to our intrinsic evaluation strategy such cases represent inaccurate reformulation, in practice this is benign as QA systems perform very well on root factoid questions.\\nFinally, we note that reformulations signifcantly shorten the input questions and result in higher type-token ratio (Appendix H). We list many examples of model input\\/output pairs in Appendix I.\\nTable 2: Results for the baseline and SURF models using different reformulation types on our test set.\"}\n{\"section_title\":\"5 Results and Discussions\",\"section_content\":\"\"}\n\n... # only display 6 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
{"role": "assistant", "content": "[Thought]: The retrieved sections still do not provide the specific information needed to answer the question. I will try a more targeted similarity search to find the exact method that performs the best on ID states with the full-chain setting and the reason for -inf in Fig. 3.\n[Action]:\nClassicRetrieve(query=\"In the paper 'Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning', which method performs the best on ID states with full-chain setting? Why is there -inf in Fig. 3?\", limit=10)"}
{"role": "user", "content": "[Observation]:\n{\"score\":0.6804,\"pdf_id\":\"0142149a-5c51-5917-bf03-0a62c623ffc2\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"14e8c2c6-fa9f-5b5a-b587-b94aa6d988a8\",\"text\":\"[45] Inwoo Hwang, Yunhyeok Kwak, Suhyung Choi, Byoung-Tak Zhang, and Sanghack Lee. Quan-\\ntized local independence discovery for fine-grained causal dynamics learning in reinforcement\\nlearning, 2024. URL https:\\/\\/openreview.net\\/forum?id=9UGAUQjibp.\\n[46] Danru Xu, Dingling Yao, S\\u00e9bastien Lachapelle, Perouz Taslakian, Julius von K\\u00fcgelgen,\\nFrancesco Locatello, and Sara Magliacane. A sparsity principle for partially observable causal\"}\n{\"score\":0.6659,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e59f5ef9-ed7f-5ce8-aafb-d8a64c40ed5b\",\"text\":\"Quantized Local Independence Discovery for\\nFine-Grained Causal Dynamics Learning in\\nReinforcement Learning\\nInwoo Hwang1\\nYunhyeok Kwak1\\nSuhyung Choi1\\nByoung-Tak Zhang\\u22171\\nSanghack Lee\\u22172\\n1AI Institute, Seoul National University\\n2Graduate School of Data Science, Seoul National University\\nAbstract\\nIncorporating causal relationships between the variables into dynamics learning\\nhas emerged as a promising approach to enhance robustness and generalization\"}\n{\"score\":0.6141,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":5,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"a988fdd9-b4f5-5d09-9a54-375a73f20b16\",\"text\":\"approach to find such decomposition for robust and fine-grained dynamics modeling in MBRL.\\n3.3\\nCausal dynamics learning with quantized local independence discovery\\nAs described above, the decomposition and corresponding graphs that maximize the score (Eq. (4)),\\ni.e., { \\u02c6\\nGz, \\u02c6\\nEz}K\\nz=1 \\u2208argmax{Gz,Ez} S({Gz, Ez}K\\nz=1), provide a fine-grained understanding of the\\ndynamics. Our goal is to (i) find decomposition (i.e., {Ez}) which captures meaningful contexts, (ii)\"}\n{\"score\":0.5956,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"2e290870-d308-5f8e-8c97-6e16ec63f9d6\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nTable 2. Causal Graph Accuracy for CDL with Different Transition\\nCollection Policies\\nMethod\\nPredDiff (Ours)\\nUniform\\nCuriosity\\nAccuracy (%)\\n90.2 \\u00b1 0.3\\n89.1 \\u00b1 0.6\\n88.9 \\u00b1 0.2\\nC.3.2. For ID states, all methods show similar prediction\\nperformance. However, for OOD states, the performance of\\ndense models drops signi\\ufb01cantly as they suffer from spuri-\\nous correlations while CDL and Reg mask those out with the\"}\n{\"score\":0.5683,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"770de309-1a7c-51cc-b656-cf2530612cc1\",\"text\":\"of the inaccurately learned causal graphs.\\nFurthermore, to test the generalization of the learned poli-\\ncies, we evaluate their performance for 100 episodes on\\nboth ID and OOD states, as shown in Fig. 8. Again, CDL\\ngeneralizes the best across all methods on OOD states.\\n5. Conclusions\\nIn this work, we introduce CDL, Causal Dynamics Learn-\\ning for Task-Independent State Abstraction. In contrast to\\nmost existing MBRL methods that learn a dense dynamics\"}\n{\"score\":0.5617,\"pdf_id\":\"5b01591b-d5e4-55ee-a33d-e11a6d0d1901\",\"page_number\":1,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e4dd2fa8-1f20-53fb-accd-516b4fdcf3c4\",\"text\":\"Causal Dynamics Learning for Task-Independent State Abstraction\\nZizhao Wang 1 Xuesu Xiao 2 Zifan Xu 2 Yuke Zhu 2 Peter Stone 2 3\\nAbstract\\nLearning dynamics models accurately is an impor-\\ntant goal for Model-Based Reinforcement Learn-\\ning (MBRL), but most MBRL methods learn a\\ndense dynamics model which is vulnerable to spu-\\nrious correlations and therefore generalizes poorly\\nto unseen states.\\nIn this paper, we introduce\\nCausal Dynamics Learning for Task-Independent\"}\n{\"score\":0.5532,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":13,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"4f2fa982-0020-5acc-9895-d9d907ae6091\",\"text\":\"task-independent state abstraction. In International Conference on Machine Learning, pages\\n23151\\u201323180. PMLR, 2022.\\n[60] Will Williams, Sam Ringer, Tom Ash, David MacLeod, Jamie Dougherty, and John Hughes.\\nHierarchical quantized autoencoders. Advances in Neural Information Processing Systems, 33:\\n4524\\u20134535, 2020.\\n[61] Weiran Yao, Guangyi Chen, and Kun Zhang. Learning latent causal dynamics. arXiv preprint\\narXiv:2202.04828, 2022.\"}\n{\"score\":0.5442,\"pdf_id\":\"5ebc56ef-411b-5842-89ff-24f6adc31fe0\",\"page_number\":11,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"e99e0d50-4d31-5be3-bb16-1225838415fb\",\"text\":\"in-the-loop causal discovery under latent confounding using ancestral gflownets.\\narXiv\\npreprint:2309.12032, 2023.\\n[14] M. P. Deisenroth and C. E. Rasmussen. PILCO: A model-based and data-efficient approach to\\npolicy search. In ICML, Proceedings of Machine Learning Research, pages 465\\u2013472. PMLR,\\n2011.\\n[15] T. Deleu, A. G\\u00f3is, C. C. Emezue, M. Rankawat, S. Lacoste-Julien, S. Bauer, and Y. Bengio.\\nBayesian structure learning with generative flow networks. In UAI, 2022.\"}\n{\"score\":0.5392,\"pdf_id\":\"1e3d6210-2df4-5eba-92d6-beab951bf795\",\"page_number\":4,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"50d50dbe-bd04-5d15-87b3-8194698dd520\",\"text\":\"3\\nFine-Grained Causal Dynamics Learning\\nWe first describe a brief background on the local independences and local causal graph that represents\\nthe fine-grained causal relationships (Sec. 3.1). We then formulate a problem of finding the optimal\\ndecomposition and describe its implications (Sec. 3.2). As a practical approach, we present our\\nproposed causal dynamics model that discovers decomposition and event-specific causal relationships\"}\n{\"score\":0.5322,\"pdf_id\":\"4bf87140-b2d2-5435-86b7-ed66c30d8bd8\",\"page_number\":8,\"table_name\":\"chunks\",\"column_name\":\"text_content\",\"primary_key\":\"fee33440-c8c0-5999-9802-3c4dd7412325\",\"text\":\"CDL [24] uses causal discovery to learn a task-independent world model. Denoised MDP [12] and\\nIFactor [13] conduct causal state abstraction based on their controllability and reward relevance.\\nThe last three methods are designed for online settings, so we only implement their model learning\\nobjectives. We attach more details of the baseline implementation in Appendix C.6.\\n4.2\\nExperiment Results Analysis\\nWe empirically answer the following research questions.\"}\n\nIn total, 10 rows are displayed in JSON format."}
{"role": "assistant", "content": "[Thought]: The retrieved chunks still do not provide the specific information needed to answer the question. I will try a more focused SQL query to retrieve the specific section that discusses the experimental results and the reasoning behind the -inf in Fig. 3.\n[Action]:\nRetrieveFromDatabase(sql=\"SELECT sections.section_title, sections.section_content FROM sections JOIN metadata ON sections.ref_paper_id = metadata.paper_id WHERE metadata.paper_id = '1e3d6210-2df4-5eba-92d6-beab951bf795' AND sections.section_title LIKE '%Results%' OR sections.section_title LIKE '%Discussion%' OR sections.section_title LIKE '%Experiments%';\")"}
{"role": "user", "content": "[Observation]:\n{\"section_title\":\"5 Results and Discussions\",\"section_content\":\"Table 3 reports the comparison results on two existing ASQP datasets. Since all methods apply the same splitting on these two datasets, we copy the results of baselines from corresponding references. The results show that: (1) Generation-based methods gain signifcant improvement over pipelinebased methods as pipeline-based methods tend to propagate the errors. (2) Regarding generationbased methods, OTG attains the best performance on the F1 score. The exceptional performance may come from integrating various features, e.g., syntax and semantic information, for forming the opinion tree structure (Bao et al., 2022). (3) Our OneASQP is competitive with generation-based methods. By checking the LM sizes, we know that the generation-based baselines except BARTABSA apply T5-base as the LM, which consists of 220M parameters. In comparison, our One-ASQP model utilizes DeBERTaV3, which consists of only 86M and 304M backbone parameters for its base and large versions, respectively. The compact model parameter size is a crucial advantage of our approach. However, on the Restaurant-ACOS and Laptop-ACOS datasets, One-ASQP falls slightly behind some generation-based methods that can take advantage of the semantics of sentiment elements by generating natural language labels. In contrast, One-ASQP maps each label to a specifc symbol, similar to the numerical indexing in classifcation models. Unfortunately, the limited quantity of these datasets prevents our One-ASQP model from achieving optimal performance.\\n\\nWe further conduct experiments on en-Phone and zh-FoodBeverage and compare our OneASQP with three strong baselines, Extract-ClassifyACOS, Paraphrase, and GEN-SCL-NAT. We select them because Extract-Classify-ACOS is the best pipeline-based method. Furthermore, Paraphrase and GEN-SCL-NAT are two strong generationbased baselines releasing source codes, which is easier for replication. Results in Table 4 are averaged by fve runs with different random seeds and show that our One-ASQP, even when adopting the base LM version, outperforms three strong baselines. We conjecture that good performance comes from two reasons: (1) The newly-released datasets contain higher quadruple density and fne-grained sentiment quadruples. This increases the task diffculty and amplifes the order issue in generationbased methods (Mao et al., 2022), i.e., the orders between the generated quads do not naturally exist, or the generation of the current quads should not condition on the previous ones. More evaluation tests are provided in Sec. 5.4. (2) The number of categories in the new datasets is much larger than Restaurant-ACOS and Laptop-ACOS. This also increases the search space, which tends to yield generation bias, i.e., the generated tokens neither come from the original text nor the pre-defned categories and sentiments. Overall, the results demonstrate the signifcance of our released datasets for further technical development.\\nTable 5 reports the time cost (in seconds) of training in one epoch and inferring the models on Restaurant-ACOS and en-Phone; more results are in Appendix B.1. The results show that our OneASQP is much more effcient than the strong baselines as Extract-Classify-ACOS needs to encode twice and Paraphrase can only decode the token sequentially. To provide a fair comparison, we set the batch size to 1 and show the inference time in the round bracket. The overall results show that our One-ASQP is more effcient than the baselines. Our One-ASQP can infer the quadruples parallel, which is much favorite for real-world deployment.\"}\n{\"section_title\":\"Results and Discussion\",\"section_content\":\"RESULTS AND DISCUSSION\\n3.1\\nACCURACY ON THE SOLVATED FRAGMENTS DATASET\\nIn this section, we summarize the key metrics of training our MLFF model, presenting validation and\\ntest set performance. Overall, our predictions are correlated strongly with the ground truth, i.e., a\\nSpearman rank correlation coefficient of 0.99 was obtained for both the total energy of the system\\nand the norm of forces. We provide an overview of the absolute errors obtained for the validation\\nand test set in Appendix A.4. It demonstrates that our model achieves mean and median absolute\\nforce errors of 5.1 and 3.1 kcal\\/(mol\\u00b7 \\u02da\\nA), respectively. However, it also exhibits very large maximum\\nerrors, significantly effecting the mean error. Due to this observation, we conducted an analysis of\\nthe dataset, which is reported in Appendix A.5 and ideas on improving this dataset in future work are\\ndiscussed in section A.11 of the Appendix.\\n3.2\\nMD SIMULATIONS\\nTo assess the generalisation of the developed MLFF model to unseen structures beyond the test set, we\\nconduct MD simulations using the complete MD pipeline and validate (1) qualitatively the stability\\nof the simulations (i.e., molecules remain intact) and (2) quantitatively the accuracy of the predicted\\nforces compared to DFT, for a selection of snapshots from the trajectory. As test systems, we select\\n(i) two fragments from the original test set, (ii) a selection of small non-peptide molecules, and (iii)\\nadditional unseen peptide structures. The complete list of systems can be found in Table 1, in which\\nthe quantitative MD results are presented. We ran 100 ps simulations with a timestep of 1 fs and at a\\ntemperature of 300 K, and subsequently extracted 20 equidistant snapshots from the simulations to\\ncalculate DFT reference forces with the PySCF Sun et al. (2018) program. For each snapshot, a MAE\\nvalue was obtained and the mean, standard deviation, and maximum of these values are presented in\\nTable 1. For the peptide chignolin with 175 atoms, we restricted the DFT reference calculation to the\\ninitial structure of the simulation for which we obtained an MAE in forces of 2.4 kcal\\/(mol\\u00b7 \\u02da\\nA).\\n3\\nPublished at the GEM workshop, ICLR 2024\\nFor the qualitative analysis of all simulated molecular systems, we observed stable simulations.\\nVisual inspection of the trajectories mostly revealed physically reasonable simulations, however,\\na few untypical proton transfers were observed. In particular, protonated amino groups (\\u2212NH+\\n3 )\\nwere found to be strong proton donors and deprotonated carboxyl groups (\\u2212CO\\u2212\\n2 ) strong proton\\nacceptors. In Figure A3 in the Appendix, we depict an example of an unphysical proton transfer that\\nwas observed during the MD simulation of chignolin. A proton was transferred from a nitrogen atom\\nto the deprotonated carboxyl group. As this leaves the nitrogen atom behind with a formally negative\\ncharge, this proton transfer is unexpected and unphysical. Furthermore, we performed simulations\\nat elevated temperatures of 500 K as a stress test and observed that the simulations of most systems\\nremain stable. Only for the decaalanine system, the very high temperature leads to a decomposition\\nof the molecule after about five picoseconds of stable simulation time.\\nThe obtained force errors with respect to the DFT reference are between 0.8 and 4.0 kcal\\/(mol\\u00b7 \\u02da\\nA)\\non average, i.e., lower than the metrics reported in section 3.1. We suspect this mainly to be a\\nconsequence of the lower MD temperature that was used to sample the structures (300 K instead of\\n1000 K). Furthermore, we obtain more accurate forces for the peptide-like structures than for the\\ngeneric organic molecules, which can be explained by the peptide-derived nature of the training set.\\nWe also compared our forces to a GFN2-xTB reference, resulting in MAE values between 4.5 and\\n7.5 kcal\\/(mol\\u00b7 \\u02da\\nA), which underlines (a) the spread that exists even between DFT and semi-empirical\\nforces as well as (b) how our model is trained to reproduce the ones from accurate DFT calculations.\\nMoreover, we selected the molecules chignolin and decaalanine to perform long-running 5 ns MD\\nsimulations, (1) to verify the stability of the simulations and (2) generate Time-Independent Compo-\\nnent Analysis (TICA) and Root-Mean-Squared-Deviation (RMSD) plots (see Appendix A.7). We\\nalso plot the velocity autocorrelation function for the first picosecond of the decaalanine simulation\\n(see Appendix A.10).\\nTable 1: Mean absolute error (MAE) of the MLFF forces for snapshots along an MD trajectory with\\nrespect to revPBE-D3(BJ)\\/def2-TZVP. For each molecule, we provide the mean MAE of the snaphots,\\nthe standard deviation \\u03c3 and the maximum MAE (all values in kcal\\/(mol\\u00b7 \\u02da\\nA)).\\nMOLECULE\\nMEAN ERROR\\n\\u03c3\\nMAXIMUM ERROR\\nTEST SET FRAGMENT 1\\n0.809\\n0.094\\n1.101\\nTEST SET FRAGMENT 2\\n0.953\\n0.099\\n1.256\\nTRIPEPTIDE ACY\\n2.120\\n0.517\\n4.241\\nDECAALANINE (FOLDED)\\n1.854\\n0.225\\n2.693\\nDECAALANINE (UNFOLDED)\\n1.806\\n0.075\\n1.944\\nPROPYL-ANTHRACENE\\n2.943\\n0.188\\n3.263\\nASPIRIN\\n3.017\\n0.272\\n3.470\\nCURCUMIN\\n3.951\\n0.352\\n4.738\\nFor chignolin, the execution time is approximately 30 seconds (see Figure A5 in the Appendix) for\\neach picosecond of simulation time with our MLFF\\/MD pipeline on a single NVIDIA Tesla V100\\nSXM3 GPU. Compared to a generic force field such as GFN-FF Spicher & Grimme (2020), this is\\naround ten times slower, however, compared to the semi-empirical method GFN2-xTB, our pipeline\\nprovides more than a 20-times speed-up (reference simulations are performed with the xTB program\\nBannwarth et al. (2021)). We emphasize that there exists potential to further accelerate our pipeline,\\nfor example, by parallelising inference on multiple GPUs, running it on TPUs, or applying general\\ncode optimisations. In order for such improvement strategies to have a significant impact on the\\nexecution speed of the simulations, it is essential that the scaling of the model with system size\\nfollows a linear relationship (such as in classical force fields with an LR interaction cutoff distance)\\nrather than a quadratic or cubic one (such as for semi-empirical QC methods). To confirm that our\\nmodel exhibits this linear scaling, we visualise the execution times with respect to the number of\\natoms for our test molecules in Figure A5. As we expect the bottleneck of the model inference to be\\nattributed to the GNN and not to the LR interaction correction term, the 5 \\u02da\\nA graph cutoff should be\\nsmall enough such that we observe a linear scaling already for these test molecules comprised of less\\nthan 200 atoms. The results presented in Figure A5 confirm this assumption.\\n4\\nPublished at the GEM workshop, ICLR 2024\\n3.3\\nENERGY MINIMISATIONS\\nIn this section, we analyse the performance of the MLFF model for accurate energy minimisations\\n(structure optimisations). As mentioned in section 2.2, we have applied the FIRE algorithm Bitzek\\net al. (2006) to six test molecules, namely; tripeptide ACY; propyl-anthracene; curcumin; aspirin;\\nand two fragments from the test set included in section 3.2. The FIRE algorithm has been run with\\nan initial timestep of 0.5 fs, a maximum timestep of 2 fs, and all other parameters set to the defaults\\nof the JAX-MD engine. In a successful and stable energy minimisation, the atomic forces should\\nconverge at zero, hence, resulting in the atom positions to remain unchanged after convergence.\\n0\\n250\\n500\\n750\\n1000\\n1250\\n1500\\n1750\\n2000\\nMinimization step\\n0\\n10\\n20\\n30\\n40\\n50\\nForce norm in kcal\\/(mol \\u00c5)\\nACY\\npropyl-anthracene\\ncurcumin\\naspirin\\ntest set frag. 1\\ntest set frag. 2\\n0\\n250\\n500\\n750\\n1000\\n1250\\n1500\\n1750\\n2000\\nMinimization step\\n0.000\\n0.005\\n0.010\\n0.015\\nRMSD in \\u00c5\\nACY\\npropyl-anthracene\\ncurcumin\\naspirin\\ntest set frag. 1\\ntest set frag. 2\\nFigure 1: Norm of forces (left) and change in RMSD (right) during an MLFF energy minimisation.\\nIn Figure 1, we demonstrate that the developed MLFF model fulfills these two criteria. After 500\\nminimisation steps, we observe a \\u2206RMSD between steps of less than 0.001 \\u02da\\nA for all molecules and\\nobserve full convergence after at most 1000 steps for all but one of the test set fragments. Note that\\nboth test set fragments consist of two non-covalently bonded substructures that are typically prone to\\nmore difficult convergence. Furthermore, we observe a stable convergence of the forces to zero. For\\ntwo molecules, the tripeptide and the second test set fragment, we observe small fluctuations in forces\\nafter 1000 steps, which appear to not result in significant fluctuations in the positions. We contribute\\nthose to numerical instabilities that can be potentially resolved by fine-tuning the parameters of the\\nFIRE algorithm.\\nTo assess the quality of the minimisation result, we optimised all six test structures with DFT\\nemploying the PSI4 Parrish et al. (2017) quantum chemistry program with its default settings. To\\nthese ground truth results, we compare (1) the initial structure, (2) a structure optimised with the\\nGFN2-xTB method using the xTB program Bannwarth et al. (2021), and (3) the final structure after\\nenergy minimisation with the MLFF model. We compute the MAE of bond distances and bond angles\\nto assess local structural agreement and the RMSD to assess global conformational alignment. As\\npresented in Table A3 in the Appendix, we observe that the errors on bond distances are smaller for\\nthe MLFF method as compared with GFN2-xTB for all tested molecules. The bond angle errors of\\nGFN2-xTB and the MLFF are similar. For RMSD, the MLFF exhibits similar errors as GFN2-xTB as\\nwell. In particular, we observe more accurate results for the test set fragments and the tripeptide than\\nfor the other systems, which can be explained by the peptide-based training set of the MLFF model.\\nIn Figure A4 in the Appendix, we present a visual comparison of the initial structure to the final\\nstructures obtained from energy minimisations with the MLFF model and the DFT reference. In the\\ntwo selected examples, it becomes clear that the optimised structures differ significantly from the\\ninitial structures, however, the structures of the MLFF model compared to the DFT reference, are\\nsimilar, underlining the MLFF model\\u2019s ability to run stable and accurate energy minimisations for\\nthe systems investigated in this work.\\n4\"}\n{\"section_title\":\"Results and Discussions\",\"section_content\":\"Results and Discussions\\nj-IR-vis was pretrained to detect the presence of 9 functional groups from IR spectra, specifically,\\nalcohols, amines, esters, ketones, aldehydes, carboxylic acids, ethers, amides, and nitro compounds.\\nNotably, alkenes and alkynes were omitted from j-IR-vis\\u2019s training due to their characteristically\\nlow-intensity signals in IR spectra. j-IR-vis was most successful at predicting aldehydes, amides,\\ncarboxylic acids, and nitro groups (Fig. 2(b)), as these functional groups exhibit more than one\\nhigh-intensity stretching vibration in the 1500-4000 cm\\u22121 region of IR spectra. Additional results\\nare presented in Table 1.\\nj-IR-vis was most challenged at predicting alcohols, amines, ethers, esters, and ketones (Fig. 2(b)).\\nWhile alcohols and amines possess O\\u2212H and N\\u2212H stretching vibrations that produce strong signals\\nbetween 3100-3500 cm\\u22121, we believe that the model struggled to identify these groups due to the\\nquality of IR spectra obtained from the NIST database. The IR spectra used were primarily based\\non gas-phase data and the O\\u2212H and N\\u2212H stretching signals possessed lower intensities than what\\nwould be expected for these functional groups. Ether functional groups exhibit only a C\\u2212O stretch\\nbetween 1000-1300 cm\\u22121; however, this signal is contained in the fingerprint region (< 1500 cm\\u22121).\\nThe fingerprint region in IR spectra contains many stretching and bending vibrations common to\\norganic molecules (e.g., C\\u2212C, C\\u2212O, C\\u2212N) and as such it may be difficult for j-IR-vis to distinguish\\nthe C\\u2212O signal from other signals in this region. Lastly, ketones and esters show strong signals\\nfor the C\\u2212\\n\\u2212O stretch between 1700-1750 cm\\u22121; however, neither of these functional groups exhibit\\nanother vibration that allows them to be definitively identified over other carbonyl-based functional\\ngroups as seen for aldehydes, amides, and carboxylic acids.\\nAs outlined in the Methodology Section, we tested both the joint training of Spectro with j-IR-\\nvis, and Spectro with fixed IR and NMR embeddings. To quantify the model\\u2019s accuracy, we\\nemployed two metrics, Tanimoto Similarity (TS) and the Number of Wrong Tokens (NWT), defined\\nas, NWT(y, \\u02c6\\ny) = PM\\ni 1\\u2212\\u03b4(yi = \\u02c6\\nyi) where y and \\u02c6\\ny represent the tokens of the predicted and target\\nmolecule respectively, and M is the total number of tokens, M = 45. For all molecules, the TS was\\ncomputed using RDKit with 2, 048 bits.\\nIn Fig. 3 we present the results for the entire test dataset for the TS and NWT metrics. Spectro\\naccurately predicts 88% of molecules (TS = 1) when trained with fixed embeddings from IR, 1H,\\nand 13C NMR data, and the accuracy improves to 93% when jointly trained with j-IR-vis (Fig. 3(a)).\\nA similar accuracy is observed using the NWT metric, with Spectro making no token prediction\\nerrors for 91% of the test molecules. Joint training of Spectro provides further insight into molecular\\nstructure through fine-tuning of j-IR-vis. Furthermore, Spectro achieved 90.42% and 95.61% on\\nTop-1 and Top-2 sequence-wise accuracy, respectively. Spectro predicts more than four tokens in\\nonly 1.4% of the test data (see the insight in Fig. 3(a)). Finally, Fig. 3(b) and Fig. 6(e) in the SM\\nshowcase some of Spectro\\u2019s predictions for the test molecules when using only NMR data, compared\\nto when both IR and NMR embeddings are combined.\\nIn addition to TS and NWT, we assessed Spectro\\u2019s accuracy using the hydrogen deficiency index\\n(HDI) (Fig. 6(a) in the SM), which measures the degree of unsaturation in molecules, and the\\n4\\nFigure 3: a) Histograms of Tanimoto Similarity and the number of wrong tokens. b) Predicted\\nmolecules with Spectro, and the TS.\\nmolecular weight (MW) (Fig. 6(b) in the SM). Spectro shows a linear correlation between the\\npredicted and true values of HDI and MW, indicating its effectiveness in capturing the structure and\\nsize of the molecule. Finally, our results further demonstrate that Spectro is not biased toward specific\\nmolecular sizes (Fig. 6(d) in the SM), as the mean of the TS for wrongly predicted molecules (TS<1)\\nis around 0.25\\u20130.3 across all molecular weights.\\n4\"}\n\n... # only display 3 rows in JSON format, more are truncated due to length constraint based on max_tokens (5000)"}
