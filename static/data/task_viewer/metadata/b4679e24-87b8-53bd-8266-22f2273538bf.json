{
    "uuid": "b4679e24-87b8-53bd-8266-22f2273538bf",
    "title": "Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting",
    "conference_full": "The 2023 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: EMNLP 2023",
    "bibtex": "@inproceedings{ye-etal-2023-enhancing,\n    title = \"Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting\",\n    author = \"Ye, Fanghua  and\n      Fang, Meng  and\n      Li, Shenghui  and\n      Yilmaz, Emine\",\n    editor = \"Bouamor, Houda  and\n      Pino, Juan  and\n      Bali, Kalika\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2023\",\n    month = dec,\n    year = \"2023\",\n    address = \"Singapore\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-emnlp.398\",\n    doi = \"10.18653/v1/2023.findings-emnlp.398\",\n    pages = \"5985--6006\",\n    abstract = \"Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a {``}rewrite-then-edit{''} process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.\",\n}\n",
    "authors": [
        "Fanghua Ye",
        "Meng Fang",
        "Shenghui Li",
        "Emine Yilmaz"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-emnlp.398.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2023/b4679e24-87b8-53bd-8266-22f2273538bf.pdf",
    "num_pages": 22,
    "abstract": "Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a “rewrite-then-edit” process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.",
    "tldr": "LLMs improve conversational search by generating informative query rewrites.",
    "tags": [
        "Conversational search",
        "query rewriting",
        "large language models",
        "informative rewrites",
        "retrieval performance"
    ]
}