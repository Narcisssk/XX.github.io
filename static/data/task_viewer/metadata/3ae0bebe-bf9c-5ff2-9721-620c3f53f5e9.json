{
    "uuid": "3ae0bebe-bf9c-5ff2-9721-620c3f53f5e9",
    "title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2023,
    "volume": "FMDM@NeurIPS2023",
    "bibtex": "@inproceedings{\nzheng2023synapse,\ntitle={Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control},\nauthor={Longtao Zheng and Rundong Wang and Xinrun Wang and Bo An},\nbooktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop},\nyear={2023},\nurl={https://openreview.net/forum?id=pI6ylnkPAD}\n}",
    "authors": [
        "Longtao Zheng",
        "Rundong Wang",
        "Xinrun Wang",
        "Bo An"
    ],
    "pdf_url": "https://openreview.net/pdf/7b8f79151a63a9c5421d7c3e2f9b44b09ea4c91a.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2023/3ae0bebe-bf9c-5ff2-9721-620c3f53f5e9.pdf",
    "num_pages": 31,
    "abstract": "Building agents with large language models (LLMs) for computer control is a burgeoning research area, where the agent receives computer states and performs actions to complete complex tasks. Previous computer agents have demonstrated the benefits of in-context learning (ICL); however, their performance is hindered by several issues. First, the limited context length of LLMs and complex computer states restrict the number of exemplars, as a single webpage can consume the entire context. Second, the exemplars in current methods, such as high-level plans and multi-choice questions, cannot represent complete trajectories, leading to suboptimal performance in long-horizon tasks. Third, existing computer agents rely on task-specific exemplars and overlook the similarity among tasks, resulting in poor generalization to novel tasks. To address these challenges, we introduce Synapse, a computer agent featuring three key components: i) state abstraction, which filters out task-irrelevant information from raw states, allowing more exemplars within the limited context, ii) trajectory-as-exemplar prompting, which prompts the LLM with complete trajectories of the abstracted states and actions for improved multi-step decision-making, and iii) exemplar memory, which stores the embeddings of exemplars and retrieves them via similarity search for generalization to novel tasks. We evaluate Synapse on MiniWoB++, a standard task suite, and Mind2Web, a real-world website benchmark. In MiniWoB++, Synapse achieves a 99.2% average success rate (a 10% relative improvement) across 64 tasks using demonstrations from only 48 tasks. Notably, Synapse is the first ICL method to solve the book-flight task in MiniWoB++. Synapse also exhibits a 56% relative improvement in average step success rate over the previous state-of-the-art prompting scheme in Mind2Web.",
    "tldr": "We introduce Synapse, a state-of-the-art computer agent featuring state abstraction, trajectory-as-exemplar prompting and exemplar memory.",
    "tags": [
        "web navigation",
        "large language models",
        "prompting"
    ]
}