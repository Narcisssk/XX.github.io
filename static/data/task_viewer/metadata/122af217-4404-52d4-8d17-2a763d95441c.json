{
    "uuid": "122af217-4404-52d4-8d17-2a763d95441c",
    "title": "CROWD: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack",
    "conference_full": "The 2024 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: EMNLP 2024",
    "bibtex": "@inproceedings{sun-etal-2024-crowd,\n    title = \"{CROWD}: Certified Robustness via Weight Distribution for Smoothed Classifiers against Backdoor Attack\",\n    author = \"Sun, Siqi  and\n      Sen, Procheta  and\n      Ruan, Wenjie\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.993/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.993\",\n    pages = \"17056--17070\",\n    abstract = \"Language models are vulnerable to clandestinely modified data and manipulation by attackers. Despite considerable research dedicated to enhancing robustness against adversarial attacks, the realm of provable robustness for backdoor attacks remains relatively unexplored. In this paper, we initiate a pioneering investigation into the certified robustness of NLP models against backdoor triggers.We propose a model-agnostic mechanism for large-scale models that applies to complex model structures without the need for assessing model architecture or internal knowledge. More importantly, we take recent advances in randomized smoothing theory and propose a novel weight-based distribution algorithm to enable semantic similarity and provide theoretical robustness guarantees.Experimentally, we demonstrate the efficacy of our approach across a diverse range of datasets and tasks, highlighting its utility in mitigating backdoor triggers. Our results show strong performance in terms of certified accuracy, scalability, and semantic preservation.\"\n}\n",
    "authors": [
        "Siqi Sun",
        "Procheta Sen",
        "Wenjie Ruan"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-emnlp.993.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2024/122af217-4404-52d4-8d17-2a763d95441c.pdf",
    "num_pages": 15,
    "abstract": "Language models are vulnerable to clandestinely modified data and manipulation by attackers. Despite considerable research dedicated to enhancing robustness against adversarial attacks, the realm of provable robustness for backdoor attacks remains relatively unexplored. In this paper, we initiate a pioneering investigation into the certified robustness of NLP models against backdoor triggers.We propose a model-agnostic mechanism for large-scale models that applies to complex model structures without the need for assessing model architecture or internal knowledge. More importantly, we take recent advances in randomized smoothing theory and propose a novel weight-based distribution algorithm to enable semantic similarity and provide theoretical robustness guarantees.Experimentally, we demonstrate the efficacy of our approach across a diverse range of datasets and tasks, highlighting its utility in mitigating backdoor triggers. Our results show strong performance in terms of certified accuracy, scalability, and semantic preservation.",
    "tldr": "Proposes a method for certifying robustness of NLP models against backdoor attacks.",
    "tags": [
        "certified robustness",
        "backdoor attacks",
        "language models",
        "randomized smoothing",
        "weight distribution"
    ]
}