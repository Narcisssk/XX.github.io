{
    "uuid": "0d247231-e960-5a59-aaee-f0706a8b9115",
    "title": "Semi-Supervised Sound Event Detection with Local and Global Consistency Regularization",
    "conference_full": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "conference": "icassp",
    "year": 2024,
    "volume": "ICASSP session AASP: Audio & Acoustic Signal Processing",
    "bibtex": "@inproceedings{DBLP:conf/icassp/LiW0TYO24,\n  author       = {Yiming Li and\n                  Xiangdong Wang and\n                  Hong Liu and\n                  Rui Tao and\n                  Long Yan and\n                  Kazushige Ouchi},\n  title        = {Semi-Supervised Sound Event Detection with Local and Global Consistency\n                  Regularization},\n  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,\n                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},\n  pages        = {271--275},\n  publisher    = {{IEEE}},\n  year         = {2024},\n  url          = {https://doi.org/10.1109/ICASSP48485.2024.10446386},\n  doi          = {10.1109/ICASSP48485.2024.10446386},\n  timestamp    = {Mon, 05 Aug 2024 15:27:25 +0200},\n  biburl       = {https://dblp.org/rec/conf/icassp/LiW0TYO24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}",
    "authors": [
        "Yiming Li",
        "Xiangdong Wang",
        "Hong Liu",
        "Rui Tao",
        "Long Yan",
        "Kazushige Ouchi"
    ],
    "pdf_url": "https://doi.org/10.1109/ICASSP48485.2024.10446386",
    "pdf_path": "data/dataset/airqa/papers/icassp2024/0d247231-e960-5a59-aaee-f0706a8b9115.pdf",
    "num_pages": 5,
    "abstract": "Learning meaningful frame-wise features on a partially labeled dataset is crucial to semi-supervised sound event detection. Prior works either maintain consistency on frame-level predictions or seek feature-level similarity among neighboring frames, which cannot exploit the potential of unlabeled data. In this work, we design a Local and Global Consistency (LGC) regularization scheme to enhance the model on both label- and feature-level. The audio CutMix is introduced to change the contextual information of clips. Then, the local consistency is adopted to encourage the model to leverage local features for frame-level predictions, and the global consistency is applied to force features to align with global prototypes through a specially designed contrastive loss. Experiments on the DESED dataset indicate the superiority of LGC, surpassing its respective competitors largely under the same settings. Besides, combining LGC with existing methods can obtain further improvements. The code is available at https://github.com/Ming-er/LGC-SED.",
    "tldr": "Enhances semi-supervised sound event detection using Local and Global Consistency.",
    "tags": [
        "semi-supervised learning",
        "sound event detection",
        "consistency regularization",
        "audio processing",
        "feature extraction"
    ]
}