{
    "uuid": "8528897c-c080-5a33-8af9-815ef526d204",
    "title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning",
    "conference_full": "The 2024 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2024,
    "volume": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{yin-etal-2024-mumath,\n    title = \"{M}u{M}ath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning\",\n    author = \"Yin, Shuo  and\n      You, Weihao  and\n      Ji, Zhilong  and\n      Zhong, Guoqiang  and\n      Bai, Jinfeng\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.274\",\n    doi = \"10.18653/v1/2024.emnlp-main.274\",\n    pages = \"4770--4785\",\n    abstract = \"The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math reasoning data. However, a great method to integrate the above two research paths and combine their advantages remains to be explored. In this work, we firstly include new math questions via **mu**lti-perspective data augmenting methods and then synthesize **code**-nested solutions to them. The open LLMs (e.g., Llama-2) are finetuned on the augmented dataset to get the resulting models, **MuMath-Code** ($\\mu$-Math-Code). During the inference phase, our MuMath-Code generates code and interacts with the external python interpreter to get the execution results. Therefore, MuMath-Code leverages the advantages of both the external tool and data augmentation. To fully leverage the advantages of our augmented data, we propose a two-stage training strategy: In Stage-1, we finetune Llama-2 on pure CoT data to get an intermediate model, which then is trained on the code-nested data in Stage-2 to get the resulting MuMath-Code.Our MuMath-Code-7B achieves 83.8{\\%} on GSM8K and 52.4{\\%} on MATH, while MuMath-Code-70B model achieves new state-of-the-art performance among open methods{---}achieving 90.7{\\%} on GSM8K and 55.1{\\%} on MATH. Extensive experiments validate the combination of tool use and data augmentation, as well as our two-stage training strategy.We release the proposed dataset along with the associated code for public use: https://github.com/youweihao-tal/MuMath-Code.\",\n}\n",
    "authors": [
        "Shuo Yin",
        "Weihao You",
        "Zhilong Ji",
        "Guoqiang Zhong",
        "Jinfeng Bai"
    ],
    "pdf_url": "https://aclanthology.org/2024.emnlp-main.274.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2024/8528897c-c080-5a33-8af9-815ef526d204.pdf",
    "num_pages": 16,
    "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math reasoning data. However, a great method to integrate the above two research paths and combine their advantages remains to be explored. In this work, we firstly include new math questions via **mu**lti-perspective data augmenting methods and then synthesize **code**-nested solutions to them. The open LLMs (e.g., Llama-2) are finetuned on the augmented dataset to get the resulting models, **MuMath-Code** (ùúá-Math-Code). During the inference phase, our MuMath-Code generates code and interacts with the external python interpreter to get the execution results. Therefore, MuMath-Code leverages the advantages of both the external tool and data augmentation. To fully leverage the advantages of our augmented data, we propose a two-stage training strategy: In Stage-1, we finetune Llama-2 on pure CoT data to get an intermediate model, which then is trained on the code-nested data in Stage-2 to get the resulting MuMath-Code.Our MuMath-Code-7B achieves 83.8% on GSM8K and 52.4% on MATH, while MuMath-Code-70B model achieves new state-of-the-art performance among open methods‚Äîachieving 90.7% on GSM8K and 55.1% on MATH. Extensive experiments validate the combination of tool use and data augmentation, as well as our two-stage training strategy.We release the proposed dataset along with the associated code for public use: https://github.com/youweihao-tal/MuMath-Code.",
    "tldr": "MuMath-Code enhances math reasoning by combining tool use and data augmentation.",
    "tags": [
        "Tool-Use LLMs",
        "Mathematical Reasoning",
        "Data Augmentation",
        "Code Generation",
        "Two-Stage Training"
    ]
}