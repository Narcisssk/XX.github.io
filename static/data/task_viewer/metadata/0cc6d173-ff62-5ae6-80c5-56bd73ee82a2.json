{
    "uuid": "0cc6d173-ff62-5ae6-80c5-56bd73ee82a2",
    "title": "Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach",
    "conference_full": "The 2023 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2023,
    "volume": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{singh-etal-2023-image,\n    title = \"Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach\",\n    author = \"Singh, Harman  and\n      Garg, Poorva  and\n      Gupta, Mohit  and\n      Shah, Kevin  and\n      Goswami, Ashish  and\n      Modi, Satyam  and\n      Mondal, Arnab  and\n      Khandelwal, Dinesh  and\n      Garg, Dinesh  and\n      Singla, Parag\",\n    editor = \"Bouamor, Houda  and\n      Pino, Juan  and\n      Bali, Kalika\",\n    booktitle = \"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2023\",\n    address = \"Singapore\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.emnlp-main.181\",\n    doi = \"10.18653/v1/2023.emnlp-main.181\",\n    pages = \"2975--3007\",\n    abstract = \"We are interested in image manipulation via natural language text {--} a task that is useful for multiple AI applications but requires complex reasoning over multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning (NSCL), which has been quite effective for the task of Visual Question Answering (VQA), for the task of image manipulation. Our system referred to as NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and only requires weak supervision in the form of annotated data for VQA. NeuroSIM parses an instruction into a symbolic program, based on a Domain Specific Language (DSL) comprising of object attributes and manipulation operations, that guides its execution. We create a new dataset for the task, and extensive experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA baselines that make use of supervised data for manipulation.\",\n}\n",
    "authors": [
        "Harman Singh",
        "Poorva Garg",
        "Mohit Gupta",
        "Kevin Shah",
        "Ashish Goswami",
        "Satyam Modi",
        "Arnab Mondal",
        "Dinesh Khandelwal",
        "Dinesh Garg",
        "Parag Singla"
    ],
    "pdf_url": "https://aclanthology.org/2023.emnlp-main.181.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2023/0cc6d173-ff62-5ae6-80c5-56bd73ee82a2.pdf",
    "num_pages": 33,
    "abstract": "We are interested in image manipulation via natural language text â€“ a task that is useful for multiple AI applications but requires complex reasoning over multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning (NSCL), which has been quite effective for the task of Visual Question Answering (VQA), for the task of image manipulation. Our system referred to as NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and only requires weak supervision in the form of annotated data for VQA. NeuroSIM parses an instruction into a symbolic program, based on a Domain Specific Language (DSL) comprising of object attributes and manipulation operations, that guides its execution. We create a new dataset for the task, and extensive experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA baselines that make use of supervised data for manipulation.",
    "tldr": "NeuroSIM enables image manipulation using weakly-supervised neuro-symbolic learning.",
    "tags": [
        "image manipulation",
        "multi-hop reasoning",
        "neuro-symbolic learning",
        "weak supervision",
        "visual question answering"
    ]
}