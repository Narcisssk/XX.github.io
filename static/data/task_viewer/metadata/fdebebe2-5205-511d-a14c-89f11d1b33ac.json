{
    "uuid": "fdebebe2-5205-511d-a14c-89f11d1b33ac",
    "title": "LMCodec: A Low Bitrate Speech Codec with Causal Transformer Models",
    "conference_full": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "conference": "icassp",
    "year": 2023,
    "volume": "ICASSP session SS: Signal Separation",
    "bibtex": "@inproceedings{DBLP:conf/icassp/JenrungrotCKSBZT23,\n  author       = {Teerapat Jenrungrot and\n                  Michael Chinen and\n                  W. Bastiaan Kleijn and\n                  Jan Skoglund and\n                  Zal{\\'{a}}n Borsos and\n                  Neil Zeghidour and\n                  Marco Tagliasacchi},\n  title        = {LMCodec: {A} Low Bitrate Speech Codec with Causal Transformer Models},\n  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing\n                  {ICASSP} 2023, Rhodes Island, Greece, June 4-10, 2023},\n  pages        = {1--5},\n  publisher    = {{IEEE}},\n  year         = {2023},\n  url          = {https://doi.org/10.1109/ICASSP49357.2023.10095442},\n  doi          = {10.1109/ICASSP49357.2023.10095442},\n  timestamp    = {Fri, 10 Nov 2023 19:45:41 +0100},\n  biburl       = {https://dblp.org/rec/conf/icassp/JenrungrotCKSBZT23.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}",
    "authors": [
        "Teerapat Jenrungrot",
        "Michael Chinen",
        "W. Bastiaan Kleijn",
        "Jan Skoglund",
        "Zalán Borsos",
        "Neil Zeghidour",
        "Marco Tagliasacchi"
    ],
    "pdf_url": "https://doi.org/10.1109/ICASSP49357.2023.10095442",
    "pdf_path": "data/dataset/airqa/papers/icassp2023/fdebebe2-5205-511d-a14c-89f11d1b33ac.pdf",
    "num_pages": 5,
    "abstract": "We introduce LMCodec, a causal neural speech codec that provides high quality audio at very low bitrates. The backbone of the system is a causal convolutional codec that encodes audio into a hierarchy of coarse-to-ﬁne tokens using residual vector quantization. LMCodec trains a Transformer language model to predict the ﬁne tokens from the coarse ones in a generative fashion, allowing for the transmission of fewer codes. A second Transformer predicts the uncertainty of the next codes given the past transmitted codes, and is used to perform conditional entropy coding. A MUSHRA subjective test was conducted and shows that the quality is comparable to reference codecs at higher bitrates. Example audio is available at https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec.",
    "tldr": "LMCodec achieves high-quality audio at low bitrates using causal Transformer models.",
    "tags": [
        "Low Bitrate",
        "Speech Codec",
        "Causal Transformer",
        "Residual Vector Quantization",
        "Audio Quality"
    ]
}