{
    "uuid": "23e4f6c4-0d28-52be-8ab4-7aef1c19b5ce",
    "title": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",
    "conference_full": "International Conference on Learning Representations",
    "conference": "ICLR",
    "year": 2024,
    "volume": "ICLR 2024 oral",
    "bibtex": "@inproceedings{\nasai2024selfrag,\ntitle={Self-{RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},\nauthor={Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hSyW5go0v8}\n}",
    "authors": [
        "Akari Asai",
        "Zeqiu Wu",
        "Yizhong Wang",
        "Avirup Sil",
        "Hannaneh Hajishirzi"
    ],
    "pdf_url": "https://openreview.net/pdf/9a78cf641fab9032078e65ae2734293ae8e2f398.pdf",
    "pdf_path": "data/dataset/airqa/papers/iclr2024/23e4f6c4-0d28-52be-8ab4-7aef1c19b5ce.pdf",
    "num_pages": 30,
    "abstract": "Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called **Self-Reflective Retrieval-Augmented Generation (Self-RAG)** that enhances an LM's quality and factuality through retrieval and self-reflection. \nOur framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. \nExperiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. \nSpecifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/",
    "tldr": "We introduce Self-RAG, a new training and inference framework to enable an LM learn to retrieve, generate and critique.",
    "tags": [
        "Retrieval-augmented Generation",
        "Language Models",
        "Retrieval-augmented LMs",
        "Factuality"
    ]
}