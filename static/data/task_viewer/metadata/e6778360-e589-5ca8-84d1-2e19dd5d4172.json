{
    "uuid": "e6778360-e589-5ca8-84d1-2e19dd5d4172",
    "title": "Aligning Language Models to Explicitly Handle Ambiguity",
    "conference_full": "The 2024 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2024,
    "volume": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{kim-etal-2024-aligning,\n    title = \"Aligning Language Models to Explicitly Handle Ambiguity\",\n    author = \"Kim, Hyuhng Joon  and\n      Kim, Youna  and\n      Park, Cheonbok  and\n      Kim, Junyeob  and\n      Park, Choonghyun  and\n      Yoo, Kang Min  and\n      Lee, Sang-goo  and\n      Kim, Taeuk\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.119\",\n    doi = \"10.18653/v1/2024.emnlp-main.119\",\n    pages = \"1989--2007\",\n    abstract = \"In interactions between users and language model agents, user utterances frequently exhibit ellipsis (omission of words or phrases) or imprecision (lack of exactness) to prioritize efficiency. This can lead to varying interpretations of the same input based on different assumptions or background knowledge. It is thus crucial for agents to adeptly handle the inherent ambiguity in queries to ensure reliability. However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may vary depending on the possessed knowledge. To address these issues, we propose Alignment with Perceived Ambiguity (APA), a novel pipeline that aligns LLMs to manage ambiguous queries by leveraging their own assessment of ambiguity (i.e., perceived ambiguity). Experimental results on question-answering datasets demonstrate that APA empowers LLMs to explicitly detect and manage ambiguous queries while retaining the ability to answer clear questions. Furthermore, our finding proves that APA excels beyond training with gold-standard labels, especially in out-of-distribution scenarios. The data and code are available at https://github.com/heyjoonkim/APA.\",\n}\n",
    "authors": [
        "Hyuhng Joon Kim",
        "Youna Kim",
        "Cheonbok Park",
        "Junyeob Kim",
        "Choonghyun Park",
        "Kang Min Yoo",
        "Sang-goo Lee",
        "Taeuk Kim"
    ],
    "pdf_url": "https://aclanthology.org/2024.emnlp-main.119.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2024/e6778360-e589-5ca8-84d1-2e19dd5d4172.pdf",
    "num_pages": 19,
    "abstract": "In interactions between users and language model agents, user utterances frequently exhibit ellipsis (omission of words or phrases) or imprecision (lack of exactness) to prioritize efficiency. This can lead to varying interpretations of the same input based on different assumptions or background knowledge. It is thus crucial for agents to adeptly handle the inherent ambiguity in queries to ensure reliability. However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may vary depending on the possessed knowledge. To address these issues, we propose Alignment with Perceived Ambiguity (APA), a novel pipeline that aligns LLMs to manage ambiguous queries by leveraging their own assessment of ambiguity (i.e., perceived ambiguity). Experimental results on question-answering datasets demonstrate that APA empowers LLMs to explicitly detect and manage ambiguous queries while retaining the ability to answer clear questions. Furthermore, our finding proves that APA excels beyond training with gold-standard labels, especially in out-of-distribution scenarios. The data and code are available at https://github.com/heyjoonkim/APA.",
    "tldr": "Proposes APA to improve LLMs' handling of ambiguous user queries.",
    "tags": [
        "language models",
        "ambiguity handling",
        "ellipsis",
        "imprecision",
        "alignment techniques"
    ]
}