{
    "uuid": "1bd3021a-e648-5ed5-a5a4-0c835dc0f3cd",
    "title": "Deep Support Vectors",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2024,
    "volume": "NeurIPS 2024 poster",
    "bibtex": "@inproceedings{\nlee2024deep,\ntitle={Deep Support Vectors},\nauthor={Junhoo Lee and Hyunho Lee and Kyomin Hwang and Nojun Kwak},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=5WoYFypPv0}\n}",
    "authors": [
        "Junhoo Lee",
        "Hyunho Lee",
        "Kyomin Hwang",
        "Nojun Kwak"
    ],
    "pdf_url": "https://openreview.net/pdf/c34cbd4c21b4871ff90d03acc5b73b7af13721a3.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2024/1bd3021a-e648-5ed5-a5a4-0c835dc0f3cd.pdf",
    "num_pages": 27,
    "abstract": "Deep learning has achieved tremendous success. However, unlike SVMs, which provide direct decision criteria and can be trained with a small dataset, it still has significant weaknesses due to its requirement for massive datasets during training and the black-box characteristics on decision criteria. This paper addresses these issues by identifying support vectors in deep learning models. To this end, we propose the DeepKKT condition, an adaptation of the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models, and confirm that generated Deep Support Vectors (DSVs) using this condition exhibit properties similar to traditional support vectors. This allows us to apply our method to few-shot dataset distillation problems and alleviate the black-box characteristics of deep learning models. Additionally, we demonstrate that the DeepKKT condition can transform conventional classification models into generative models with high fidelity, particularly as latent generation models using class labels as latent variables. We validate the effectiveness of DSVs using common datasets (ImageNet, CIFAR10 and CIFAR100) on the general architectures (ResNet and ConvNet), proving their practical applicability.",
    "tldr": "This paper finds support vector in deep learning model. These vectors has same characteristics to conventional SVM. It can be used in dataset distillation, global explanation. In its beyond, it can be used as latent generative model.",
    "tags": [
        "model inversion",
        "privacy attacks",
        "generative model",
        "dataset distillation",
        "support vector machines"
    ]
}