{
    "uuid": "c43d3a9e-fd1b-5e5c-8f4c-fd8c82218f78",
    "title": "Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2024,
    "volume": "NeurIPS 2024 poster",
    "bibtex": "@inproceedings{\nbui2024erasing,\ntitle={Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation},\nauthor={Anh Tuan Bui and Long Tung Vuong and Khanh Doan and Trung Le and Paul Montague and Tamas Abraham and Dinh Phung},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=GDz8rkfikp}\n}",
    "authors": [
        "Anh Tuan Bui",
        "Long Tung Vuong",
        "Khanh Doan",
        "Trung Le",
        "Paul Montague",
        "Tamas Abraham",
        "Dinh Phung"
    ],
    "pdf_url": "https://openreview.net/pdf/9cd92e3aafbec2538fcfd9312326ad11d1101960.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2024/c43d3a9e-fd1b-5e5c-8f4c-fd8c82218f78.pdf",
    "num_pages": 35,
    "abstract": "Diffusion models excel at generating visually striking content from text but can inadvertently produce undesirable or harmful content when trained on unfiltered internet data. A practical solution is to selectively removing target concepts from the model, but this may impact the remaining concepts. Prior approaches have tried to balance this by introducing a loss term to preserve neutral content or a regularization term to minimize changes in the model parameters, yet resolving this trade-off remains challenging. In this work, we propose to identify and preserving concepts most affected by parameter changes, termed as *adversarial concepts*. This approach ensures stable erasure with minimal impact on the other concepts. We demonstrate the effectiveness of our method using the Stable Diffusion model, showing that it outperforms state-of-the-art erasure methods in eliminating unwanted content while maintaining the integrity of other unrelated elements. Our code is available at \\url{https://github.com/tuananhbui89/Erasing-Adversarial-Preservation}.",
    "tldr": "Proposes a method to erase harmful concepts in diffusion models with minimal impact.",
    "tags": [
        "Diffusion models",
        "Erasing Concepts; Trustworthy GenAI"
    ]
}