{
    "uuid": "c5c49d69-0cf3-58f9-8a74-17f9d5b17ffe",
    "title": "Back to School: Translation Using Grammar Books",
    "conference_full": "The 2024 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2024,
    "volume": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{hus-anastasopoulos-2024-back,\n    title = \"Back to School: Translation Using Grammar Books\",\n    author = \"Hus, Jonathan  and\n      Anastasopoulos, Antonios\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1127\",\n    doi = \"10.18653/v1/2024.emnlp-main.1127\",\n    pages = \"20207--20219\",\n    abstract = \"Machine translation systems for high resource languages perform exceptionally well and produce high quality translations. Unfortunately, the vast majority of languages are not considered high resource and lack the quantity of parallel sentences needed to train such systems. These under-represented languages are not without resources, however, and bilingual dictionaries and grammar books are available as linguistic reference material. With current large language models (LLMs) supporting near book-length contexts, we can begin to use the available material to ensure advancements are shared among all of the world{'}s languages. In this paper, we demonstrate incorporating grammar books in the prompt of GPT-4 to improve machine translation and evaluate the performance on 16 topologically diverse low-resource languages, using a combination of reference material to show that the machine translation performance of LLMs can be improved using this method.\",\n}\n",
    "authors": [
        "Jonathan Hus",
        "Antonios Anastasopoulos"
    ],
    "pdf_url": "https://aclanthology.org/2024.emnlp-main.1127.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2024/c5c49d69-0cf3-58f9-8a74-17f9d5b17ffe.pdf",
    "num_pages": 13,
    "abstract": "Machine translation systems for high resource languages perform exceptionally well and produce high quality translations. Unfortunately, the vast majority of languages are not considered high resource and lack the quantity of parallel sentences needed to train such systems. These under-represented languages are not without resources, however, and bilingual dictionaries and grammar books are available as linguistic reference material. With current large language models (LLMs) supporting near book-length contexts, we can begin to use the available material to ensure advancements are shared among all of the worldâ€™s languages. In this paper, we demonstrate incorporating grammar books in the prompt of GPT-4 to improve machine translation and evaluate the performance on 16 topologically diverse low-resource languages, using a combination of reference material to show that the machine translation performance of LLMs can be improved using this method.",
    "tldr": "Incorporating grammar books enhances machine translation for low-resource languages.",
    "tags": [
        "machine translation",
        "low-resource languages",
        "grammar books",
        "bilingual dictionaries",
        "large language models"
    ]
}