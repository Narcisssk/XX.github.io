{
    "uuid": "0c64c0b5-4466-51d6-9e84-59fa73d8a450",
    "title": "Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations",
    "conference_full": "The 2023 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2023,
    "volume": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{huang-etal-2023-bridging,\n    title = \"Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations\",\n    author = \"Huang, James Y.  and\n      Yao, Wenlin  and\n      Song, Kaiqiang  and\n      Zhang, Hongming  and\n      Chen, Muhao  and\n      Yu, Dong\",\n    editor = \"Bouamor, Houda  and\n      Pino, Juan  and\n      Bali, Kalika\",\n    booktitle = \"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2023\",\n    address = \"Singapore\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.emnlp-main.900\",\n    doi = \"10.18653/v1/2023.emnlp-main.900\",\n    pages = \"14584--14595\",\n    abstract = \"Traditional sentence embedding models encode sentences into vector representations to capture useful properties such as the semantic similarity between sentences. However, in addition to similarity, sentence semantics can also be interpreted via compositional operations such as sentence fusion or difference. It is unclear whether the compositional semantics of sentences can be directly reflected as compositional operations in the embedding space. To more effectively bridge the continuous embedding and discrete text spaces, we explore the plausibility of incorporating various compositional properties into the sentence embedding space that allows us to interpret embedding transformations as compositional sentence operations. We propose InterSent, an end-to-end framework for learning interpretable sentence embeddings that supports compositional sentence operations in the embedding space. Our method optimizes operator networks and a bottleneck encoder-decoder model to produce meaningful and interpretable sentence embeddings. Experimental results demonstrate that our method significantly improves the interpretability of sentence embeddings on four textual generation tasks over existing approaches while maintaining strong performance on traditional semantic similarity tasks.\",\n}\n",
    "authors": [
        "James Y. Huang",
        "Wenlin Yao",
        "Kaiqiang Song",
        "Hongming Zhang",
        "Muhao Chen",
        "Dong Yu"
    ],
    "pdf_url": "https://aclanthology.org/2023.emnlp-main.900.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2023/0c64c0b5-4466-51d6-9e84-59fa73d8a450.pdf",
    "num_pages": 12,
    "abstract": "Traditional sentence embedding models encode sentences into vector representations to capture useful properties such as the semantic similarity between sentences. However, in addition to similarity, sentence semantics can also be interpreted via compositional operations such as sentence fusion or difference. It is unclear whether the compositional semantics of sentences can be directly reflected as compositional operations in the embedding space. To more effectively bridge the continuous embedding and discrete text spaces, we explore the plausibility of incorporating various compositional properties into the sentence embedding space that allows us to interpret embedding transformations as compositional sentence operations. We propose InterSent, an end-to-end framework for learning interpretable sentence embeddings that supports compositional sentence operations in the embedding space. Our method optimizes operator networks and a bottleneck encoder-decoder model to produce meaningful and interpretable sentence embeddings. Experimental results demonstrate that our method significantly improves the interpretability of sentence embeddings on four textual generation tasks over existing approaches while maintaining strong performance on traditional semantic similarity tasks.",
    "tldr": "InterSent enhances sentence embeddings with interpretable compositional operations.",
    "tags": [
        "sentence embeddings",
        "compositional semantics",
        "interpretability",
        "embedding space",
        "operator networks"
    ]
}