{
    "uuid": "be89f00a-d771-5b5e-9b99-ba0becab9275",
    "title": "MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction",
    "conference_full": "The 2023 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: EMNLP 2023",
    "bibtex": "@inproceedings{ye-etal-2023-mixedit,\n    title = \"{M}ix{E}dit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction\",\n    author = \"Ye, Jingheng  and\n      Li, Yinghui  and\n      Li, Yangning  and\n      Zheng, Hai-Tao\",\n    editor = \"Bouamor, Houda  and\n      Pino, Juan  and\n      Bali, Kalika\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2023\",\n    month = dec,\n    year = \"2023\",\n    address = \"Singapore\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-emnlp.681\",\n    doi = \"10.18653/v1/2023.findings-emnlp.681\",\n    pages = \"10161--10175\",\n    abstract = \"Data Augmentation through generating pseudo data has been proven effective in mitigating the challenge of data scarcity in the field of Grammatical Error Correction (GEC). Various augmentation strategies have been widely explored, most of which are motivated by two heuristics, i.e., increasing the distribution similarity and diversity of pseudo data. However, the underlying mechanism responsible for the effectiveness of these strategies remains poorly understood. In this paper, we aim to clarify how data augmentation improves GEC models. To this end, we introduce two interpretable and computationally efficient measures: Affinity and Diversity. Our findings indicate that an excellent GEC data augmentation strategy characterized by high Affinity and appropriate Diversity can better improve the performance of GEC models. Based on this observation, we propose MixEdit, a data augmentation approach that strategically and dynamically augments realistic data, without requiring extra monolingual corpora. To verify the correctness of our findings and the effectiveness of the proposed MixEdit, we conduct experiments on mainstream English and Chinese GEC datasets. The results show that MixEdit substantially improves GEC models and is complementary to traditional data augmentation methods. All the source codes of MixEdit are released at https://github.com/THUKElab/MixEdit.\",\n}\n",
    "authors": [
        "Jingheng Ye",
        "Yinghui Li",
        "Yangning Li",
        "Hai-Tao Zheng"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-emnlp.681.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2023/be89f00a-d771-5b5e-9b99-ba0becab9275.pdf",
    "num_pages": 15,
    "abstract": "Data Augmentation through generating pseudo data has been proven effective in mitigating the challenge of data scarcity in the field of Grammatical Error Correction (GEC). Various augmentation strategies have been widely explored, most of which are motivated by two heuristics, i.e., increasing the distribution similarity and diversity of pseudo data. However, the underlying mechanism responsible for the effectiveness of these strategies remains poorly understood. In this paper, we aim to clarify how data augmentation improves GEC models. To this end, we introduce two interpretable and computationally efficient measures: Affinity and Diversity. Our findings indicate that an excellent GEC data augmentation strategy characterized by high Affinity and appropriate Diversity can better improve the performance of GEC models. Based on this observation, we propose MixEdit, a data augmentation approach that strategically and dynamically augments realistic data, without requiring extra monolingual corpora. To verify the correctness of our findings and the effectiveness of the proposed MixEdit, we conduct experiments on mainstream English and Chinese GEC datasets. The results show that MixEdit substantially improves GEC models and is complementary to traditional data augmentation methods. All the source codes of MixEdit are released at https://github.com/THUKElab/MixEdit.",
    "tldr": "MixEdit enhances grammatical error correction via strategic data augmentation methods.",
    "tags": [
        "Data Augmentation",
        "Grammatical Error Correction",
        "MixEdit",
        "Pseudo Data",
        "Model Performance"
    ]
}