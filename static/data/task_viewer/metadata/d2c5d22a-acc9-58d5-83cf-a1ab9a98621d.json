{
    "uuid": "d2c5d22a-acc9-58d5-83cf-a1ab9a98621d",
    "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2024,
    "volume": "NeurIPS 2024 Track Datasets and Benchmarks Poster",
    "bibtex": "@inproceedings{\nxie2024osworld,\ntitle={{OSW}orld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},\nauthor={Tianbao Xie and Danyang Zhang and Jixuan Chen and Xiaochuan Li and Siheng Zhao and Ruisheng Cao and Toh Jing Hua and Zhoujun Cheng and Dongchan Shin and Fangyu Lei and Yitao Liu and Yiheng Xu and Shuyan Zhou and Silvio Savarese and Caiming Xiong and Victor Zhong and Tao Yu},\nbooktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2024},\nurl={https://openreview.net/forum?id=tN61DTr4Ed}\n}",
    "authors": [
        "Tianbao Xie",
        "Danyang Zhang",
        "Jixuan Chen",
        "Xiaochuan Li",
        "Siheng Zhao",
        "Ruisheng Cao",
        "Toh Jing Hua",
        "Zhoujun Cheng",
        "Dongchan Shin",
        "Fangyu Lei",
        "Yitao Liu",
        "Yiheng Xu",
        "Shuyan Zhou",
        "Silvio Savarese",
        "Caiming Xiong",
        "Victor Zhong",
        "Tao Yu"
    ],
    "pdf_url": "https://openreview.net/pdf/ccc94fc4e3f12dd23e556b91244c7a2b22ebd1bb.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2024/d2c5d22a-acc9-58d5-83cf-a1ab9a98621d.pdf",
    "num_pages": 55,
    "abstract": "Autonomous agents that accomplish complex computer tasks with minimal human interventions have the potential to transform human-computer interaction, significantly enhancing accessibility and productivity. However, existing benchmarks either lack an interactive environment or are limited to environments specific to certain applications or domains, failing to reflect the diverse and complex nature of real-world computer use, thereby limiting the scope of tasks and agent scalability. To address this issue, we introduce OSWorld, the first-of-its-kind scalable, real computer environment for multimodal agents, supporting task setup, execution-based evaluation, and interactive learning across various operating systems such as Ubuntu, Windows, and macOS. OSWorld can serve as a unified, integrated computer environment for assessing open-ended computer tasks that involve arbitrary applications. Building upon OSWorld, we create a benchmark of 369 computer tasks involving real web and desktop apps in open domains, OS file I/O, and workflows spanning multiple applications. Each task example is derived from real-world computer use cases and includes a detailed initial state setup configuration and a custom execution-based evaluation script for reliable, reproducible evaluation. Extensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld reveals significant deficiencies in their ability to serve as computer assistants. While humans can accomplish over 72.36% of the tasks, the best model achieves only 12.24% success, primarily struggling with GUI grounding and operational knowledge. Comprehensive analysis using OSWorld provides valuable insights for developing multimodal generalist agents that were not possible with previous benchmarks. Our code, environment, baseline models, and data are publicly available at [this https URL](https://os-world.github.io/).",
    "tldr": "OSWorld is a scalable real computer environment for evaluating multimodal agents on 369 real-world tasks, highlighting major performance gaps in current models.",
    "tags": [
        "Benchmark; Multimodal Agents; Real Computer Environment"
    ]
}