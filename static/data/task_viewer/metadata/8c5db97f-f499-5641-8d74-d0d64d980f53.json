{
    "uuid": "8c5db97f-f499-5641-8d74-d0d64d980f53",
    "title": "Generative Adversarial Training with Perturbed Token Detection for Model Robustness",
    "conference_full": "The 2023 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2023,
    "volume": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{zhao-mao-2023-generative,\n    title = \"Generative Adversarial Training with Perturbed Token Detection for Model Robustness\",\n    author = \"Zhao, Jiahao  and\n      Mao, Wenji\",\n    editor = \"Bouamor, Houda  and\n      Pino, Juan  and\n      Bali, Kalika\",\n    booktitle = \"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2023\",\n    address = \"Singapore\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.emnlp-main.804\",\n    doi = \"10.18653/v1/2023.emnlp-main.804\",\n    pages = \"13012--13025\",\n    abstract = \"Adversarial training is the dominant strategy towards model robustness. Current adversarial training methods typically apply perturbations to embedding representations, whereas actual text-based attacks introduce perturbations as discrete tokens. Thus there exists a gap between the continuous embedding representations and discrete text tokens that hampers the effectiveness of adversarial training. Moreover, the continuous representations of perturbations cannot be further utilized, resulting in the suboptimal performance. To bridge this gap for adversarial robustness, in this paper, we devise a novel generative adversarial training framework that integrates gradient-based learning, adversarial example generation and perturbed token detection. Our proposed framework consists of generative adversarial attack and adversarial training process. Specifically, in generative adversarial attack, the embeddings are shared between the classifier and the generative model, which enables the generative model to leverage the gradients from the classifier for generating perturbed tokens. Then, adversarial training process combines adversarial regularization with perturbed token detection to provide token-level supervision and improve the efficiency of sample utilization. Extensive experiments on five datasets from the AdvGLUE benchmark demonstrate that our framework significantly enhances the model robustness, surpassing the state-of-the-art results of ChatGPT by 10{\\%} in average accuracy.\",\n}\n",
    "authors": [
        "Jiahao Zhao",
        "Wenji Mao"
    ],
    "pdf_url": "https://aclanthology.org/2023.emnlp-main.804.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2023/8c5db97f-f499-5641-8d74-d0d64d980f53.pdf",
    "num_pages": 14,
    "abstract": "Adversarial training is the dominant strategy towards model robustness. Current adversarial training methods typically apply perturbations to embedding representations, whereas actual text-based attacks introduce perturbations as discrete tokens. Thus there exists a gap between the continuous embedding representations and discrete text tokens that hampers the effectiveness of adversarial training. Moreover, the continuous representations of perturbations cannot be further utilized, resulting in the suboptimal performance. To bridge this gap for adversarial robustness, in this paper, we devise a novel generative adversarial training framework that integrates gradient-based learning, adversarial example generation and perturbed token detection. Our proposed framework consists of generative adversarial attack and adversarial training process. Specifically, in generative adversarial attack, the embeddings are shared between the classifier and the generative model, which enables the generative model to leverage the gradients from the classifier for generating perturbed tokens. Then, adversarial training process combines adversarial regularization with perturbed token detection to provide token-level supervision and improve the efficiency of sample utilization. Extensive experiments on five datasets from the AdvGLUE benchmark demonstrate that our framework significantly enhances the model robustness, surpassing the state-of-the-art results of ChatGPT by 10% in average accuracy.",
    "tldr": "Novel adversarial training framework improves model robustness with token detection.",
    "tags": [
        "Generative Adversarial Training",
        "Adversarial Robustness",
        "Perturbed Token Detection",
        "Embedding Representations",
        "Text-Based Attacks"
    ]
}