{
    "uuid": "2b518d78-7e56-5928-85cb-ff7ccfd63307",
    "title": "EgoDistill: Egocentric Head Motion Distillation for Efficient Video Understanding",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2023,
    "volume": "NeurIPS 2023 poster",
    "bibtex": "@inproceedings{\ntan2023egodistill,\ntitle={EgoDistill: Egocentric Head Motion Distillation for Efficient Video Understanding},\nauthor={Shuhan Tan and Tushar Nagarajan and Kristen Grauman},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=OfjVAKx44G}\n}",
    "authors": [
        "Shuhan Tan",
        "Tushar Nagarajan",
        "Kristen Grauman"
    ],
    "pdf_url": "https://openreview.net/pdf/a871f625fa82041a24737a159cfd97f2bab50466.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2023/2b518d78-7e56-5928-85cb-ff7ccfd63307.pdf",
    "num_pages": 14,
    "abstract": "Recent advances in egocentric video understanding models are promising, but their heavy computational expense is a barrier for many real-world applications. To address this challenge, we propose EgoDistill, a distillation-based approach that learns to reconstruct heavy ego-centric video clip features by combining the semantics from a sparse set of video frames with head motion from lightweight IMU readings. We further devise a novel IMU-based self-supervised pretraining strategy. Our method leads to significant improvements in efficiency, requiring 200Ã— fewer GFLOPs than equivalent video models. We demonstrate its effectiveness on the Ego4D and EPIC- Kitchens datasets, where our method outperforms state-of-the-art efficient video understanding methods.",
    "tldr": "EgoDistill reduces computation in egocentric video understanding using head motion data.",
    "tags": [
        "Egocentric Video; IMU; Efficient Video Understanding"
    ]
}