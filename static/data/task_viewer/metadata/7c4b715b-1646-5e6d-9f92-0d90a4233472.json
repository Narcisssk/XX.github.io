{
    "uuid": "7c4b715b-1646-5e6d-9f92-0d90a4233472",
    "title": "Improving Multi-Speaker ASR With Overlap-Aware Encoding And Monotonic Attention",
    "conference_full": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "conference": "icassp",
    "year": 2024,
    "volume": "ICASSP session SLP: Speech & Language Processing",
    "bibtex": "@inproceedings{DBLP:conf/icassp/LiWGHHL24,\n  author       = {Tao Li and\n                  Feng Wang and\n                  Wenhao Guan and\n                  Lingyan Huang and\n                  Qingyang Hong and\n                  Lin Li},\n  title        = {Improving Multi-Speaker {ASR} With Overlap-Aware Encoding And Monotonic\n                  Attention},\n  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,\n                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},\n  pages        = {12416--12420},\n  publisher    = {{IEEE}},\n  year         = {2024},\n  url          = {https://doi.org/10.1109/ICASSP48485.2024.10445900},\n  doi          = {10.1109/ICASSP48485.2024.10445900},\n  timestamp    = {Wed, 07 Aug 2024 12:26:13 +0200},\n  biburl       = {https://dblp.org/rec/conf/icassp/LiWGHHL24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}",
    "authors": [
        "Tao Li",
        "Feng Wang",
        "Wenhao Guan",
        "Lingyan Huang",
        "Qingyang Hong",
        "Lin Li"
    ],
    "pdf_url": "https://doi.org/10.1109/ICASSP48485.2024.10445900",
    "pdf_path": "data/dataset/airqa/papers/icassp2024/7c4b715b-1646-5e6d-9f92-0d90a4233472.pdf",
    "num_pages": 5,
    "abstract": "End-to-end (E2E) multi-speaker speech recognition with the serialized output training (SOT) strategy demonstrates good performance in modeling diverse speaker scenarios. However, the E2E architecture doesn’t explicitly address the modeling of overlapping speech areas, potentially limiting the model’s ability to generalize. To tackle this issue, we introduce two approaches: overlap-aware encoding method and monotonic attention loss. The former enables the model to acquire knowledge about overlapping speech through multi-task learning, while the latter encourages the model to learn specific attention patterns associated with overlap by constraining the attention of adjacent text time steps. Our experimental results on the AliMeeting dataset show that the combination of these two methods effectively enhances the model’s performance.",
    "tldr": "Enhancing multi-speaker ASR with overlap-aware encoding and monotonic attention.",
    "tags": [
        "multi-speaker ASR",
        "overlap-aware encoding",
        "monotonic attention",
        "speech recognition",
        "multi-task learning"
    ]
}