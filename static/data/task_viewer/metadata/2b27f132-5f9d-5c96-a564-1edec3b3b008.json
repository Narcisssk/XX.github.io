{
    "uuid": "2b27f132-5f9d-5c96-a564-1edec3b3b008",
    "title": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2024,
    "volume": "NeurIPS 2024 Track Datasets and Benchmarks Poster",
    "bibtex": "@inproceedings{\nxia2024cares,\ntitle={{CARES}: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models},\nauthor={Peng Xia and Ze Chen and Juanxi Tian and Gong Yangrui and Ruibo Hou and Yue Xu and Zhenbang Wu and Zhiyuan Fan and Yiyang Zhou and Kangyu Zhu and Wenhao Zheng and Zhaoyang Wang and Xiao Wang and Xuchao Zhang and Chetan Bansal and Marc Niethammer and Junzhou Huang and Hongtu Zhu and Yun Li and Jimeng Sun and Zongyuan Ge and Gang Li and James Zou and Huaxiu Yao},\nbooktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2024},\nurl={https://openreview.net/forum?id=b6IBmU1uzw}\n}",
    "authors": [
        "Peng Xia",
        "Ze Chen",
        "Juanxi Tian",
        "Gong Yangrui",
        "Ruibo Hou",
        "Yue Xu",
        "Zhenbang Wu",
        "Zhiyuan Fan",
        "Yiyang Zhou",
        "Kangyu Zhu",
        "Wenhao Zheng",
        "Zhaoyang Wang",
        "Xiao Wang",
        "Xuchao Zhang",
        "Chetan Bansal",
        "Marc Niethammer",
        "Junzhou Huang",
        "Hongtu Zhu",
        "Yun Li",
        "Jimeng Sun",
        "Zongyuan Ge",
        "Gang Li",
        "James Zou",
        "Huaxiu Yao"
    ],
    "pdf_url": "https://openreview.net/pdf/cf74809bc5b0004b99c2858cb6366e2846e73749.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2024/2b27f132-5f9d-5c96-a564-1edec3b3b008.pdf",
    "num_pages": 32,
    "abstract": "Artificial intelligence has significantly impacted medical applications, particularly with the advent of Medical Large Vision Language Models (Med-LVLMs), sparking optimism for the future of automated and personalized healthcare. However, the trustworthiness of Med-LVLMs remains unverified, posing significant risks for future model deployment. In this paper, we introduce CARES and aim to comprehensively evaluate the Trustworthiness of Med-LVLMs across the medical domain. We assess the trustworthiness of Med-LVLMs across five dimensions, including trustfulness, fairness, safety, privacy, and robustness. CARES comprises about 41K question-answer pairs in both closed and open-ended formats, covering 16 medical image modalities and 27 anatomical regions. Our analysis reveals that the models consistently exhibit concerns regarding trustworthiness, often displaying factual inaccuracies and failing to maintain fairness across different demographic groups. Furthermore, they are vulnerable to attacks and demonstrate a lack of privacy awareness. We publicly release our benchmark and code in https://github.com/richard-peng-xia/CARES.",
    "tldr": "A comprehensive evaluation of trustworthiness in medical large vision language models",
    "tags": [
        "medical large vision language models",
        "medical imaging",
        "trustworthiness"
    ]
}