{
    "uuid": "22086214-ba3b-50f5-9a22-a247a50375fe",
    "title": "Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2023,
    "volume": "NeurIPS 2023 Datasets and Benchmarks Spotlight",
    "bibtex": "@inproceedings{\nli2023can,\ntitle={Can {LLM} Already Serve as A Database Interface? A {BI}g Bench for Large-Scale Database Grounded Text-to-{SQL}s},\nauthor={Jinyang Li and Binyuan Hui and GE QU and Jiaxi Yang and Binhua Li and Bowen Li and Bailin Wang and Bowen Qin and Ruiying Geng and Nan Huo and Xuanhe Zhou and Chenhao Ma and Guoliang Li and Kevin Chang and Fei Huang and Reynold Cheng and Yongbin Li},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2023},\nurl={https://openreview.net/forum?id=dI4wzAE6uV}\n}",
    "authors": [
        "Jinyang Li",
        "Binyuan Hui",
        "GE QU",
        "Jiaxi Yang",
        "Binhua Li",
        "Bowen Li",
        "Bailin Wang",
        "Bowen Qin",
        "Ruiying Geng",
        "Nan Huo",
        "Xuanhe Zhou",
        "Chenhao Ma",
        "Guoliang Li",
        "Kevin Chang",
        "Fei Huang",
        "Reynold Cheng",
        "Yongbin Li"
    ],
    "pdf_url": "https://openreview.net/pdf/14830972ccbc1319be12d4a5763f76f6c9a7dcc8.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2023/22086214-ba3b-50f5-9a22-a247a50375fe.pdf",
    "num_pages": 28,
    "abstract": "Text-to-SQL parsing, which aims at converting natural language instructions into executable SQLs, has gained increasing attention in recent years.  In particular, GPT-4 and Claude-2 have shown impressive results in this task. However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on database schema with few rows of database contents leaving the gap between academic study and real-world applications. To mitigate this gap, we present BIRD, a BIg benchmark for laRge-scale Database grounded in text-to-SQL tasks, containing 12,751 pairs of text-to-SQL data and 95 databases with a total size of 33.4 GB, spanning 37 professional domains. Our emphasis on database values highlights the new challenges of dirty database contents, external knowledge between NL questions and database contents,  and SQL efficiency, particularly in the context of massive databases. To solve these problems, text-to-SQL models must feature database value comprehension in addition to semantic parsing. The experimental results demonstrate the significance of database values in generating accurate text-to-SQLs for big databases. Furthermore, even the most popular and effective text-to-SQL models, i.e. GPT-4, only achieve 54.89% in execution accuracy, which is still far from the human result of 92.96%, proving that challenges still stand. We also provide an efficiency analysis to offer insights into generating text-to-efficient-SQLs that are beneficial to industries. \nWe believe that BIRD will contribute to advancing real-world applications of text-to-SQL research.\nThe leaderboard and source code are available: https://bird-bench.github.io/.",
    "tldr": "BIRD benchmark addresses challenges in text-to-SQL for large databases.",
    "tags": [
        "Text-to-SQL Parsing",
        "Large Language Models",
        "Database Grounding",
        "SQL Efficiency"
    ]
}