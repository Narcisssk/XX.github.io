{
    "uuid": "911d4572-a45c-5bb8-8662-2e2455909cd2",
    "title": "Freevc: Towards High-Quality Text-Free One-Shot Voice Conversion",
    "conference_full": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "conference": "icassp",
    "year": 2023,
    "volume": "ICASSP session SLT: Spoken Language Technology",
    "bibtex": "@inproceedings{DBLP:conf/icassp/LiTX23a,\n  author       = {Jingyi Li and\n                  Weiping Tu and\n                  Li Xiao},\n  title        = {Freevc: Towards High-Quality Text-Free One-Shot Voice Conversion},\n  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing\n                  {ICASSP} 2023, Rhodes Island, Greece, June 4-10, 2023},\n  pages        = {1--5},\n  publisher    = {{IEEE}},\n  year         = {2023},\n  url          = {https://doi.org/10.1109/ICASSP49357.2023.10095191},\n  doi          = {10.1109/ICASSP49357.2023.10095191},\n  timestamp    = {Fri, 06 Sep 2024 20:43:04 +0200},\n  biburl       = {https://dblp.org/rec/conf/icassp/LiTX23a.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}",
    "authors": [
        "Jingyi Li",
        "Weiping Tu",
        "Li Xiao"
    ],
    "pdf_url": "https://doi.org/10.1109/ICASSP49357.2023.10095191",
    "pdf_path": "data/dataset/airqa/papers/icassp2023/911d4572-a45c-5bb8-8662-2e2455909cd2.pdf",
    "num_pages": 5,
    "abstract": "Voice conversion (VC) can be achieved by first extracting source content information and target speaker information, and then reconstructing waveform with these information. However, current approaches normally either extract dirty content information with speaker information leaked in, or demand a large amount of annotated data for training. Besides, the quality of reconstructed waveform can be degraded by the mismatch between conversion model and vocoder. In this paper, we adopt the end-to-end framework of VITS for high-quality waveform reconstruction, and propose strategies for clean content information extraction without text annotation. We disentangle content information by imposing an information bottleneck to WavLM features, and propose the spectrogram-resize based data augmentation to improve the purity of extracted content information. Experimental results show that the proposed method outperforms the latest VC models trained with annotated data and has greater robustness.",
    "tldr": "Freevc enables high-quality, text-free voice conversion with improved content extraction.",
    "tags": [
        "Voice Conversion",
        "One-Shot Learning",
        "Waveform Reconstruction",
        "Data Augmentation",
        "Information Bottleneck"
    ]
}