{
    "uuid": "1d0c97b9-f24f-5651-83f1-5d6f37d431f0",
    "title": "Octopus: A Multi-modal LLM with Parallel Recognition and Sequential Understanding",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2024,
    "volume": "NeurIPS 2024 poster",
    "bibtex": "@inproceedings{\nzhao2024octopus,\ntitle={Octopus: A Multi-modal {LLM} with Parallel Recognition and Sequential Understanding},\nauthor={Chuyang Zhao and YuXin Song and Junru Chen and KANG RONG and Haocheng Feng and Gang Zhang and Shufan Ji and Jingdong Wang and Errui Ding and Yifan Sun},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=ujE83r50tR}\n}",
    "authors": [
        "Chuyang Zhao",
        "YuXin Song",
        "Junru Chen",
        "KANG RONG",
        "Haocheng Feng",
        "Gang Zhang",
        "Shufan Ji",
        "Jingdong Wang",
        "Errui Ding",
        "Yifan Sun"
    ],
    "pdf_url": "https://openreview.net/pdf/2555221db7dc3b492d4ad067e94664955534d668.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2024/1d0c97b9-f24f-5651-83f1-5d6f37d431f0.pdf",
    "num_pages": 21,
    "abstract": "A mainstream of Multi-modal Large Language Models (MLLMs) have two essential functions, i.e., visual recognition (e.g., grounding) and understanding (e.g., visual question answering). Presently, all these MLLMs integrate visual recognition and understanding in a same sequential manner in the LLM head, i.e., generating the response token-by-token for both recognition and understanding. We think unifying them in the same sequential manner is not optimal for two reasons: 1) parallel recognition is more efficient than sequential recognition and is actually prevailing in deep visual recognition, and 2) the recognition results can be integrated to help high-level cognition (while the current manner does not). Such motivated, this paper proposes a novel “parallel recognition → sequential understanding” framework for MLLMs. The bottom LLM layers are utilized for parallel recognition and the recognition results are relayed into the top LLM layers for sequential understanding. Specifically, parallel recognition in the bottom LLM layers is implemented via object queries, a popular mechanism in DEtection TRansformer, which we find to harmonize well with the LLM layers. Empirical studies show our MLLM named Octopus improves accuracy on popular MLLM tasks and is up to 5× faster on visual grounding tasks.",
    "tldr": "Octopus enhances MLLMs with efficient parallel recognition and sequential understanding.",
    "tags": [
        "multimodal large language model",
        "large language model",
        "object detection"
    ]
}