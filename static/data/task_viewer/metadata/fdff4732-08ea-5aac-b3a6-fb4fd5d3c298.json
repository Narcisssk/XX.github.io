{
    "uuid": "fdff4732-08ea-5aac-b3a6-fb4fd5d3c298",
    "title": "R-divergence for Estimating Model-oriented Distribution Discrepancy",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2023,
    "volume": "NeurIPS 2023 poster",
    "bibtex": "@inproceedings{\nzhao2023rdivergence,\ntitle={R-divergence for Estimating Model-oriented Distribution Discrepancy},\nauthor={Zhilin Zhao and Longbing Cao},\nbooktitle={Thirty-seventh Conference on Neural Information Processing Systems},\nyear={2023},\nurl={https://openreview.net/forum?id=DVWIA9v9Jm}\n}",
    "authors": [
        "Zhilin Zhao",
        "Longbing Cao"
    ],
    "pdf_url": "https://openreview.net/pdf/64bf9e19a84518e00b503b5afb42bd12e605087d.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2023/fdff4732-08ea-5aac-b3a6-fb4fd5d3c298.pdf",
    "num_pages": 19,
    "abstract": "Real-life data are often non-IID due to complex distributions and interactions, and the sensitivity to the distribution of samples can differ among learning models. Accordingly, a key question for any supervised or unsupervised model is whether the probability distributions of two given datasets can be considered identical. To address this question, we introduce R-divergence, designed to assess model-oriented distribution discrepancies. The core insight is that two distributions are likely identical if their optimal hypothesis yields the same expected risk for each distribution. To estimate the distribution discrepancy between two datasets, R-divergence learns a minimum hypothesis on the mixed data and then gauges the empirical risk difference between them. We evaluate the test power across various unsupervised and supervised tasks and find that R-divergence achieves state-of-the-art performance. To demonstrate the practicality of R-divergence, we employ R-divergence to train robust neural networks on samples with noisy labels.",
    "tldr": "R-divergence is proposed to estimate the discrepancy between two probability distributions for specific supervised or unsupervised machine learning models.",
    "tags": [
        "non-IID",
        "Distribution Discrepancy",
        "Data Divergence",
        "Two-sample Test"
    ]
}