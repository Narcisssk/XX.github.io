{
    "uuid": "d47ee42f-200a-5a19-8004-ea8a34c37bd8",
    "title": "PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-To-Speech Using Natural Language Descriptions",
    "conference_full": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "conference": "icassp",
    "year": 2024,
    "volume": "ICASSP session SLP: Speech & Language Processing",
    "bibtex": "@inproceedings{DBLP:conf/icassp/ShimizuYKSDKT24,\n  author       = {Reo Shimizu and\n                  Ryuichi Yamamoto and\n                  Masaya Kawamura and\n                  Yuma Shirahata and\n                  Hironori Doi and\n                  Tatsuya Komatsu and\n                  Kentaro Tachibana},\n  title        = {PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-To-Speech\n                  Using Natural Language Descriptions},\n  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,\n                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},\n  pages        = {12672--12676},\n  publisher    = {{IEEE}},\n  year         = {2024},\n  url          = {https://doi.org/10.1109/ICASSP48485.2024.10448173},\n  doi          = {10.1109/ICASSP48485.2024.10448173},\n  timestamp    = {Wed, 07 Aug 2024 12:26:13 +0200},\n  biburl       = {https://dblp.org/rec/conf/icassp/ShimizuYKSDKT24.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}",
    "authors": [
        "Reo Shimizu",
        "Ryuichi Yamamoto",
        "Masaya Kawamura",
        "Yuma Shirahata",
        "Hironori Doi",
        "Tatsuya Komatsu",
        "Kentaro Tachibana"
    ],
    "pdf_url": "https://doi.org/10.1109/ICASSP48485.2024.10448173",
    "pdf_path": "data/dataset/airqa/papers/icassp2024/d47ee42f-200a-5a19-8004-ea8a34c37bd8.pdf",
    "num_pages": 5,
    "abstract": "We propose PromptTTS++, a prompt-based text-to-speech (TTS) synthesis system that allows control over speaker identity using natural language descriptions. To control speaker identity within the prompt-based TTS framework, we introduce the concept of speaker prompt, which describes voice characteristics (e.g., gender-neutral, young, old, and muffled) designed to be approximately independent of speaking style. Since there is no large-scale dataset containing speaker prompts, we first construct a dataset based on the LibriTTS-R corpus with manually annotated speaker prompts. We then employ a diffusion-based acoustic model with mixture density networks to model diverse speaker factors in the training data. Unlike previous studies that rely on style prompts describing only a limited aspect of speaker individuality, such as pitch, speaking speed, and energy, our method utilizes an additional speaker prompt to effectively learn the mapping from natural language descriptions to the acoustic features of diverse speakers. Our subjective evaluation results show that the proposed method can better control speaker characteristics than the methods without the speaker prompt. Audio samples are available at https://reppy4620.github.io/demo.promptttspp/.",
    "tldr": "PromptTTS++ enables speaker identity control in TTS using natural language descriptions.",
    "tags": [
        "Text-to-Speech",
        "Speaker Identity",
        "Natural Language Processing",
        "Acoustic Modeling",
        "Prompt-Based Synthesis"
    ]
}