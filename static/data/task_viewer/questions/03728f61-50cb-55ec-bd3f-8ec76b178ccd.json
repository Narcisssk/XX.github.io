{
    "uuid": "03728f61-50cb-55ec-bd3f-8ec76b178ccd",
    "question": "What's the base pre-trained model used in this paper? For this pre-trained model, what's the pre-train dataset?",
    "answer_format": "Your answer should be a single python list like this: [\"model_name\", [\"dataset_name1\",\"dataset_name2\"]]. Note that for theses names, the abbreviation is required.",
    "tags": [
        "multiple",
        "table",
        "objective"
    ],
    "anchor_pdf": [
        "MEDICAL IMAGE UNDERSTANDING WITH PRETRAINED VISION LANGUAGE MODELS: A COMPREHENSIVE STUDY"
    ],
    "reference_pdf": [
        "Grounded language-image pre-training"
    ],
    "conference": [],
    "reasoning_steps": [],
    "evaluator": {
        "eval_func": "eval_conjunction",
        "eval_kwargs": {
            "eval_func_list": [
                "eval_element_included",
                "eval_element_list_included"
            ],
            "eval_kwargs_list": [
                {
                    "gold": [
                        "GLIP-T (C)",
                        "GLIP-T (C) variant"
                    ],
                    "lowercase": true,
                    "ignore_blank": true
                },
                {
                    "gold": [
                        "O365",
                        "GoldG",
                        "Objects365"
                    ],
                    "lowercase": true
                }
            ]
        }
    },
    "state": {
        "gui-gpt-4o-2024-11-20": false
    },
    "annotator": "kangzhangyi",
    "status": "failure"
}