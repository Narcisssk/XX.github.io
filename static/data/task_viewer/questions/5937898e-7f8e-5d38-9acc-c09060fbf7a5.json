{
    "uuid": "5937898e-7f8e-5d38-9acc-c09060fbf7a5",
    "question": "In the paper that introduces TMID dataset, which pretrained model gets the best F1 score after fine-tuning on TMID dataset? And when pretraining this model, what percentage of tokens were used in the Self-Supervised Blank Infilling task?",
    "answer_format": "Your answer should be a single python list containing two strings, the first element of the list is the pretrained model's name, and the second element of the list is the percentage as an integer, for example, '56%'.",
    "tags": [
        "multiple",
        "table",
        "objective"
    ],
    "anchor_pdf": [
        "94217f41-ec91-59ed-879b-66911867c7e6"
    ],
    "reference_pdf": [
        "1496affd-ee29-52de-8179-42e0418c899e"
    ],
    "conference": [],
    "reasoning_steps": [],
    "evaluator": {
        "eval_func": "eval_structured_object_exact_match",
        "eval_kwargs": {
            "gold": [
                "ChatGLM",
                "95%"
            ],
            "lowercase": true,
            "ignore_order": true
        }
    },
    "state": {
        "gui-gpt-4o-2024-11-20": false
    },
    "annotator": "wangchenrun"
}