{
    "uuid": "1f43b095-5787-5f8c-9570-f1751018227f",
    "question": "What is the main Implicit K-means loss used in this paper(titled \"THE HIDDEN UNIFORM CLUSTER PRIOR IN SELF-SUPERVISED LEARNING\")? How is the loss between two batches defined in the source paper of this loss?",
    "answer_format": "Your answer should be a single python list like [\"xxx loss\",\"some formulas in latex format\"]",
    "tags": [
        "multiple",
        "formula",
        "subjective"
    ],
    "anchor_pdf": [
        "a59a0160-827d-5d49-aed6-060a814fbb31"
    ],
    "reference_pdf": [
        "0e9c9810-0d97-5a61-a5d2-c256ea760d25"
    ],
    "conference": [],
    "reasoning_steps": [],
    "evaluator": {
        "eval_func": "eval_conjunction",
        "eval_kwargs": {
            "eval_func_list": [
                "eval_string_exact_match",
                "eval_reference_answer_with_llm"
            ],
            "eval_kwargs_list": [
                {
                    "gold": "VICReg loss",
                    "lowercase": true
                },
                {
                    "formulas": [
                        "\\ell\\left(Z, Z^{\\prime}\\right) = \\lambda s\\left(Z, Z^{\\prime}\right)+\\mu\\left[v(Z)+v\\left(Z^{\\prime}\\right)\\right]+\nu\\left[c(Z)+c\\left(Z^{\\prime}\\right)\\right]",
                        "s(Z,Z^{\\prime})=\\frac{1}{n}\\sum_i\\|z_i-z_i^{\\prime}\\|_2^2",
                        "v(Z)=\\frac{1}{d}\\sum_{j=1}^d\\max(0,\\gamma-S(z^j,\\epsilon))",
                        "c(Z)=\\frac{1}{d}\\sum_{i\\neq j}[C(Z)]_{i,j}^2"
                    ],
                    "question": "How is the loss between two batches defined in the source paper of this loss?"
                }
            ]
        }
    },
    "state": {
        "gui-gpt-4o-2024-11-20": false
    },
    "annotator": "kangzhangyi"
}